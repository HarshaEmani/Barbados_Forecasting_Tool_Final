[I 2025-04-14 17:36:52,905] A new study created in memory with name: tune-1-LightGBM_Baseline-24hr
[I 2025-04-14 17:36:58,636] Trial 0 finished with value: 0.11489428115689905 and parameters: {'n_estimators': 193, 'learning_rate': 0.002126751898386737, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 43, 'subsample': 0.964269474474685, 'colsample_bytree': 0.6614694952956011, 'reg_alpha': 0.0002091680266631521, 'reg_lambda': 0.48002620959466114}. Best is trial 0 with value: 0.11489428115689905.
[I 2025-04-14 17:37:00,652] Trial 1 finished with value: 0.08524900638805438 and parameters: {'n_estimators': 168, 'learning_rate': 0.2593877074627434, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 12, 'subsample': 0.5382747582889195, 'colsample_bytree': 0.9770194467807627, 'reg_alpha': 3.517207233693396e-05, 'reg_lambda': 2.7530892248565704e-06}. Best is trial 1 with value: 0.08524900638805438.
[I 2025-04-14 17:37:04,435] Trial 2 finished with value: 0.08506783287582559 and parameters: {'n_estimators': 253, 'learning_rate': 0.09401906843224815, 'num_leaves': 26, 'max_depth': 5, 'min_child_samples': 6, 'subsample': 0.9108283679479716, 'colsample_bytree': 0.7201757812094447, 'reg_alpha': 0.009126932699026527, 'reg_lambda': 6.924908583910351e-07}. Best is trial 2 with value: 0.08506783287582559.
[I 2025-04-14 17:37:05,211] Trial 3 finished with value: 0.08451300728644588 and parameters: {'n_estimators': 132, 'learning_rate': 0.18531022104898753, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 36, 'subsample': 0.6785577480008229, 'colsample_bytree': 0.8590701984795571, 'reg_alpha': 0.009414359430485568, 'reg_lambda': 0.6690853204298963}. Best is trial 3 with value: 0.08451300728644588.
[I 2025-04-14 17:37:06,532] Trial 4 finished with value: 0.10490082205554141 and parameters: {'n_estimators': 115, 'learning_rate': 0.006310742498907575, 'num_leaves': 13, 'max_depth': 5, 'min_child_samples': 11, 'subsample': 0.9909936766604804, 'colsample_bytree': 0.6853275584982574, 'reg_alpha': 0.4883853045021716, 'reg_lambda': 9.448743685409472e-06}. Best is trial 3 with value: 0.08451300728644588.
[I 2025-04-14 17:37:07,414] Trial 5 finished with value: 0.11456542340730351 and parameters: {'n_estimators': 225, 'learning_rate': 0.001990174814785192, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 49, 'subsample': 0.906504530653843, 'colsample_bytree': 0.5606016600856347, 'reg_alpha': 1.2195531595368939e-05, 'reg_lambda': 0.004226189691019602}. Best is trial 3 with value: 0.08451300728644588.
[I 2025-04-14 17:37:07,944] Trial 6 finished with value: 0.08374042670785586 and parameters: {'n_estimators': 60, 'learning_rate': 0.08704245844109393, 'num_leaves': 55, 'max_depth': 10, 'min_child_samples': 29, 'subsample': 0.7724313847725135, 'colsample_bytree': 0.7996256487137644, 'reg_alpha': 1.4772801556220205e-06, 'reg_lambda': 0.16920240300567346}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:08,587] Trial 7 finished with value: 0.10829265365636183 and parameters: {'n_estimators': 113, 'learning_rate': 0.004886066477323505, 'num_leaves': 53, 'max_depth': 11, 'min_child_samples': 28, 'subsample': 0.7442641097201466, 'colsample_bytree': 0.6220044878711182, 'reg_alpha': 0.22317440521484233, 'reg_lambda': 1.4993702592277878e-08}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:09,319] Trial 8 finished with value: 0.09785187884340048 and parameters: {'n_estimators': 175, 'learning_rate': 0.009958931710696315, 'num_leaves': 49, 'max_depth': 9, 'min_child_samples': 45, 'subsample': 0.627249046357208, 'colsample_bytree': 0.9562939843133159, 'reg_alpha': 3.8424883600837324e-05, 'reg_lambda': 4.6206559515490544e-05}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:10,666] Trial 9 finished with value: 0.08649270787796419 and parameters: {'n_estimators': 187, 'learning_rate': 0.013295227599108046, 'num_leaves': 20, 'max_depth': 10, 'min_child_samples': 18, 'subsample': 0.7196586156129634, 'colsample_bytree': 0.8955157814145, 'reg_alpha': 0.012294104251010796, 'reg_lambda': 6.740570077868051e-05}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:11,196] Trial 10 finished with value: 0.08714712112547691 and parameters: {'n_estimators': 50, 'learning_rate': 0.047955821309050205, 'num_leaves': 35, 'max_depth': 8, 'min_child_samples': 24, 'subsample': 0.8328670902836854, 'colsample_bytree': 0.7999019594280317, 'reg_alpha': 1.436740319707092e-08, 'reg_lambda': 0.005714808195688526}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:11,635] Trial 11 finished with value: 0.08398552575606122 and parameters: {'n_estimators': 52, 'learning_rate': 0.2877741409492821, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 35, 'subsample': 0.6621757324202009, 'colsample_bytree': 0.8223451298838809, 'reg_alpha': 2.567289064328275e-07, 'reg_lambda': 0.38042271853137216}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:12,177] Trial 12 finished with value: 0.09030709571517981 and parameters: {'n_estimators': 53, 'learning_rate': 0.04048658888796709, 'num_leaves': 41, 'max_depth': 3, 'min_child_samples': 34, 'subsample': 0.8137210343370155, 'colsample_bytree': 0.8001430667303533, 'reg_alpha': 1.1749073444038601e-07, 'reg_lambda': 0.014625934560333372}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:12,994] Trial 13 finished with value: 0.08379815649951328 and parameters: {'n_estimators': 85, 'learning_rate': 0.10238310651377013, 'num_leaves': 29, 'max_depth': 7, 'min_child_samples': 33, 'subsample': 0.630490656051825, 'colsample_bytree': 0.781363165920311, 'reg_alpha': 6.656399959388614e-07, 'reg_lambda': 0.04783338133973427}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:13,712] Trial 14 finished with value: 0.08629354945453348 and parameters: {'n_estimators': 88, 'learning_rate': 0.033594249519952574, 'num_leaves': 28, 'max_depth': 12, 'min_child_samples': 27, 'subsample': 0.5653863994148237, 'colsample_bytree': 0.7571313753460883, 'reg_alpha': 8.310074020820056e-07, 'reg_lambda': 0.02605692373604494}. Best is trial 6 with value: 0.08374042670785586.
[I 2025-04-14 17:37:14,563] Trial 15 finished with value: 0.08354161084431933 and parameters: {'n_estimators': 88, 'learning_rate': 0.11746424819498673, 'num_leaves': 58, 'max_depth': 8, 'min_child_samples': 21, 'subsample': 0.6143195562136115, 'colsample_bytree': 0.9208824557130303, 'reg_alpha': 5.540640828786056e-06, 'reg_lambda': 0.0009754644117984893}. Best is trial 15 with value: 0.08354161084431933.
[I 2025-04-14 17:37:15,759] Trial 16 finished with value: 0.082925212471862 and parameters: {'n_estimators': 141, 'learning_rate': 0.0813590277899135, 'num_leaves': 60, 'max_depth': 9, 'min_child_samples': 20, 'subsample': 0.8136521026766536, 'colsample_bytree': 0.9126147201092867, 'reg_alpha': 4.576421688783207e-06, 'reg_lambda': 0.0006710184309241537}. Best is trial 16 with value: 0.082925212471862.
[I 2025-04-14 17:37:16,957] Trial 17 finished with value: 0.08513833696222455 and parameters: {'n_estimators': 146, 'learning_rate': 0.023754123383871728, 'num_leaves': 59, 'max_depth': 8, 'min_child_samples': 19, 'subsample': 0.5889514850587332, 'colsample_bytree': 0.9167724330851421, 'reg_alpha': 0.0006820763696088587, 'reg_lambda': 0.00029247847552858915}. Best is trial 16 with value: 0.082925212471862.
[I 2025-04-14 17:37:17,761] Trial 18 finished with value: 0.08248916114099973 and parameters: {'n_estimators': 97, 'learning_rate': 0.143780173340082, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 20, 'subsample': 0.8625111026367087, 'colsample_bytree': 0.9981403657772591, 'reg_alpha': 5.476285507534117e-06, 'reg_lambda': 0.0003991187467010624}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:20,595] Trial 19 finished with value: 0.08381228321309152 and parameters: {'n_estimators': 285, 'learning_rate': 0.06401403585098324, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 14, 'subsample': 0.8471430824929355, 'colsample_bytree': 0.9988680166304463, 'reg_alpha': 2.8899232037831232e-08, 'reg_lambda': 0.0008575197967314921}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:23,736] Trial 20 finished with value: 0.08613183530631309 and parameters: {'n_estimators': 147, 'learning_rate': 0.16805981120707564, 'num_leaves': 49, 'max_depth': 6, 'min_child_samples': 5, 'subsample': 0.8727143902613396, 'colsample_bytree': 0.8699902571126876, 'reg_alpha': 4.519600496136596e-06, 'reg_lambda': 1.4054239162179294e-07}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:24,527] Trial 21 finished with value: 0.0840761815834448 and parameters: {'n_estimators': 91, 'learning_rate': 0.12869510327053502, 'num_leaves': 55, 'max_depth': 9, 'min_child_samples': 21, 'subsample': 0.7780728409692084, 'colsample_bytree': 0.9485835743387114, 'reg_alpha': 5.994969893670584e-06, 'reg_lambda': 0.0004198504077155744}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:25,549] Trial 22 finished with value: 0.08288892666449969 and parameters: {'n_estimators': 110, 'learning_rate': 0.06379570288485266, 'num_leaves': 43, 'max_depth': 8, 'min_child_samples': 16, 'subsample': 0.7104913804296193, 'colsample_bytree': 0.9168922871238647, 'reg_alpha': 0.0003616838534892877, 'reg_lambda': 0.0022098229709959}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:26,557] Trial 23 finished with value: 0.08555816449396575 and parameters: {'n_estimators': 118, 'learning_rate': 0.026109422322188918, 'num_leaves': 43, 'max_depth': 9, 'min_child_samples': 16, 'subsample': 0.7071527191505707, 'colsample_bytree': 0.8575835680092427, 'reg_alpha': 0.0006853383094551624, 'reg_lambda': 2.360404697484676e-05}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:27,584] Trial 24 finished with value: 0.08390866680683358 and parameters: {'n_estimators': 158, 'learning_rate': 0.0617113217426266, 'num_leaves': 46, 'max_depth': 11, 'min_child_samples': 24, 'subsample': 0.7956461439557124, 'colsample_bytree': 0.9381388947579006, 'reg_alpha': 0.00013408603828426416, 'reg_lambda': 0.0041279491082155595}. Best is trial 18 with value: 0.08248916114099973.
[I 2025-04-14 17:37:28,875] A new study created in memory with name: tune-1-ANN_Baseload-24hr
[I 2025-04-14 17:37:31,421] Trial 0 finished with value: 0.11163099110126495 and parameters: {'n_layers': 1, 'units_layer_0': 76, 'dropout_layer_0': 0.3046045187590288, 'learning_rate': 0.002670006635330035}. Best is trial 0 with value: 0.11163099110126495.
[I 2025-04-14 17:37:33,452] Trial 1 finished with value: 0.11057926714420319 and parameters: {'n_layers': 2, 'units_layer_0': 149, 'dropout_layer_0': 0.23860170027450547, 'units_layer_1': 157, 'dropout_layer_1': 0.4348650615530445, 'learning_rate': 0.0013039618977365955}. Best is trial 1 with value: 0.11057926714420319.
[I 2025-04-14 17:37:36,374] Trial 2 finished with value: 0.09129613637924194 and parameters: {'n_layers': 3, 'units_layer_0': 189, 'dropout_layer_0': 0.2407436864758204, 'units_layer_1': 60, 'dropout_layer_1': 0.2756173816437231, 'units_layer_2': 39, 'dropout_layer_2': 0.23749281359558605, 'learning_rate': 0.0035943545151933816}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:38,666] Trial 3 finished with value: 0.09970872849225998 and parameters: {'n_layers': 2, 'units_layer_0': 51, 'dropout_layer_0': 0.10227450917582073, 'units_layer_1': 131, 'dropout_layer_1': 0.13426786774342925, 'learning_rate': 0.0009884912216018}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:40,108] Trial 4 finished with value: 0.11196406185626984 and parameters: {'n_layers': 3, 'units_layer_0': 73, 'dropout_layer_0': 0.29699529157126725, 'units_layer_1': 135, 'dropout_layer_1': 0.1295286599845087, 'units_layer_2': 219, 'dropout_layer_2': 0.37144621722804916, 'learning_rate': 0.009309980328111667}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:42,438] Trial 5 finished with value: 0.10852618515491486 and parameters: {'n_layers': 3, 'units_layer_0': 86, 'dropout_layer_0': 0.13164764541103838, 'units_layer_1': 224, 'dropout_layer_1': 0.21950075111719403, 'units_layer_2': 47, 'dropout_layer_2': 0.33551156310999664, 'learning_rate': 0.0006802748282046963}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:45,301] Trial 6 finished with value: 0.12338023632764816 and parameters: {'n_layers': 2, 'units_layer_0': 32, 'dropout_layer_0': 0.34548358695625103, 'units_layer_1': 104, 'dropout_layer_1': 0.17341778199543578, 'learning_rate': 0.00022759559551471654}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:47,820] Trial 7 finished with value: 0.11925848573446274 and parameters: {'n_layers': 1, 'units_layer_0': 88, 'dropout_layer_0': 0.40441206168111643, 'learning_rate': 0.0007161265396631634}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:50,338] Trial 8 finished with value: 0.09494131803512573 and parameters: {'n_layers': 1, 'units_layer_0': 101, 'dropout_layer_0': 0.385027508084289, 'learning_rate': 0.003026296096836562}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:52,965] Trial 9 finished with value: 0.12508851289749146 and parameters: {'n_layers': 1, 'units_layer_0': 69, 'dropout_layer_0': 0.42293967197827154, 'learning_rate': 0.0003299201210840596}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:55,052] Trial 10 finished with value: 0.12143988162279129 and parameters: {'n_layers': 3, 'units_layer_0': 229, 'dropout_layer_0': 0.4834821241439664, 'units_layer_1': 43, 'dropout_layer_1': 0.3442397500969677, 'units_layer_2': 40, 'dropout_layer_2': 0.10632698454694867, 'learning_rate': 0.008776162287288935}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:37:57,737] Trial 11 finished with value: 0.09179180860519409 and parameters: {'n_layers': 2, 'units_layer_0': 153, 'dropout_layer_0': 0.21534636859076906, 'units_layer_1': 52, 'dropout_layer_1': 0.30196268490440037, 'learning_rate': 0.0032272307040095163}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:00,599] Trial 12 finished with value: 0.09357426315546036 and parameters: {'n_layers': 3, 'units_layer_0': 211, 'dropout_layer_0': 0.20360053873711703, 'units_layer_1': 53, 'dropout_layer_1': 0.30453066547315105, 'units_layer_2': 97, 'dropout_layer_2': 0.1736583443734026, 'learning_rate': 0.0035739381817744584}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:02,803] Trial 13 finished with value: 0.09669587761163712 and parameters: {'n_layers': 2, 'units_layer_0': 151, 'dropout_layer_0': 0.2052408556471742, 'units_layer_1': 63, 'dropout_layer_1': 0.258651201601928, 'learning_rate': 0.004693372816082011}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:05,627] Trial 14 finished with value: 0.11317256093025208 and parameters: {'n_layers': 2, 'units_layer_0': 152, 'dropout_layer_0': 0.25332287563808203, 'units_layer_1': 35, 'dropout_layer_1': 0.37741007003926447, 'learning_rate': 0.0016043302395469194}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:07,710] Trial 15 finished with value: 0.11770771443843842 and parameters: {'n_layers': 3, 'units_layer_0': 123, 'dropout_layer_0': 0.1596081791791497, 'units_layer_1': 73, 'dropout_layer_1': 0.4922678518935814, 'units_layer_2': 77, 'dropout_layer_2': 0.4806945898602808, 'learning_rate': 0.005993889457053886}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:10,586] Trial 16 finished with value: 0.13743500411510468 and parameters: {'n_layers': 2, 'units_layer_0': 181, 'dropout_layer_0': 0.1753757124214807, 'units_layer_1': 81, 'dropout_layer_1': 0.2650322309223723, 'learning_rate': 0.00010145436143760591}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:12,797] Trial 17 finished with value: 0.11741425096988678 and parameters: {'n_layers': 3, 'units_layer_0': 119, 'dropout_layer_0': 0.267009209664729, 'units_layer_1': 49, 'dropout_layer_1': 0.34399128812924673, 'units_layer_2': 35, 'dropout_layer_2': 0.22586419344887004, 'learning_rate': 0.0019781155423292153}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:15,400] Trial 18 finished with value: 0.11535192281007767 and parameters: {'n_layers': 2, 'units_layer_0': 252, 'dropout_layer_0': 0.33515785214301286, 'units_layer_1': 34, 'dropout_layer_1': 0.24328188047550328, 'learning_rate': 0.004520778230641717}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:18,400] Trial 19 finished with value: 0.09468469023704529 and parameters: {'n_layers': 3, 'units_layer_0': 176, 'dropout_layer_0': 0.2009323542409483, 'units_layer_1': 59, 'dropout_layer_1': 0.4054090832891154, 'units_layer_2': 73, 'dropout_layer_2': 0.2566717694667202, 'learning_rate': 0.002358301981749211}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:21,120] Trial 20 finished with value: 0.11549478769302368 and parameters: {'n_layers': 2, 'units_layer_0': 116, 'dropout_layer_0': 0.24311889792381186, 'units_layer_1': 97, 'dropout_layer_1': 0.1921459134502576, 'learning_rate': 0.0004574840251008494}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:23,440] Trial 21 finished with value: 0.09237872809171677 and parameters: {'n_layers': 3, 'units_layer_0': 199, 'dropout_layer_0': 0.2077446346432539, 'units_layer_1': 49, 'dropout_layer_1': 0.30987460624712154, 'units_layer_2': 137, 'dropout_layer_2': 0.1503295308256566, 'learning_rate': 0.0036405850934395573}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:25,342] Trial 22 finished with value: 0.11893186718225479 and parameters: {'n_layers': 3, 'units_layer_0': 194, 'dropout_layer_0': 0.15297104433707565, 'units_layer_1': 42, 'dropout_layer_1': 0.3050571181349594, 'units_layer_2': 152, 'dropout_layer_2': 0.14108979627124166, 'learning_rate': 0.006420519210267703}. Best is trial 2 with value: 0.09129613637924194.
[I 2025-04-14 17:38:28,182] Trial 23 finished with value: 0.08983203023672104 and parameters: {'n_layers': 3, 'units_layer_0': 255, 'dropout_layer_0': 0.28062027452977767, 'units_layer_1': 71, 'dropout_layer_1': 0.2925653022404558, 'units_layer_2': 131, 'dropout_layer_2': 0.21331008677904822, 'learning_rate': 0.003775193066223191}. Best is trial 23 with value: 0.08983203023672104.
[I 2025-04-14 17:38:30,689] Trial 24 finished with value: 0.09902390837669373 and parameters: {'n_layers': 2, 'units_layer_0': 240, 'dropout_layer_0': 0.3196263545723542, 'units_layer_1': 70, 'dropout_layer_1': 0.27389538745261827, 'learning_rate': 0.0016339182738731783}. Best is trial 23 with value: 0.08983203023672104.
Env file found at location:  H:\My Drive\Barbados_Forecasting_Tool_Final\.env
Env file found at location:  H:\My Drive\Barbados_Forecasting_Tool_Final\.env
Env file found at location:  H:\My Drive\Barbados_Forecasting_Tool_Final\.env
Env file found at location:  H:\My Drive\Barbados_Forecasting_Tool_Final\.env
Fetching list of Feeder IDs...
Found 12 feeders: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
--- Starting Hyperparameter Tuning ---
Feeders: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Architectures: ['LightGBM_Baseline', 'ANN_Baseload', 'ANN_Change_in_Load', 'LSTM_Baseload', 'LSTM_Change_in_Load']
Scenarios: ['24hr', 'Day', 'Night']
Optuna Trials per combination: 25

Fetching training and validation data...
Fetching data for Feeder 1...
Fetching data for Feeder 1 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3624 records.
Fetching data for Feeder 1 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 768 records.
Fetching data for Feeder 2...
Fetching data for Feeder 2 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 2 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 744 records.
Fetching data for Feeder 3...
Fetching data for Feeder 3 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3624 records.
Fetching data for Feeder 3 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.
Fetching data for Feeder 4...
Fetching data for Feeder 4 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 4 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 720 records.
Fetching data for Feeder 5...
Fetching data for Feeder 5 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3624 records.
Fetching data for Feeder 5 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.
Fetching data for Feeder 6...
Fetching data for Feeder 6 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 6 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.
Fetching data for Feeder 7...
Fetching data for Feeder 7 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 7 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 744 records.
Fetching data for Feeder 8...
Fetching data for Feeder 8 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 8 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 744 records.
Fetching data for Feeder 9...
Fetching data for Feeder 9 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 1848 records.
Fetching data for Feeder 9 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.
Fetching data for Feeder 10...
Fetching data for Feeder 10 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 1848 records.
Fetching data for Feeder 10 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.
Fetching data for Feeder 11...
Fetching data for Feeder 11 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3672 records.
Fetching data for Feeder 11 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 744 records.
Fetching data for Feeder 12...
Fetching data for Feeder 12 from 2023-12-31 00:00:00+0000 to 2024-05-31 23:59:59+00...
Fetched 3624 records.
Fetching data for Feeder 12 from 2024-05-31 00:00:00+0000 to 2024-07-01 23:59:59+0000...
Fetched 792 records.

===== Tuning for Feeder 1 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 140, Version: v1.1_Final_Forecasting_20250414170303, Path Info: models/feeder_1/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170303.pkl
Loading artifact(s) based on path info: models/feeder_1/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170303.pkl
Detected single pickle artifact path: models/feeder_1/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170303.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170303.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170303.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (31, 177), y shape (31, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.114894

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.085249

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.085068

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.084513

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.104901

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.114565

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.083740

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.108293

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.097852

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.086493

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.087147

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.083986

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.090307

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.083798

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.086294

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.083542

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.082925

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.085138
[I 2025-04-14 17:38:32,254] A new study created in memory with name: tune-1-ANN_Change_in_Load-24hr
[I 2025-04-14 17:38:34,864] Trial 0 finished with value: 0.08107500523328781 and parameters: {'n_layers': 2, 'units_layer_0': 39, 'dropout_layer_0': 0.13398313602389333, 'units_layer_1': 105, 'dropout_layer_1': 0.30438656077380144, 'learning_rate': 0.0010283092581385457}. Best is trial 0 with value: 0.08107500523328781.
[I 2025-04-14 17:38:37,020] Trial 1 finished with value: 0.06326958537101746 and parameters: {'n_layers': 2, 'units_layer_0': 54, 'dropout_layer_0': 0.1444449672486801, 'units_layer_1': 244, 'dropout_layer_1': 0.19402385084936424, 'learning_rate': 0.009908798713996336}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:39,441] Trial 2 finished with value: 0.0654028058052063 and parameters: {'n_layers': 2, 'units_layer_0': 155, 'dropout_layer_0': 0.44536243377307205, 'units_layer_1': 174, 'dropout_layer_1': 0.34659836325376314, 'learning_rate': 0.0019113640851388769}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:42,107] Trial 3 finished with value: 0.2010890245437622 and parameters: {'n_layers': 2, 'units_layer_0': 75, 'dropout_layer_0': 0.3631424062760342, 'units_layer_1': 59, 'dropout_layer_1': 0.24817371374610986, 'learning_rate': 0.0001044492637280952}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:44,348] Trial 4 finished with value: 0.06494703888893127 and parameters: {'n_layers': 3, 'units_layer_0': 32, 'dropout_layer_0': 0.3888842906492741, 'units_layer_1': 80, 'dropout_layer_1': 0.11284881335759361, 'units_layer_2': 42, 'dropout_layer_2': 0.20964408206013535, 'learning_rate': 0.006628870994643889}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:47,090] Trial 5 finished with value: 0.06483311951160431 and parameters: {'n_layers': 3, 'units_layer_0': 230, 'dropout_layer_0': 0.4642741451348237, 'units_layer_1': 33, 'dropout_layer_1': 0.15441069846246053, 'units_layer_2': 136, 'dropout_layer_2': 0.16703155836690703, 'learning_rate': 0.0024458553972670645}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:49,892] Trial 6 finished with value: 0.0644090473651886 and parameters: {'n_layers': 2, 'units_layer_0': 57, 'dropout_layer_0': 0.3743335678493932, 'units_layer_1': 255, 'dropout_layer_1': 0.3769742622640587, 'learning_rate': 0.003223526584856648}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:52,016] Trial 7 finished with value: 0.09340770542621613 and parameters: {'n_layers': 1, 'units_layer_0': 157, 'dropout_layer_0': 0.3820597594855092, 'learning_rate': 0.001634633344073459}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:54,470] Trial 8 finished with value: 0.06924036145210266 and parameters: {'n_layers': 2, 'units_layer_0': 101, 'dropout_layer_0': 0.27128320434684783, 'units_layer_1': 76, 'dropout_layer_1': 0.20906702811319972, 'learning_rate': 0.002845945003481368}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:57,188] Trial 9 finished with value: 0.09785325825214386 and parameters: {'n_layers': 2, 'units_layer_0': 33, 'dropout_layer_0': 0.33285451223801826, 'units_layer_1': 49, 'dropout_layer_1': 0.4262184279138037, 'learning_rate': 0.0006036749540766561}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:38:59,790] Trial 10 finished with value: 0.07427626848220825 and parameters: {'n_layers': 1, 'units_layer_0': 53, 'dropout_layer_0': 0.1026879342251916, 'learning_rate': 0.00710502717284074}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:39:02,609] Trial 11 finished with value: 0.0662417784333229 and parameters: {'n_layers': 1, 'units_layer_0': 61, 'dropout_layer_0': 0.22300272524133408, 'learning_rate': 0.009963076006419151}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:39:05,314] Trial 12 finished with value: 0.06511588394641876 and parameters: {'n_layers': 3, 'units_layer_0': 51, 'dropout_layer_0': 0.19795253341232835, 'units_layer_1': 238, 'dropout_layer_1': 0.48882184090977504, 'units_layer_2': 252, 'dropout_layer_2': 0.48554536180375873, 'learning_rate': 0.003775795071019569}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:39:08,195] Trial 13 finished with value: 0.08275561034679413 and parameters: {'n_layers': 2, 'units_layer_0': 94, 'dropout_layer_0': 0.27963412584661573, 'units_layer_1': 251, 'dropout_layer_1': 0.3749276618208693, 'learning_rate': 0.00037590589442184453}. Best is trial 1 with value: 0.06326958537101746.
[I 2025-04-14 17:39:11,199] Trial 14 finished with value: 0.06172779202461243 and parameters: {'n_layers': 3, 'units_layer_0': 67, 'dropout_layer_0': 0.18743639333565498, 'units_layer_1': 146, 'dropout_layer_1': 0.21560215568540808, 'units_layer_2': 35, 'dropout_layer_2': 0.4145244715036238, 'learning_rate': 0.004839588117070405}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:14,134] Trial 15 finished with value: 0.06644991040229797 and parameters: {'n_layers': 3, 'units_layer_0': 79, 'dropout_layer_0': 0.17388615440836966, 'units_layer_1': 144, 'dropout_layer_1': 0.21548597539215408, 'units_layer_2': 33, 'dropout_layer_2': 0.4366670338623666, 'learning_rate': 0.004992413512834596}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:17,033] Trial 16 finished with value: 0.06503782421350479 and parameters: {'n_layers': 3, 'units_layer_0': 120, 'dropout_layer_0': 0.1555860960857964, 'units_layer_1': 153, 'dropout_layer_1': 0.17142834991953765, 'units_layer_2': 63, 'dropout_layer_2': 0.3556577717581978, 'learning_rate': 0.009852185076228268}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:19,897] Trial 17 finished with value: 0.10161249339580536 and parameters: {'n_layers': 3, 'units_layer_0': 42, 'dropout_layer_0': 0.2338464379757434, 'units_layer_1': 125, 'dropout_layer_1': 0.27199960830643904, 'units_layer_2': 80, 'dropout_layer_2': 0.31915464075164457, 'learning_rate': 0.0002157663301418334}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:22,414] Trial 18 finished with value: 0.10761616379022598 and parameters: {'n_layers': 1, 'units_layer_0': 66, 'dropout_layer_0': 0.11412260369271135, 'learning_rate': 0.0011752138803897056}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:24,306] Trial 19 finished with value: 0.065648652613163 and parameters: {'n_layers': 3, 'units_layer_0': 45, 'dropout_layer_0': 0.23789169321491296, 'units_layer_1': 188, 'dropout_layer_1': 0.10376354102849383, 'units_layer_2': 52, 'dropout_layer_2': 0.3876383837166346, 'learning_rate': 0.0047954575110737375}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:27,016] Trial 20 finished with value: 0.07911978662014008 and parameters: {'n_layers': 2, 'units_layer_0': 120, 'dropout_layer_0': 0.16998479333327743, 'units_layer_1': 196, 'dropout_layer_1': 0.1708853026627943, 'learning_rate': 0.0005241746684871866}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:29,093] Trial 21 finished with value: 0.06358727812767029 and parameters: {'n_layers': 2, 'units_layer_0': 59, 'dropout_layer_0': 0.3228436006705221, 'units_layer_1': 245, 'dropout_layer_1': 0.3380253178111562, 'learning_rate': 0.0034865428020479693}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:31,245] Trial 22 finished with value: 0.06508798897266388 and parameters: {'n_layers': 2, 'units_layer_0': 69, 'dropout_layer_0': 0.31785539690354664, 'units_layer_1': 199, 'dropout_layer_1': 0.3048749071739751, 'learning_rate': 0.006035564688437782}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:33,520] Trial 23 finished with value: 0.06371282041072845 and parameters: {'n_layers': 2, 'units_layer_0': 89, 'dropout_layer_0': 0.2715305677138143, 'units_layer_1': 132, 'dropout_layer_1': 0.23348329807490859, 'learning_rate': 0.0040143938097783}. Best is trial 14 with value: 0.06172779202461243.
[I 2025-04-14 17:39:36,016] Trial 24 finished with value: 0.06780538707971573 and parameters: {'n_layers': 1, 'units_layer_0': 48, 'dropout_layer_0': 0.19490799897267605, 'learning_rate': 0.007691674714650258}. Best is trial 14 with value: 0.06172779202461243.

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.082489

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.083812

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.086132

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.084076

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.082889

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.085558

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.083909

--- Best Results for Feeder=1, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.082489
Best Hyperparameters:
  n_estimators: 97
  learning_rate: 0.143780173340082
  num_leaves: 47
  max_depth: 9
  min_child_samples: 20
  subsample: 0.8625111026367087
  colsample_bytree: 0.9981403657772591
  reg_alpha: 5.476285507534117e-06
  reg_lambda: 0.0003991187467010624

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=1, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=1, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 88, Version: v1.0_automated_training_20250414022040, Path Info: {"keras_model": "models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040.keras", "scalers_pkl": "models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040.keras', 'scalers_pkl': 'models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040_scalers.pkl'}
Detected separate Keras model (models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040.keras) and scalers (models/feeder_1/ANN_Baseload_24hr_v1.0_automated_training_20250414022040_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Baseload_24hr_v1.0_automated_training_20250414022040.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Baseload_24hr_v1.0_automated_training_20250414022040_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Baseload_24hr_v1.0_automated_training_20250414022040.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Baseload_24hr_v1.0_automated_training_20250414022040_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (31, 177), y shape (31, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for ANN_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.111631

--- Optuna Trial 1 for ANN_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.110579

--- Optuna Trial 2 for ANN_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.091296

--- Optuna Trial 3 for ANN_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.099709

--- Optuna Trial 4 for ANN_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.111964

--- Optuna Trial 5 for ANN_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.108526

--- Optuna Trial 6 for ANN_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.123380

--- Optuna Trial 7 for ANN_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.119258

--- Optuna Trial 8 for ANN_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.094941

--- Optuna Trial 9 for ANN_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.125089

--- Optuna Trial 10 for ANN_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.121440

--- Optuna Trial 11 for ANN_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.091792

--- Optuna Trial 12 for ANN_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.093574

--- Optuna Trial 13 for ANN_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.096696

--- Optuna Trial 14 for ANN_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.113173

--- Optuna Trial 15 for ANN_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.117708

--- Optuna Trial 16 for ANN_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.137435

--- Optuna Trial 17 for ANN_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.117414

--- Optuna Trial 18 for ANN_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.115352

--- Optuna Trial 19 for ANN_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.094685

--- Optuna Trial 20 for ANN_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.115495

--- Optuna Trial 21 for ANN_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.092379

--- Optuna Trial 22 for ANN_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.118932

--- Optuna Trial 23 for ANN_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.089832

--- Optuna Trial 24 for ANN_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.099024

--- Best Results for Feeder=1, Arch=ANN_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.089832
Best Hyperparameters:
  n_layers: 3
  units_layer_0: 255
  dropout_layer_0: 0.28062027452977767
  units_layer_1: 71
  dropout_layer_1: 0.2925653022404558
  units_layer_2: 131
  dropout_layer_2: 0.21331008677904822
  learning_rate: 0.003775193066223191

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
[I 2025-04-14 17:39:37,945] A new study created in memory with name: tune-1-LSTM_Baseload-24hr
[I 2025-04-14 17:39:42,998] Trial 0 finished with value: 0.09212396293878555 and parameters: {'n_lstm_layers': 1, 'lstm_units': 70, 'n_dense_layers': 2, 'lstm_dropout_0': 0.15116259785819208, 'dense_units_0': 41, 'dense_dropout_0': 0.40106340752163916, 'dense_units_1': 54, 'dense_dropout_1': 0.3550948664759722, 'learning_rate': 0.008355545447979628}. Best is trial 0 with value: 0.09212396293878555.
[I 2025-04-14 17:39:48,065] Trial 1 finished with value: 0.10881919413805008 and parameters: {'n_lstm_layers': 1, 'lstm_units': 70, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3703716288329373, 'dense_units_0': 64, 'dense_dropout_0': 0.28715216827911483, 'dense_units_1': 50, 'dense_dropout_1': 0.43802272062937764, 'learning_rate': 0.001518343197193882}. Best is trial 0 with value: 0.09212396293878555.
[I 2025-04-14 17:39:53,903] Trial 2 finished with value: 0.11378005146980286 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4526521759615668, 'lstm_dropout_1': 0.46248603431433466, 'dense_units_0': 47, 'dense_dropout_0': 0.2901332734412697, 'learning_rate': 0.008692571285786916}. Best is trial 0 with value: 0.09212396293878555.
[I 2025-04-14 17:39:58,008] Trial 3 finished with value: 0.09083603322505951 and parameters: {'n_lstm_layers': 1, 'lstm_units': 38, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17914611927753615, 'learning_rate': 0.005304692511124775}. Best is trial 3 with value: 0.09083603322505951.
[I 2025-04-14 17:40:03,038] Trial 4 finished with value: 0.10129924863576889 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 1, 'lstm_dropout_0': 0.43052619686493754, 'dense_units_0': 17, 'dense_dropout_0': 0.44770679208572295, 'learning_rate': 0.001306042211852384}. Best is trial 3 with value: 0.09083603322505951.
[I 2025-04-14 17:40:07,590] Trial 5 finished with value: 0.09473246335983276 and parameters: {'n_lstm_layers': 1, 'lstm_units': 117, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4877801064118421, 'dense_units_0': 60, 'dense_dropout_0': 0.25274071942982457, 'learning_rate': 0.0010989826140784234}. Best is trial 3 with value: 0.09083603322505951.
[I 2025-04-14 17:40:14,466] Trial 6 finished with value: 0.08702300488948822 and parameters: {'n_lstm_layers': 2, 'lstm_units': 54, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21969691399188274, 'lstm_dropout_1': 0.28824467955746585, 'learning_rate': 0.002418396142255863}. Best is trial 6 with value: 0.08702300488948822.
[I 2025-04-14 17:40:21,990] Trial 7 finished with value: 0.11420147866010666 and parameters: {'n_lstm_layers': 2, 'lstm_units': 36, 'n_dense_layers': 1, 'lstm_dropout_0': 0.36506964280440235, 'lstm_dropout_1': 0.4096388816449261, 'dense_units_0': 23, 'dense_dropout_0': 0.2532756383010414, 'learning_rate': 0.0006439696931561749}. Best is trial 6 with value: 0.08702300488948822.
[I 2025-04-14 17:40:28,921] Trial 8 finished with value: 0.11624859273433685 and parameters: {'n_lstm_layers': 2, 'lstm_units': 83, 'n_dense_layers': 2, 'lstm_dropout_0': 0.49051186963102644, 'lstm_dropout_1': 0.4412503441450334, 'dense_units_0': 53, 'dense_dropout_0': 0.25753238777467546, 'dense_units_1': 52, 'dense_dropout_1': 0.1426336775117798, 'learning_rate': 0.0006073427204721688}. Best is trial 6 with value: 0.08702300488948822.
[I 2025-04-14 17:40:36,194] Trial 9 finished with value: 0.11645082384347916 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 2, 'lstm_dropout_0': 0.10148819757828771, 'lstm_dropout_1': 0.1411613866903217, 'dense_units_0': 23, 'dense_dropout_0': 0.2232799842389492, 'dense_units_1': 17, 'dense_dropout_1': 0.4337562362822437, 'learning_rate': 0.0013727409888000224}. Best is trial 6 with value: 0.08702300488948822.
[I 2025-04-14 17:40:43,887] Trial 10 finished with value: 0.10968763381242752 and parameters: {'n_lstm_layers': 2, 'lstm_units': 51, 'n_dense_layers': 0, 'lstm_dropout_0': 0.24944468904247033, 'lstm_dropout_1': 0.2353609853756063, 'learning_rate': 0.0001223409960353462}. Best is trial 6 with value: 0.08702300488948822.
[I 2025-04-14 17:40:48,540] Trial 11 finished with value: 0.08667498826980591 and parameters: {'n_lstm_layers': 1, 'lstm_units': 33, 'n_dense_layers': 0, 'lstm_dropout_0': 0.22482392395035428, 'learning_rate': 0.0035024953365389365}. Best is trial 11 with value: 0.08667498826980591.
[I 2025-04-14 17:40:56,022] Trial 12 finished with value: 0.0943293571472168 and parameters: {'n_lstm_layers': 2, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2609595117158239, 'lstm_dropout_1': 0.30341340726721716, 'learning_rate': 0.0030206070631002466}. Best is trial 11 with value: 0.08667498826980591.
[I 2025-04-14 17:41:00,944] Trial 13 finished with value: 0.0886358693242073 and parameters: {'n_lstm_layers': 1, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21010235112781556, 'learning_rate': 0.0028568884035975505}. Best is trial 11 with value: 0.08667498826980591.
[I 2025-04-14 17:41:05,251] Trial 14 finished with value: 0.08725043386220932 and parameters: {'n_lstm_layers': 1, 'lstm_units': 101, 'n_dense_layers': 0, 'lstm_dropout_0': 0.31154739088031713, 'learning_rate': 0.003483225988657287}. Best is trial 11 with value: 0.08667498826980591.
[I 2025-04-14 17:41:13,289] Trial 15 finished with value: 0.11342159658670425 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.27150504115153956, 'lstm_dropout_1': 0.31357599977387624, 'learning_rate': 0.00027088772803431565}. Best is trial 11 with value: 0.08667498826980591.
[I 2025-04-14 17:41:20,886] Trial 16 finished with value: 0.08231374621391296 and parameters: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20505835763267546, 'lstm_dropout_1': 0.11259093026249084, 'learning_rate': 0.0022551761476824477}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:25,877] Trial 17 finished with value: 0.085531085729599 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.14689433600491336, 'dense_units_0': 33, 'dense_dropout_0': 0.12191345977862006, 'learning_rate': 0.004918427789174408}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:32,689] Trial 18 finished with value: 0.08929216116666794 and parameters: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 1, 'lstm_dropout_0': 0.10119978781831104, 'lstm_dropout_1': 0.10129900470112724, 'dense_units_0': 32, 'dense_dropout_0': 0.1326331350063544, 'learning_rate': 0.004639630199171651}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:37,929] Trial 19 finished with value: 0.09873601794242859 and parameters: {'n_lstm_layers': 1, 'lstm_units': 40, 'n_dense_layers': 1, 'lstm_dropout_0': 0.15311956243696495, 'dense_units_0': 34, 'dense_dropout_0': 0.10165608171099161, 'learning_rate': 0.0006037958506908482}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:43,039] Trial 20 finished with value: 0.09448721259832382 and parameters: {'n_lstm_layers': 1, 'lstm_units': 37, 'n_dense_layers': 1, 'lstm_dropout_0': 0.16552782879195144, 'dense_units_0': 24, 'dense_dropout_0': 0.17716508766651387, 'learning_rate': 0.0020087832108438655}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:47,472] Trial 21 finished with value: 0.0914258286356926 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21083847939106415, 'learning_rate': 0.00548998387488859}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:52,272] Trial 22 finished with value: 0.0893004760146141 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3059995895058225, 'learning_rate': 0.005916724213833879}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:41:56,037] Trial 23 finished with value: 0.09018538147211075 and parameters: {'n_lstm_layers': 1, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.125766151011982, 'learning_rate': 0.003949917991256077}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:42:00,940] Trial 24 finished with value: 0.11416984349489212 and parameters: {'n_lstm_layers': 1, 'lstm_units': 35, 'n_dense_layers': 1, 'lstm_dropout_0': 0.19017555734923078, 'dense_units_0': 16, 'dense_dropout_0': 0.37536832708214246, 'learning_rate': 0.0019125069448130679}. Best is trial 16 with value: 0.08231374621391296.
[I 2025-04-14 17:42:02,838] A new study created in memory with name: tune-1-LSTM_Change_in_Load-24hr
[I 2025-04-14 17:42:08,167] Trial 0 finished with value: 0.06356934458017349 and parameters: {'n_lstm_layers': 1, 'lstm_units': 96, 'n_dense_layers': 2, 'lstm_dropout_0': 0.31637930655128765, 'dense_units_0': 19, 'dense_dropout_0': 0.49456125802881545, 'dense_units_1': 31, 'dense_dropout_1': 0.2575134340185266, 'learning_rate': 0.0033451631813684298}. Best is trial 0 with value: 0.06356934458017349.
Selecting model for Feeder 1, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=1, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=1, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 87, Version: v1.0_automated_training_20250414021805, Path Info: {"keras_model": "models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805.keras", "scalers_pkl": "models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805.keras', 'scalers_pkl': 'models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805_scalers.pkl'}
Detected separate Keras model (models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805.keras) and scalers (models/feeder_1/ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\ANN_Change_in_Load_24hr_v1.0_automated_training_20250414021805_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (31, 177), y shape (31, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for ANN_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.081075

--- Optuna Trial 1 for ANN_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.063270

--- Optuna Trial 2 for ANN_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.065403

--- Optuna Trial 3 for ANN_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.201089

--- Optuna Trial 4 for ANN_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.064947

--- Optuna Trial 5 for ANN_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.064833

--- Optuna Trial 6 for ANN_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.064409

--- Optuna Trial 7 for ANN_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.093408

--- Optuna Trial 8 for ANN_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.069240

--- Optuna Trial 9 for ANN_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.097853

--- Optuna Trial 10 for ANN_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.074276

--- Optuna Trial 11 for ANN_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.066242

--- Optuna Trial 12 for ANN_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.065116

--- Optuna Trial 13 for ANN_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.082756

--- Optuna Trial 14 for ANN_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.061728

--- Optuna Trial 15 for ANN_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.066450

--- Optuna Trial 16 for ANN_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.065038

--- Optuna Trial 17 for ANN_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.101612

--- Optuna Trial 18 for ANN_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.107616

--- Optuna Trial 19 for ANN_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.065649

--- Optuna Trial 20 for ANN_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.079120

--- Optuna Trial 21 for ANN_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.063587

--- Optuna Trial 22 for ANN_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.065088

--- Optuna Trial 23 for ANN_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.063713

--- Optuna Trial 24 for ANN_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.067805

--- Best Results for Feeder=1, Arch=ANN_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.061728
Best Hyperparameters:
  n_layers: 3
  units_layer_0: 67
  dropout_layer_0: 0.18743639333565498
  units_layer_1: 146
  dropout_layer_1: 0.21560215568540808
  units_layer_2: 35
  dropout_layer_2: 0.4145244715036238
  learning_rate: 0.004839588117070405

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=1, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=1, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 141, Version: v1.1_Final_Forecasting_20250414170314, Path Info: {"keras_model": "models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314.keras", "scalers_pkl": "models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314.keras', 'scalers_pkl': 'models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314_scalers.pkl'}
[I 2025-04-14 17:42:16,119] Trial 1 finished with value: 0.07324329018592834 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3152456977372802, 'lstm_dropout_1': 0.2480179538245995, 'dense_units_0': 30, 'dense_dropout_0': 0.10043915268125687, 'learning_rate': 0.0003325974055041913}. Best is trial 0 with value: 0.06356934458017349.
[I 2025-04-14 17:42:21,119] Trial 2 finished with value: 0.08491423726081848 and parameters: {'n_lstm_layers': 1, 'lstm_units': 55, 'n_dense_layers': 0, 'lstm_dropout_0': 0.309168542075241, 'learning_rate': 0.00013242016799065124}. Best is trial 0 with value: 0.06356934458017349.
[I 2025-04-14 17:42:28,651] Trial 3 finished with value: 0.06298096477985382 and parameters: {'n_lstm_layers': 2, 'lstm_units': 118, 'n_dense_layers': 0, 'lstm_dropout_0': 0.28366893290606343, 'lstm_dropout_1': 0.4624381084552558, 'learning_rate': 0.0009981080909695092}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:33,822] Trial 4 finished with value: 0.08081907778978348 and parameters: {'n_lstm_layers': 1, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.22487214626274055, 'learning_rate': 0.0001352216110755787}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:38,818] Trial 5 finished with value: 0.1343502551317215 and parameters: {'n_lstm_layers': 1, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3302608420879015, 'dense_units_0': 17, 'dense_dropout_0': 0.42835056451327047, 'learning_rate': 0.0004022570819593781}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:43,585] Trial 6 finished with value: 0.06596310436725616 and parameters: {'n_lstm_layers': 1, 'lstm_units': 95, 'n_dense_layers': 1, 'lstm_dropout_0': 0.43800021948246093, 'dense_units_0': 43, 'dense_dropout_0': 0.32259275746914806, 'learning_rate': 0.0013602332824807438}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:47,772] Trial 7 finished with value: 0.06320343166589737 and parameters: {'n_lstm_layers': 1, 'lstm_units': 84, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4431068710958015, 'dense_units_0': 21, 'dense_dropout_0': 0.3171684874333952, 'learning_rate': 0.004401208916660354}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:55,584] Trial 8 finished with value: 0.1224629282951355 and parameters: {'n_lstm_layers': 2, 'lstm_units': 83, 'n_dense_layers': 2, 'lstm_dropout_0': 0.32064056589933365, 'lstm_dropout_1': 0.16140710789764082, 'dense_units_0': 22, 'dense_dropout_0': 0.4762703010779129, 'dense_units_1': 35, 'dense_dropout_1': 0.3144837963878891, 'learning_rate': 0.00034391731227838084}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:42:59,326] Trial 9 finished with value: 0.06798364967107773 and parameters: {'n_lstm_layers': 1, 'lstm_units': 39, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3360492207720379, 'learning_rate': 0.004551534640500206}. Best is trial 3 with value: 0.06298096477985382.
[I 2025-04-14 17:43:07,102] Trial 10 finished with value: 0.06003035977482796 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10600942538360766, 'lstm_dropout_1': 0.4996540222225695, 'learning_rate': 0.0015882846404082131}. Best is trial 10 with value: 0.06003035977482796.
[I 2025-04-14 17:43:14,586] Trial 11 finished with value: 0.06268446147441864 and parameters: {'n_lstm_layers': 2, 'lstm_units': 124, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10321158944074926, 'lstm_dropout_1': 0.4970675428431445, 'learning_rate': 0.0012669001557514773}. Best is trial 10 with value: 0.06003035977482796.
[I 2025-04-14 17:43:22,030] Trial 12 finished with value: 0.06233617663383484 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10485933577243925, 'lstm_dropout_1': 0.49976595303227833, 'learning_rate': 0.0015416662335027722}. Best is trial 10 with value: 0.06003035977482796.
[I 2025-04-14 17:43:29,573] Trial 13 finished with value: 0.06039515510201454 and parameters: {'n_lstm_layers': 2, 'lstm_units': 128, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10003103484803205, 'lstm_dropout_1': 0.382728278642502, 'learning_rate': 0.009536834831092376}. Best is trial 10 with value: 0.06003035977482796.
[I 2025-04-14 17:43:36,927] Trial 14 finished with value: 0.059979457408189774 and parameters: {'n_lstm_layers': 2, 'lstm_units': 73, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17479099007116988, 'lstm_dropout_1': 0.3665487174639004, 'learning_rate': 0.009255883115117245}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:43:44,411] Trial 15 finished with value: 0.06101757660508156 and parameters: {'n_lstm_layers': 2, 'lstm_units': 41, 'n_dense_layers': 1, 'lstm_dropout_0': 0.16877630931119755, 'lstm_dropout_1': 0.3562098314616807, 'dense_units_0': 62, 'dense_dropout_0': 0.12700915066532514, 'learning_rate': 0.00803080066997102}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:43:51,821] Trial 16 finished with value: 0.061989519745111465 and parameters: {'n_lstm_layers': 2, 'lstm_units': 73, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18567018347926958, 'lstm_dropout_1': 0.3962588300233852, 'learning_rate': 0.0024969712260477306}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:43:59,351] Trial 17 finished with value: 0.11787314713001251 and parameters: {'n_lstm_layers': 2, 'lstm_units': 68, 'n_dense_layers': 2, 'lstm_dropout_0': 0.16536697348940577, 'lstm_dropout_1': 0.27215430805721336, 'dense_units_0': 63, 'dense_dropout_0': 0.2236809257627487, 'dense_units_1': 16, 'dense_dropout_1': 0.49497018576978646, 'learning_rate': 0.0005855598415920706}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:44:06,946] Trial 18 finished with value: 0.061417341232299805 and parameters: {'n_lstm_layers': 2, 'lstm_units': 46, 'n_dense_layers': 0, 'lstm_dropout_0': 0.23932477262676644, 'lstm_dropout_1': 0.3355426666026946, 'learning_rate': 0.006131960018553113}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:44:14,357] Trial 19 finished with value: 0.0640738308429718 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 1, 'lstm_dropout_0': 0.14825220762383304, 'lstm_dropout_1': 0.42569253366807003, 'dense_units_0': 34, 'dense_dropout_0': 0.24125451232274453, 'learning_rate': 0.0022818257836038245}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:44:21,808] Trial 20 finished with value: 0.06981906294822693 and parameters: {'n_lstm_layers': 2, 'lstm_units': 104, 'n_dense_layers': 1, 'lstm_dropout_0': 0.22425233123429578, 'lstm_dropout_1': 0.20730168638778146, 'dense_units_0': 45, 'dense_dropout_0': 0.41587616851557574, 'learning_rate': 0.0005429484759972544}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:44:29,337] Trial 21 finished with value: 0.06046343594789505 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 0, 'lstm_dropout_0': 0.13085062243437157, 'lstm_dropout_1': 0.3803542535332937, 'learning_rate': 0.009365659286455046}. Best is trial 14 with value: 0.059979457408189774.
[I 2025-04-14 17:44:36,719] Trial 22 finished with value: 0.05990295112133026 and parameters: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10039998011565632, 'lstm_dropout_1': 0.3146228283196653, 'learning_rate': 0.005853592387776404}. Best is trial 22 with value: 0.05990295112133026.
[I 2025-04-14 17:44:44,086] Trial 23 finished with value: 0.06068035215139389 and parameters: {'n_lstm_layers': 2, 'lstm_units': 77, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1904125400319039, 'lstm_dropout_1': 0.31196748157761534, 'learning_rate': 0.005699869736807298}. Best is trial 22 with value: 0.05990295112133026.
[I 2025-04-14 17:44:51,693] Trial 24 finished with value: 0.061083100736141205 and parameters: {'n_lstm_layers': 2, 'lstm_units': 64, 'n_dense_layers': 0, 'lstm_dropout_0': 0.13303743674628365, 'lstm_dropout_1': 0.28934610350010703, 'learning_rate': 0.0026685040886103226}. Best is trial 22 with value: 0.05990295112133026.
[I 2025-04-14 17:44:52,986] A new study created in memory with name: tune-2-LightGBM_Baseline-24hr
[I 2025-04-14 17:44:57,209] Trial 0 finished with value: 0.22991795946987428 and parameters: {'n_estimators': 50, 'learning_rate': 0.001462262640198746, 'num_leaves': 56, 'max_depth': 5, 'min_child_samples': 9, 'subsample': 0.8415234790817967, 'colsample_bytree': 0.9851207265351708, 'reg_alpha': 3.164671882106437e-05, 'reg_lambda': 0.009512182608512198}. Best is trial 0 with value: 0.22991795946987428.
[I 2025-04-14 17:44:57,685] Trial 1 finished with value: 0.12065578702719991 and parameters: {'n_estimators': 97, 'learning_rate': 0.23145920104784123, 'num_leaves': 25, 'max_depth': 6, 'min_child_samples': 34, 'subsample': 0.9081477356838645, 'colsample_bytree': 0.5006455885450215, 'reg_alpha': 0.020334575397931612, 'reg_lambda': 0.00016017782156290701}. Best is trial 1 with value: 0.12065578702719991.
[I 2025-04-14 17:44:58,130] Trial 2 finished with value: 0.2225661151767555 and parameters: {'n_estimators': 94, 'learning_rate': 0.0038729137240535285, 'num_leaves': 24, 'max_depth': 12, 'min_child_samples': 45, 'subsample': 0.6634495952747674, 'colsample_bytree': 0.5960464831948887, 'reg_alpha': 0.01219125692281291, 'reg_lambda': 7.676200822263377e-06}. Best is trial 1 with value: 0.12065578702719991.
[I 2025-04-14 17:44:59,050] Trial 3 finished with value: 0.1906267476186684 and parameters: {'n_estimators': 193, 'learning_rate': 0.002533115500510644, 'num_leaves': 37, 'max_depth': 7, 'min_child_samples': 26, 'subsample': 0.5329611856061522, 'colsample_bytree': 0.7250538752411027, 'reg_alpha': 0.1636017673424478, 'reg_lambda': 1.015244372503861e-06}. Best is trial 1 with value: 0.12065578702719991.
[I 2025-04-14 17:44:59,585] Trial 4 finished with value: 0.09171297097580035 and parameters: {'n_estimators': 73, 'learning_rate': 0.16494242595095507, 'num_leaves': 49, 'max_depth': 3, 'min_child_samples': 14, 'subsample': 0.5988240151343207, 'colsample_bytree': 0.8013284743960083, 'reg_alpha': 2.0251231679776354e-08, 'reg_lambda': 0.0009687043359664956}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:01,018] Trial 5 finished with value: 0.09762849117917194 and parameters: {'n_estimators': 263, 'learning_rate': 0.017333668002032003, 'num_leaves': 52, 'max_depth': 3, 'min_child_samples': 9, 'subsample': 0.5079531168347964, 'colsample_bytree': 0.5598057497423297, 'reg_alpha': 0.013344379263178144, 'reg_lambda': 1.3803387240453834e-06}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:01,715] Trial 6 finished with value: 0.18387473016594305 and parameters: {'n_estimators': 161, 'learning_rate': 0.003964723481272398, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 35, 'subsample': 0.9865926637797237, 'colsample_bytree': 0.7051482769685824, 'reg_alpha': 0.0028481528558021003, 'reg_lambda': 0.7214166334893258}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:04,307] Trial 7 finished with value: 0.09867145428697947 and parameters: {'n_estimators': 218, 'learning_rate': 0.01296954348649462, 'num_leaves': 34, 'max_depth': 6, 'min_child_samples': 5, 'subsample': 0.9241753748065432, 'colsample_bytree': 0.8292938203761787, 'reg_alpha': 0.00028522413647379547, 'reg_lambda': 0.24651266595614654}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:04,996] Trial 8 finished with value: 0.20028947292851393 and parameters: {'n_estimators': 179, 'learning_rate': 0.006058935095723737, 'num_leaves': 15, 'max_depth': 10, 'min_child_samples': 45, 'subsample': 0.5178143257272649, 'colsample_bytree': 0.859260410678929, 'reg_alpha': 4.4866718168074185e-07, 'reg_lambda': 1.797945683131077e-05}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:05,800] Trial 9 finished with value: 0.19163791759990426 and parameters: {'n_estimators': 132, 'learning_rate': 0.003342494378382634, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 20, 'subsample': 0.7240670057081278, 'colsample_bytree': 0.5840460822542788, 'reg_alpha': 1.0160757855143994e-08, 'reg_lambda': 2.4068910394611277e-07}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:06,254] Trial 10 finished with value: 0.09649770910368342 and parameters: {'n_estimators': 51, 'learning_rate': 0.28826950794881767, 'num_leaves': 47, 'max_depth': 3, 'min_child_samples': 18, 'subsample': 0.65583624900042, 'colsample_bytree': 0.9893999965528749, 'reg_alpha': 1.2100468860132773e-08, 'reg_lambda': 1.055024255261524e-08}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:06,695] Trial 11 finished with value: 0.09724480378864349 and parameters: {'n_estimators': 50, 'learning_rate': 0.25645386990572816, 'num_leaves': 47, 'max_depth': 3, 'min_child_samples': 18, 'subsample': 0.6429708670992434, 'colsample_bytree': 0.9884267001836601, 'reg_alpha': 1.2213552636075782e-08, 'reg_lambda': 1.4200675437457241e-08}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:07,562] Trial 12 finished with value: 0.09510729739369816 and parameters: {'n_estimators': 97, 'learning_rate': 0.07358962467323284, 'num_leaves': 59, 'max_depth': 4, 'min_child_samples': 16, 'subsample': 0.619048603179286, 'colsample_bytree': 0.8743852802461433, 'reg_alpha': 6.716756209825724e-07, 'reg_lambda': 0.0006794004891916874}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:08,412] Trial 13 finished with value: 0.09491146432622743 and parameters: {'n_estimators': 109, 'learning_rate': 0.07078965977692588, 'num_leaves': 57, 'max_depth': 4, 'min_child_samples': 15, 'subsample': 0.6076208968474948, 'colsample_bytree': 0.86309386568486, 'reg_alpha': 9.154369826676335e-07, 'reg_lambda': 0.001885979665267696}. Best is trial 4 with value: 0.09171297097580035.
Detected separate Keras model (models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314.keras) and scalers (models/feeder_1/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170314_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (31, 177), y shape (31, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.092124

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.108819

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.113780

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.090836

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.101299

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.094732

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.087023

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.114201

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.116249

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.116451

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.109688

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.086675

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.094329

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.088636

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.087250

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.113422

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.082314

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.085531

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.089292

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.098736

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.094487

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.091426

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.089300

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.090185

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.114170

--- Best Results for Feeder=1, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.082314
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 44
  n_dense_layers: 0
  lstm_dropout_0: 0.20505835763267546
  lstm_dropout_1: 0.11259093026249084
  learning_rate: 0.0022551761476824477

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=1, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=1, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 142, Version: v1.1_Final_Forecasting_20250414170323, Path Info: {"keras_model": "models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323.keras", "scalers_pkl": "models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323.keras', 'scalers_pkl': 'models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323_scalers.pkl'}
Detected separate Keras model (models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323.keras) and scalers (models/feeder_1/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170323_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (31, 177), y shape (31, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.063569

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
[I 2025-04-14 17:45:09,247] Trial 14 finished with value: 0.10614087837878643 and parameters: {'n_estimators': 135, 'learning_rate': 0.07401190678354544, 'num_leaves': 60, 'max_depth': 8, 'min_child_samples': 24, 'subsample': 0.7624382760320699, 'colsample_bytree': 0.7916814805927617, 'reg_alpha': 4.924248855295427e-07, 'reg_lambda': 0.004661611903823707}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:10,271] Trial 15 finished with value: 0.0937366340284372 and parameters: {'n_estimators': 123, 'learning_rate': 0.07750251245401836, 'num_leaves': 50, 'max_depth': 4, 'min_child_samples': 11, 'subsample': 0.5867402729132272, 'colsample_bytree': 0.904292162592518, 'reg_alpha': 1.1591459000752675e-05, 'reg_lambda': 0.01231997246706534}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:13,113] Trial 16 finished with value: 0.0936086365026148 and parameters: {'n_estimators': 295, 'learning_rate': 0.03636732824303673, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 10, 'subsample': 0.5739360833100207, 'colsample_bytree': 0.9192664584994179, 'reg_alpha': 1.952683364322041e-05, 'reg_lambda': 0.029407444657507414}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:17,126] Trial 17 finished with value: 0.09699139502136316 and parameters: {'n_estimators': 291, 'learning_rate': 0.028587779920693095, 'num_leaves': 44, 'max_depth': 9, 'min_child_samples': 5, 'subsample': 0.7390223192297776, 'colsample_bytree': 0.6636954074466678, 'reg_alpha': 0.000516470707946152, 'reg_lambda': 0.0684166076560598}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:19,176] Trial 18 finished with value: 0.09412946446691106 and parameters: {'n_estimators': 240, 'learning_rate': 0.13067465089050145, 'num_leaves': 41, 'max_depth': 10, 'min_child_samples': 12, 'subsample': 0.568366009494782, 'colsample_bytree': 0.9340733471319924, 'reg_alpha': 3.658031335943171e-06, 'reg_lambda': 0.00019918879293849947}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:20,467] Trial 19 finished with value: 0.12122190167701145 and parameters: {'n_estimators': 298, 'learning_rate': 0.034075832276532915, 'num_leaves': 51, 'max_depth': 8, 'min_child_samples': 32, 'subsample': 0.6898964174714615, 'colsample_bytree': 0.7791955332257596, 'reg_alpha': 9.156109498871672e-08, 'reg_lambda': 0.021420229376206724}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:21,653] Trial 20 finished with value: 0.10779076072215503 and parameters: {'n_estimators': 217, 'learning_rate': 0.034366516857838994, 'num_leaves': 10, 'max_depth': 10, 'min_child_samples': 22, 'subsample': 0.7839705686743188, 'colsample_bytree': 0.8132304803115259, 'reg_alpha': 7.012949394869894e-05, 'reg_lambda': 0.08297182536001514}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:22,763] Trial 21 finished with value: 0.09385674655283612 and parameters: {'n_estimators': 131, 'learning_rate': 0.1430895393787665, 'num_leaves': 52, 'max_depth': 4, 'min_child_samples': 10, 'subsample': 0.5780575829608208, 'colsample_bytree': 0.9098120957994342, 'reg_alpha': 4.302878094763839e-06, 'reg_lambda': 0.0011912216888952732}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:23,472] Trial 22 finished with value: 0.09411755982984081 and parameters: {'n_estimators': 70, 'learning_rate': 0.12093488315388372, 'num_leaves': 48, 'max_depth': 5, 'min_child_samples': 14, 'subsample': 0.5686642115509539, 'colsample_bytree': 0.9078321069452032, 'reg_alpha': 1.084343580944483e-05, 'reg_lambda': 0.022860073232488076}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:24,043] Trial 23 finished with value: 0.11436756688819172 and parameters: {'n_estimators': 79, 'learning_rate': 0.06304897184983045, 'num_leaves': 39, 'max_depth': 9, 'min_child_samples': 29, 'subsample': 0.6035062963148775, 'colsample_bytree': 0.9427406019157332, 'reg_alpha': 9.317450573828168e-08, 'reg_lambda': 2.667766682229174e-05}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:25,552] Trial 24 finished with value: 0.0941550022084201 and parameters: {'n_estimators': 155, 'learning_rate': 0.049011652879687805, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 7, 'subsample': 0.6920462828620538, 'colsample_bytree': 0.7470774377515658, 'reg_alpha': 0.9980232083245932, 'reg_lambda': 0.003727368355718676}. Best is trial 4 with value: 0.09171297097580035.
[I 2025-04-14 17:45:27,558] A new study created in memory with name: tune-2-LSTM_Baseload-24hr
[I 2025-04-14 17:45:31,840] Trial 0 finished with value: 0.1439313441514969 and parameters: {'n_lstm_layers': 1, 'lstm_units': 37, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2658191902486984, 'dense_units_0': 36, 'dense_dropout_0': 0.42218188109154486, 'dense_units_1': 16, 'dense_dropout_1': 0.3927490459310997, 'learning_rate': 0.008283492547862426}. Best is trial 0 with value: 0.1439313441514969.
[I 2025-04-14 17:45:36,378] Trial 1 finished with value: 0.22385750710964203 and parameters: {'n_lstm_layers': 1, 'lstm_units': 40, 'n_dense_layers': 1, 'lstm_dropout_0': 0.39274013782628436, 'dense_units_0': 52, 'dense_dropout_0': 0.13111402216765955, 'learning_rate': 0.0001824220339157156}. Best is trial 0 with value: 0.1439313441514969.
[I 2025-04-14 17:45:41,371] Trial 2 finished with value: 0.1378708928823471 and parameters: {'n_lstm_layers': 1, 'lstm_units': 39, 'n_dense_layers': 2, 'lstm_dropout_0': 0.15383282969727252, 'dense_units_0': 40, 'dense_dropout_0': 0.32366512379582885, 'dense_units_1': 56, 'dense_dropout_1': 0.33319791786863606, 'learning_rate': 0.000955744457754963}. Best is trial 2 with value: 0.1378708928823471.
[I 2025-04-14 17:45:48,706] Trial 3 finished with value: 0.12155192345380783 and parameters: {'n_lstm_layers': 2, 'lstm_units': 48, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4609781283755191, 'lstm_dropout_1': 0.24371218115893256, 'dense_units_0': 43, 'dense_dropout_0': 0.14419588347355616, 'learning_rate': 0.0012848218842512577}. Best is trial 3 with value: 0.12155192345380783.
Trial 1: Validation Score (mae, scaled) = 0.073243

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.084914

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.062981

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.080819

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.134350

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.065963

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.063203

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.122463

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.067984

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.060030

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.062684

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.062336

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.060395

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.059979

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.061018

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.061990

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.117873

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.061417

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.064074

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.069819

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.060463

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.059903

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.060680

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.061083

--- Best Results for Feeder=1, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.059903
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 79
  n_dense_layers: 0
  lstm_dropout_0: 0.10039998011565632
  lstm_dropout_1: 0.3146228283196653
  learning_rate: 0.005853592387776404

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=1, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 1, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=1, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=1, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 2 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 144, Version: v1.1_Final_Forecasting_20250414170337, Path Info: models/feeder_2/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170337.pkl
Loading artifact(s) based on path info: models/feeder_2/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170337.pkl
Detected single pickle artifact path: models/feeder_2/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170337.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170337.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170337.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.229918

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.120656

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.222566

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.190627

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.091713

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.097628

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.183875

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.098671

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.200289

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.191638

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.096498

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.097245

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.095107

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.094911

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
[I 2025-04-14 17:45:53,127] Trial 4 finished with value: 0.1217370480298996 and parameters: {'n_lstm_layers': 1, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10584294827135068, 'learning_rate': 0.0010052241773662912}. Best is trial 3 with value: 0.12155192345380783.
[I 2025-04-14 17:45:58,096] Trial 5 finished with value: 0.11334704607725143 and parameters: {'n_lstm_layers': 1, 'lstm_units': 107, 'n_dense_layers': 0, 'lstm_dropout_0': 0.25021881001490986, 'learning_rate': 0.0026066536076162833}. Best is trial 5 with value: 0.11334704607725143.
[I 2025-04-14 17:46:02,828] Trial 6 finished with value: 0.21865347027778625 and parameters: {'n_lstm_layers': 1, 'lstm_units': 51, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3236504828190959, 'learning_rate': 0.0001249718152445332}. Best is trial 5 with value: 0.11334704607725143.
[I 2025-04-14 17:46:07,734] Trial 7 finished with value: 0.2866261303424835 and parameters: {'n_lstm_layers': 1, 'lstm_units': 128, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3506603437986091, 'dense_units_0': 49, 'dense_dropout_0': 0.33587842003975826, 'learning_rate': 0.00013413176391371232}. Best is trial 5 with value: 0.11334704607725143.
[I 2025-04-14 17:46:15,102] Trial 8 finished with value: 0.24909432232379913 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 2, 'lstm_dropout_0': 0.37022906510206843, 'lstm_dropout_1': 0.13556588731854435, 'dense_units_0': 46, 'dense_dropout_0': 0.4056635803201961, 'dense_units_1': 39, 'dense_dropout_1': 0.29314549247641036, 'learning_rate': 0.00027246355673097363}. Best is trial 5 with value: 0.11334704607725143.
[I 2025-04-14 17:46:19,949] Trial 9 finished with value: 0.15891186892986298 and parameters: {'n_lstm_layers': 1, 'lstm_units': 42, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4502299908625086, 'dense_units_0': 18, 'dense_dropout_0': 0.38559208676670154, 'learning_rate': 0.001218822449165379}. Best is trial 5 with value: 0.11334704607725143.
[I 2025-04-14 17:46:26,951] Trial 10 finished with value: 0.1126064583659172 and parameters: {'n_lstm_layers': 2, 'lstm_units': 101, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2315464283289544, 'lstm_dropout_1': 0.4991283504101151, 'learning_rate': 0.006987867761678907}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:46:34,103] Trial 11 finished with value: 0.11375751346349716 and parameters: {'n_lstm_layers': 2, 'lstm_units': 103, 'n_dense_layers': 0, 'lstm_dropout_0': 0.23119479447149124, 'lstm_dropout_1': 0.4915940196558129, 'learning_rate': 0.008011975319195968}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:46:41,205] Trial 12 finished with value: 0.11518163979053497 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20832999783914224, 'lstm_dropout_1': 0.4955566949270846, 'learning_rate': 0.003695237582470118}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:46:48,484] Trial 13 finished with value: 0.11566521972417831 and parameters: {'n_lstm_layers': 2, 'lstm_units': 83, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1807660248263982, 'lstm_dropout_1': 0.3538802276699298, 'learning_rate': 0.0036209860049377747}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:46:56,051] Trial 14 finished with value: 0.117941714823246 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2793349178395465, 'lstm_dropout_1': 0.36292597231456936, 'learning_rate': 0.003543872469323572}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:47:03,326] Trial 15 finished with value: 0.11759983748197556 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2399083920375626, 'lstm_dropout_1': 0.40670532325856357, 'learning_rate': 0.002348293279012204}. Best is trial 10 with value: 0.1126064583659172.
[I 2025-04-14 17:47:11,221] Trial 16 finished with value: 0.10089866071939468 and parameters: {'n_lstm_layers': 2, 'lstm_units': 92, 'n_dense_layers': 1, 'lstm_dropout_0': 0.29777493411700545, 'lstm_dropout_1': 0.24045226694478883, 'dense_units_0': 20, 'dense_dropout_0': 0.2390892086324524, 'learning_rate': 0.005842769995302442}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:18,939] Trial 17 finished with value: 0.10581321269273758 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3103779185513257, 'lstm_dropout_1': 0.23861493560790253, 'dense_units_0': 21, 'dense_dropout_0': 0.22766788993609632, 'learning_rate': 0.005685401596510169}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:26,473] Trial 18 finished with value: 0.1642455756664276 and parameters: {'n_lstm_layers': 2, 'lstm_units': 69, 'n_dense_layers': 1, 'lstm_dropout_0': 0.32818692099449337, 'lstm_dropout_1': 0.22049026417983958, 'dense_units_0': 21, 'dense_dropout_0': 0.22714494452848805, 'learning_rate': 0.0005014968153650127}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:34,292] Trial 19 finished with value: 0.10372818261384964 and parameters: {'n_lstm_layers': 2, 'lstm_units': 85, 'n_dense_layers': 1, 'lstm_dropout_0': 0.40100641248571606, 'lstm_dropout_1': 0.20982141302360924, 'dense_units_0': 26, 'dense_dropout_0': 0.23462180393022564, 'learning_rate': 0.005389338792046183}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:41,832] Trial 20 finished with value: 0.11616112291812897 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4128352566782352, 'lstm_dropout_1': 0.1464047321818322, 'dense_units_0': 27, 'dense_dropout_0': 0.23607849471824893, 'learning_rate': 0.0018813364261176576}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:49,392] Trial 21 finished with value: 0.10377170890569687 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3086871235980241, 'lstm_dropout_1': 0.2304846965402999, 'dense_units_0': 25, 'dense_dropout_0': 0.23240930254048822, 'learning_rate': 0.005222627954929947}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:47:56,554] Trial 22 finished with value: 0.1130695790052414 and parameters: {'n_lstm_layers': 2, 'lstm_units': 90, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4288974732824919, 'lstm_dropout_1': 0.19952658876956442, 'dense_units_0': 26, 'dense_dropout_0': 0.2594666826592918, 'learning_rate': 0.004740783303027097}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:48:04,107] Trial 23 finished with value: 0.11302535235881805 and parameters: {'n_lstm_layers': 2, 'lstm_units': 76, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3646234130907434, 'lstm_dropout_1': 0.2959499241138117, 'dense_units_0': 28, 'dense_dropout_0': 0.18122318336961277, 'learning_rate': 0.004804051159269475}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:48:11,703] Trial 24 finished with value: 0.1490866094827652 and parameters: {'n_lstm_layers': 2, 'lstm_units': 33, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4909601559658842, 'lstm_dropout_1': 0.28429277960016847, 'dense_units_0': 16, 'dense_dropout_0': 0.4993660492275349, 'dense_units_1': 16, 'dense_dropout_1': 0.14520315882773321, 'learning_rate': 0.009942779201570195}. Best is trial 16 with value: 0.10089866071939468.
[I 2025-04-14 17:48:13,586] A new study created in memory with name: tune-2-LSTM_Change_in_Load-24hr
[I 2025-04-14 17:48:18,656] Trial 0 finished with value: 0.18640269339084625 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 2, 'lstm_dropout_0': 0.48190706192715427, 'dense_units_0': 25, 'dense_dropout_0': 0.3551705104890469, 'dense_units_1': 60, 'dense_dropout_1': 0.41746467134236076, 'learning_rate': 0.0002630263424619593}. Best is trial 0 with value: 0.18640269339084625.
[I 2025-04-14 17:48:23,762] Trial 1 finished with value: 0.22461947798728943 and parameters: {'n_lstm_layers': 1, 'lstm_units': 69, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4932130549183168, 'dense_units_0': 48, 'dense_dropout_0': 0.24023726112419458, 'dense_units_1': 38, 'dense_dropout_1': 0.17378613879855892, 'learning_rate': 0.00010949306321919955}. Best is trial 0 with value: 0.18640269339084625.
[I 2025-04-14 17:48:28,423] Trial 2 finished with value: 0.10896187275648117 and parameters: {'n_lstm_layers': 1, 'lstm_units': 125, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3371248316764799, 'dense_units_0': 40, 'dense_dropout_0': 0.212466672251625, 'dense_units_1': 27, 'dense_dropout_1': 0.3778387258529722, 'learning_rate': 0.0015546476520602618}. Best is trial 2 with value: 0.10896187275648117.
[I 2025-04-14 17:48:36,408] Trial 3 finished with value: 0.09098302572965622 and parameters: {'n_lstm_layers': 2, 'lstm_units': 70, 'n_dense_layers': 2, 'lstm_dropout_0': 0.19799375289953522, 'lstm_dropout_1': 0.3582077556465366, 'dense_units_0': 29, 'dense_dropout_0': 0.33924327683099015, 'dense_units_1': 37, 'dense_dropout_1': 0.12096250731489887, 'learning_rate': 0.008237582303230502}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:48:44,106] Trial 4 finished with value: 0.19246305525302887 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1730002871770641, 'lstm_dropout_1': 0.30509076085781106, 'dense_units_0': 27, 'dense_dropout_0': 0.3031902653761292, 'dense_units_1': 22, 'dense_dropout_1': 0.3049623450702771, 'learning_rate': 0.0003127370922220586}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:48:51,696] Trial 5 finished with value: 0.12929663062095642 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1630679585996652, 'lstm_dropout_1': 0.38132605210257187, 'dense_units_0': 28, 'dense_dropout_0': 0.4670988254041477, 'dense_units_1': 25, 'dense_dropout_1': 0.4774897825187425, 'learning_rate': 0.0008816762528272634}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:48:56,734] Trial 6 finished with value: 0.11460712552070618 and parameters: {'n_lstm_layers': 1, 'lstm_units': 78, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2726510231145728, 'dense_units_0': 38, 'dense_dropout_0': 0.22721528144031056, 'learning_rate': 0.0005817627112262716}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:04,145] Trial 7 finished with value: 0.1018579974770546 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.14607702896229952, 'lstm_dropout_1': 0.32584800796202584, 'dense_units_0': 22, 'dense_dropout_0': 0.4709877259512756, 'learning_rate': 0.00286422097024353}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:11,998] Trial 8 finished with value: 0.1959446221590042 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 1, 'lstm_dropout_0': 0.23686874760780371, 'lstm_dropout_1': 0.1826439707685415, 'dense_units_0': 34, 'dense_dropout_0': 0.32893040571751875, 'learning_rate': 0.00015432127915417456}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:19,801] Trial 9 finished with value: 0.1112213134765625 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3761722343915008, 'lstm_dropout_1': 0.22431450921746704, 'dense_units_0': 60, 'dense_dropout_0': 0.3610486899263834, 'dense_units_1': 22, 'dense_dropout_1': 0.2966504819340027, 'learning_rate': 0.0006228104896702795}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:27,115] Trial 10 finished with value: 0.09426725655794144 and parameters: {'n_lstm_layers': 2, 'lstm_units': 49, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10066228562220424, 'lstm_dropout_1': 0.4994072350969723, 'learning_rate': 0.009194531472465333}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:33,903] Trial 11 finished with value: 0.0926666259765625 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.11126802466562981, 'lstm_dropout_1': 0.4924017606283002, 'learning_rate': 0.009909161426480823}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:40,858] Trial 12 finished with value: 0.09914595633745193 and parameters: {'n_lstm_layers': 2, 'lstm_units': 54, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2271335656204579, 'lstm_dropout_1': 0.4999230287225116, 'learning_rate': 0.008368765508891833}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:47,874] Trial 13 finished with value: 0.09272334724664688 and parameters: {'n_lstm_layers': 2, 'lstm_units': 52, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10905518040130341, 'lstm_dropout_1': 0.39969558882705836, 'learning_rate': 0.003974575909742869}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:49:54,769] Trial 14 finished with value: 0.09399296343326569 and parameters: {'n_lstm_layers': 2, 'lstm_units': 93, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20385102845836295, 'lstm_dropout_1': 0.41841238995676083, 'learning_rate': 0.004078205555716414}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:50:02,159] Trial 15 finished with value: 0.0934901311993599 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2784203243617744, 'lstm_dropout_1': 0.12526834101309087, 'dense_units_0': 18, 'dense_dropout_0': 0.1402205801870126, 'learning_rate': 0.005587383159934564}. Best is trial 3 with value: 0.09098302572965622.
Trial 14: Validation Score (mae, scaled) = 0.106141

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.093737

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.093609

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.096991

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.094129

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.121222

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.107791

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.093857

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.094118

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.114368

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.094155

--- Best Results for Feeder=2, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.091713
Best Hyperparameters:
  n_estimators: 73
  learning_rate: 0.16494242595095507
  num_leaves: 49
  max_depth: 3
  min_child_samples: 14
  subsample: 0.5988240151343207
  colsample_bytree: 0.8013284743960083
  reg_alpha: 2.0251231679776354e-08
  reg_lambda: 0.0009687043359664956

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=2, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=2, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=2, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 145, Version: v1.1_Final_Forecasting_20250414170340, Path Info: {"keras_model": "models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340.keras", "scalers_pkl": "models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340.keras', 'scalers_pkl': 'models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340_scalers.pkl'}
Detected separate Keras model (models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340.keras) and scalers (models/feeder_2/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170340_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.143931

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.223858

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.137871

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.121552

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
[I 2025-04-14 17:50:09,767] Trial 16 finished with value: 0.11145603656768799 and parameters: {'n_lstm_layers': 2, 'lstm_units': 62, 'n_dense_layers': 1, 'lstm_dropout_0': 0.14780071984005455, 'lstm_dropout_1': 0.4410416577398951, 'dense_units_0': 17, 'dense_dropout_0': 0.41805417568854464, 'learning_rate': 0.0017193607366546224}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:50:14,677] Trial 17 finished with value: 0.09369222819805145 and parameters: {'n_lstm_layers': 1, 'lstm_units': 61, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40908888389999887, 'learning_rate': 0.0020494787675419566}. Best is trial 3 with value: 0.09098302572965622.
[I 2025-04-14 17:50:22,205] Trial 18 finished with value: 0.08597281575202942 and parameters: {'n_lstm_layers': 2, 'lstm_units': 98, 'n_dense_layers': 1, 'lstm_dropout_0': 0.20042059664590312, 'lstm_dropout_1': 0.26169928068784837, 'dense_units_0': 50, 'dense_dropout_0': 0.12236734149397777, 'learning_rate': 0.005711374221914915}. Best is trial 18 with value: 0.08597281575202942.
[I 2025-04-14 17:50:30,020] Trial 19 finished with value: 0.08479864150285721 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 1, 'lstm_dropout_0': 0.31919056548067415, 'lstm_dropout_1': 0.2566754956483025, 'dense_units_0': 64, 'dense_dropout_0': 0.10831157130924224, 'learning_rate': 0.0054834224985391014}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:50:34,986] Trial 20 finished with value: 0.091105617582798 and parameters: {'n_lstm_layers': 1, 'lstm_units': 103, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3264770875693302, 'dense_units_0': 59, 'dense_dropout_0': 0.14433996980437971, 'learning_rate': 0.004741296464120098}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:50:42,066] Trial 21 finished with value: 0.08880908787250519 and parameters: {'n_lstm_layers': 2, 'lstm_units': 101, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26074203419062303, 'lstm_dropout_1': 0.24405775401873964, 'dense_units_0': 50, 'dense_dropout_0': 0.1109970656226386, 'learning_rate': 0.00623487158938037}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:50:49,837] Trial 22 finished with value: 0.09127993881702423 and parameters: {'n_lstm_layers': 2, 'lstm_units': 106, 'n_dense_layers': 1, 'lstm_dropout_0': 0.25622114934382495, 'lstm_dropout_1': 0.24581420693016148, 'dense_units_0': 50, 'dense_dropout_0': 0.10168610380767841, 'learning_rate': 0.0028681304957933777}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:50:56,563] Trial 23 finished with value: 0.09565691649913788 and parameters: {'n_lstm_layers': 2, 'lstm_units': 92, 'n_dense_layers': 1, 'lstm_dropout_0': 0.31997403938427715, 'lstm_dropout_1': 0.24455163142750366, 'dense_units_0': 64, 'dense_dropout_0': 0.10082228507470956, 'learning_rate': 0.0059997682572679265}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:51:04,266] Trial 24 finished with value: 0.09122106432914734 and parameters: {'n_lstm_layers': 2, 'lstm_units': 107, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3569075492661033, 'lstm_dropout_1': 0.19642382982368706, 'dense_units_0': 49, 'dense_dropout_0': 0.16636878220807894, 'learning_rate': 0.002835230387149298}. Best is trial 19 with value: 0.08479864150285721.
[I 2025-04-14 17:51:05,540] A new study created in memory with name: tune-3-LightGBM_Baseline-24hr
[I 2025-04-14 17:51:09,696] Trial 0 finished with value: 0.04965568091106576 and parameters: {'n_estimators': 126, 'learning_rate': 0.02559299480398126, 'num_leaves': 40, 'max_depth': 5, 'min_child_samples': 37, 'subsample': 0.6560469515552267, 'colsample_bytree': 0.7180648439725924, 'reg_alpha': 0.00013630142248478597, 'reg_lambda': 4.674217405878829e-08}. Best is trial 0 with value: 0.04965568091106576.
[I 2025-04-14 17:51:10,491] Trial 1 finished with value: 0.048753479307145214 and parameters: {'n_estimators': 114, 'learning_rate': 0.03244857152521878, 'num_leaves': 57, 'max_depth': 10, 'min_child_samples': 20, 'subsample': 0.7127685235954886, 'colsample_bytree': 0.5597874513052898, 'reg_alpha': 0.0076153203904857905, 'reg_lambda': 4.8167718444907585e-05}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:10,851] Trial 2 finished with value: 0.06160499322057362 and parameters: {'n_estimators': 60, 'learning_rate': 0.0027647007326880775, 'num_leaves': 50, 'max_depth': 11, 'min_child_samples': 35, 'subsample': 0.9341561650959479, 'colsample_bytree': 0.7843362379775035, 'reg_alpha': 0.012984778614960247, 'reg_lambda': 0.015284976332301274}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:12,299] Trial 3 finished with value: 0.04912331362601898 and parameters: {'n_estimators': 287, 'learning_rate': 0.012024342929984576, 'num_leaves': 32, 'max_depth': 6, 'min_child_samples': 24, 'subsample': 0.8474101343714213, 'colsample_bytree': 0.7470915779604632, 'reg_alpha': 0.000996026350793915, 'reg_lambda': 0.003331681603836727}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:12,977] Trial 4 finished with value: 0.04891620083604231 and parameters: {'n_estimators': 163, 'learning_rate': 0.08855736399268384, 'num_leaves': 57, 'max_depth': 7, 'min_child_samples': 40, 'subsample': 0.9753467206577957, 'colsample_bytree': 0.8267336041566742, 'reg_alpha': 0.012374492414753937, 'reg_lambda': 1.058344134042464e-07}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:13,724] Trial 5 finished with value: 0.05133966944261873 and parameters: {'n_estimators': 171, 'learning_rate': 0.010542508096010993, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 32, 'subsample': 0.6837638700545403, 'colsample_bytree': 0.8385344263836554, 'reg_alpha': 6.436393881657304e-07, 'reg_lambda': 2.0228796934153085e-05}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:14,293] Trial 6 finished with value: 0.059589238438298005 and parameters: {'n_estimators': 125, 'learning_rate': 0.002427372141318852, 'num_leaves': 58, 'max_depth': 8, 'min_child_samples': 41, 'subsample': 0.7810734802070759, 'colsample_bytree': 0.6477932601390215, 'reg_alpha': 1.4710678090223653e-06, 'reg_lambda': 1.1706671154491802e-07}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:16,189] Trial 7 finished with value: 0.05950597543887359 and parameters: {'n_estimators': 286, 'learning_rate': 0.0010127833489290117, 'num_leaves': 12, 'max_depth': 9, 'min_child_samples': 17, 'subsample': 0.6776166520922056, 'colsample_bytree': 0.5194944077626461, 'reg_alpha': 0.001219104942728549, 'reg_lambda': 2.6112702838445182e-05}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:17,524] Trial 8 finished with value: 0.05620969934114184 and parameters: {'n_estimators': 241, 'learning_rate': 0.0024579229042198314, 'num_leaves': 30, 'max_depth': 9, 'min_child_samples': 21, 'subsample': 0.9973664532286105, 'colsample_bytree': 0.7718205086962501, 'reg_alpha': 0.007671309823032007, 'reg_lambda': 0.000496401499369658}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:18,215] Trial 9 finished with value: 0.06112895549319328 and parameters: {'n_estimators': 156, 'learning_rate': 0.001209134883616583, 'num_leaves': 52, 'max_depth': 9, 'min_child_samples': 40, 'subsample': 0.9294101292682616, 'colsample_bytree': 0.8151960241472145, 'reg_alpha': 0.21756098338378863, 'reg_lambda': 1.0289859641346133e-05}. Best is trial 1 with value: 0.048753479307145214.
[I 2025-04-14 17:51:18,844] Trial 10 finished with value: 0.04794830380050464 and parameters: {'n_estimators': 60, 'learning_rate': 0.21536600748058388, 'num_leaves': 44, 'max_depth': 3, 'min_child_samples': 6, 'subsample': 0.5149124220004353, 'colsample_bytree': 0.9769862349681175, 'reg_alpha': 1.608709878285765e-08, 'reg_lambda': 0.207055538327243}. Best is trial 10 with value: 0.04794830380050464.
[I 2025-04-14 17:51:19,487] Trial 11 finished with value: 0.04779301877523554 and parameters: {'n_estimators': 56, 'learning_rate': 0.2529123409929625, 'num_leaves': 43, 'max_depth': 3, 'min_child_samples': 5, 'subsample': 0.5216162127787921, 'colsample_bytree': 0.9733744070601357, 'reg_alpha': 4.404260154360035e-08, 'reg_lambda': 0.293391060646091}. Best is trial 11 with value: 0.04779301877523554.
[I 2025-04-14 17:51:20,086] Trial 12 finished with value: 0.047900923883371214 and parameters: {'n_estimators': 58, 'learning_rate': 0.2712392842226386, 'num_leaves': 42, 'max_depth': 3, 'min_child_samples': 6, 'subsample': 0.5020113051396848, 'colsample_bytree': 0.986588207724165, 'reg_alpha': 2.8162998205761242e-08, 'reg_lambda': 0.7908028878375639}. Best is trial 11 with value: 0.04779301877523554.
[I 2025-04-14 17:51:20,794] Trial 13 finished with value: 0.04971368892259979 and parameters: {'n_estimators': 83, 'learning_rate': 0.2866777319573619, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 6, 'subsample': 0.5097834301943922, 'colsample_bytree': 0.9814845403620069, 'reg_alpha': 1.3053941893668475e-08, 'reg_lambda': 0.8490088310415558}. Best is trial 11 with value: 0.04779301877523554.
[I 2025-04-14 17:51:22,404] Trial 14 finished with value: 0.04770320990498255 and parameters: {'n_estimators': 226, 'learning_rate': 0.09366857168798846, 'num_leaves': 22, 'max_depth': 4, 'min_child_samples': 14, 'subsample': 0.5830621047879283, 'colsample_bytree': 0.9101315943483237, 'reg_alpha': 1.1797219423663298e-06, 'reg_lambda': 0.048441450491068364}. Best is trial 14 with value: 0.04770320990498255.
[I 2025-04-14 17:51:24,377] Trial 15 finished with value: 0.047145095795558374 and parameters: {'n_estimators': 223, 'learning_rate': 0.06856482671559008, 'num_leaves': 21, 'max_depth': 5, 'min_child_samples': 13, 'subsample': 0.5829821236998173, 'colsample_bytree': 0.9072033258167731, 'reg_alpha': 1.4896384584284221e-06, 'reg_lambda': 0.024113614875541957}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:26,124] Trial 16 finished with value: 0.04774146034295252 and parameters: {'n_estimators': 223, 'learning_rate': 0.07107531695180656, 'num_leaves': 19, 'max_depth': 5, 'min_child_samples': 14, 'subsample': 0.5966104481807946, 'colsample_bytree': 0.8995275849044362, 'reg_alpha': 7.496857587751424e-06, 'reg_lambda': 0.013293985720797343}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:26,976] Trial 17 finished with value: 0.05067084077675923 and parameters: {'n_estimators': 224, 'learning_rate': 0.0793522625814878, 'num_leaves': 22, 'max_depth': 5, 'min_child_samples': 49, 'subsample': 0.5977908051928346, 'colsample_bytree': 0.8987528478202531, 'reg_alpha': 5.421161926428712e-07, 'reg_lambda': 0.03416981021157951}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:28,995] Trial 18 finished with value: 0.04740086109819314 and parameters: {'n_estimators': 252, 'learning_rate': 0.043919086500439124, 'num_leaves': 12, 'max_depth': 4, 'min_child_samples': 13, 'subsample': 0.6054910444375006, 'colsample_bytree': 0.9002461347643711, 'reg_alpha': 1.4949891744545218e-05, 'reg_lambda': 0.0017131354562762813}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:31,418] Trial 19 finished with value: 0.047236555607043484 and parameters: {'n_estimators': 256, 'learning_rate': 0.039879959330519285, 'num_leaves': 13, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.7549302357383822, 'colsample_bytree': 0.6679510866141299, 'reg_alpha': 1.8647371986488487e-05, 'reg_lambda': 0.0005940485788836323}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:32,396] Trial 20 finished with value: 0.05174215690379208 and parameters: {'n_estimators': 198, 'learning_rate': 0.007511575353343239, 'num_leaves': 17, 'max_depth': 6, 'min_child_samples': 29, 'subsample': 0.7853304628088088, 'colsample_bytree': 0.6660801750471509, 'reg_alpha': 8.275878916802446e-05, 'reg_lambda': 0.0002251572009802294}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:34,663] Trial 21 finished with value: 0.04736034703141756 and parameters: {'n_estimators': 258, 'learning_rate': 0.04155349204222502, 'num_leaves': 10, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.7441044089362382, 'colsample_bytree': 0.6252545753562541, 'reg_alpha': 2.1946839615634688e-05, 'reg_lambda': 0.00308642291482003}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:37,102] Trial 22 finished with value: 0.04734516133126396 and parameters: {'n_estimators': 267, 'learning_rate': 0.04883210927656652, 'num_leaves': 10, 'max_depth': 6, 'min_child_samples': 9, 'subsample': 0.8310532019243833, 'colsample_bytree': 0.6039332603759655, 'reg_alpha': 1.9304480509666114e-05, 'reg_lambda': 2.2180698291851903e-06}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:39,584] Trial 23 finished with value: 0.04749487556418088 and parameters: {'n_estimators': 268, 'learning_rate': 0.018884806261042515, 'num_leaves': 16, 'max_depth': 7, 'min_child_samples': 11, 'subsample': 0.8481937176789819, 'colsample_bytree': 0.586335651375878, 'reg_alpha': 5.5303054257942364e-06, 'reg_lambda': 2.7588973199861413e-06}. Best is trial 15 with value: 0.047145095795558374.
[I 2025-04-14 17:51:41,560] Trial 24 finished with value: 0.04819289746287867 and parameters: {'n_estimators': 196, 'learning_rate': 0.1263667041834071, 'num_leaves': 25, 'max_depth': 6, 'min_child_samples': 10, 'subsample': 0.8273935841654902, 'colsample_bytree': 0.6867955424073064, 'reg_alpha': 0.00012008851003988364, 'reg_lambda': 8.51429189141433e-07}. Best is trial 15 with value: 0.047145095795558374.
Trial 4: Validation Score (mae, scaled) = 0.121737

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.113347

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.218653

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.286626

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.249094

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.158912

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.112606

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.113758

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.115182

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.115665

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.117942

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.117600

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.100899

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.105813

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.164246

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.103728

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.116161

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.103772

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.113070

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.113025

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.149087

--- Best Results for Feeder=2, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.100899
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 92
  n_dense_layers: 1
  lstm_dropout_0: 0.29777493411700545
  lstm_dropout_1: 0.24045226694478883
  dense_units_0: 20
  dense_dropout_0: 0.2390892086324524
  learning_rate: 0.005842769995302442

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=2, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=2, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 146, Version: v1.1_Final_Forecasting_20250414170350, Path Info: {"keras_model": "models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350.keras", "scalers_pkl": "models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350.keras', 'scalers_pkl': 'models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350_scalers.pkl'}
Detected separate Keras model (models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350.keras) and scalers (models/feeder_2/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170350_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.186403

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.224619

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.108962

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.090983

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.192463

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.129297

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.114607

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.101858

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.195945

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.111221

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.094267

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.092667

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.099146

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.092723

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.093993

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.093490

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...[I 2025-04-14 17:51:44,941] A new study created in memory with name: tune-3-LSTM_Baseload-24hr
[I 2025-04-14 17:51:49,902] Trial 0 finished with value: 0.0765526071190834 and parameters: {'n_lstm_layers': 1, 'lstm_units': 58, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2593707244949722, 'dense_units_0': 32, 'dense_dropout_0': 0.344612502156762, 'dense_units_1': 39, 'dense_dropout_1': 0.1531717760518912, 'learning_rate': 0.0003141695038334125}. Best is trial 0 with value: 0.0765526071190834.
[I 2025-04-14 17:51:55,066] Trial 1 finished with value: 0.1272897720336914 and parameters: {'n_lstm_layers': 1, 'lstm_units': 116, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1206716199390578, 'dense_units_0': 57, 'dense_dropout_0': 0.11327749659332853, 'dense_units_1': 23, 'dense_dropout_1': 0.3271344899532034, 'learning_rate': 0.0001507279144384034}. Best is trial 0 with value: 0.0765526071190834.
[I 2025-04-14 17:52:02,265] Trial 2 finished with value: 0.12358853965997696 and parameters: {'n_lstm_layers': 2, 'lstm_units': 97, 'n_dense_layers': 1, 'lstm_dropout_0': 0.430579340246371, 'lstm_dropout_1': 0.10572466448678597, 'dense_units_0': 21, 'dense_dropout_0': 0.24173863009426155, 'learning_rate': 0.0001668863921193942}. Best is trial 0 with value: 0.0765526071190834.
[I 2025-04-14 17:52:09,685] Trial 3 finished with value: 0.058056168258190155 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3065296130910681, 'lstm_dropout_1': 0.2009795898196957, 'dense_units_0': 29, 'dense_dropout_0': 0.23069408565500835, 'dense_units_1': 40, 'dense_dropout_1': 0.22249675487718573, 'learning_rate': 0.001652594653320424}. Best is trial 3 with value: 0.058056168258190155.
[I 2025-04-14 17:52:16,783] Trial 4 finished with value: 0.06646381318569183 and parameters: {'n_lstm_layers': 2, 'lstm_units': 52, 'n_dense_layers': 0, 'lstm_dropout_0': 0.31862413837214243, 'lstm_dropout_1': 0.4028971971414773, 'learning_rate': 0.00030824254161438726}. Best is trial 3 with value: 0.058056168258190155.
[I 2025-04-14 17:52:24,364] Trial 5 finished with value: 0.08903960883617401 and parameters: {'n_lstm_layers': 2, 'lstm_units': 120, 'n_dense_layers': 2, 'lstm_dropout_0': 0.18469532821529955, 'lstm_dropout_1': 0.36619293639563855, 'dense_units_0': 22, 'dense_dropout_0': 0.1250887043867681, 'dense_units_1': 43, 'dense_dropout_1': 0.46419687527656084, 'learning_rate': 0.0003436037014763251}. Best is trial 3 with value: 0.058056168258190155.
[I 2025-04-14 17:52:28,669] Trial 6 finished with value: 0.05361509695649147 and parameters: {'n_lstm_layers': 1, 'lstm_units': 70, 'n_dense_layers': 0, 'lstm_dropout_0': 0.494957108791353, 'learning_rate': 0.007510391505539189}. Best is trial 6 with value: 0.05361509695649147.
[I 2025-04-14 17:52:32,769] Trial 7 finished with value: 0.0561872236430645 and parameters: {'n_lstm_layers': 1, 'lstm_units': 89, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20994840139152995, 'learning_rate': 0.0019168070932699267}. Best is trial 6 with value: 0.05361509695649147.
[I 2025-04-14 17:52:39,983] Trial 8 finished with value: 0.10387089848518372 and parameters: {'n_lstm_layers': 2, 'lstm_units': 92, 'n_dense_layers': 1, 'lstm_dropout_0': 0.289747442481173, 'lstm_dropout_1': 0.1344870427457491, 'dense_units_0': 27, 'dense_dropout_0': 0.48227028486650325, 'learning_rate': 0.00029164005314364673}. Best is trial 6 with value: 0.05361509695649147.
[I 2025-04-14 17:52:46,448] Trial 9 finished with value: 0.054430972784757614 and parameters: {'n_lstm_layers': 2, 'lstm_units': 114, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1751942944667922, 'lstm_dropout_1': 0.14399895651278585, 'dense_units_0': 36, 'dense_dropout_0': 0.33837509747490563, 'learning_rate': 0.009781894692397299}. Best is trial 6 with value: 0.05361509695649147.
[I 2025-04-14 17:52:50,430] Trial 10 finished with value: 0.056120067834854126 and parameters: {'n_lstm_layers': 1, 'lstm_units': 41, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49583924597820755, 'learning_rate': 0.009161192180323}. Best is trial 6 with value: 0.05361509695649147.
[I 2025-04-14 17:52:55,251] Trial 11 finished with value: 0.053224772214889526 and parameters: {'n_lstm_layers': 1, 'lstm_units': 73, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3728473852130089, 'dense_units_0': 47, 'dense_dropout_0': 0.3847274684317129, 'learning_rate': 0.008504021355281777}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:52:59,180] Trial 12 finished with value: 0.057361066341400146 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4002906831592256, 'learning_rate': 0.004192314887349906}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:03,659] Trial 13 finished with value: 0.054022349417209625 and parameters: {'n_lstm_layers': 1, 'lstm_units': 65, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4992286472903188, 'dense_units_0': 55, 'dense_dropout_0': 0.45878923458403903, 'learning_rate': 0.004150926170160678}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:07,610] Trial 14 finished with value: 0.05725695937871933 and parameters: {'n_lstm_layers': 1, 'lstm_units': 74, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3941443430245511, 'learning_rate': 0.004178581277342826}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:12,419] Trial 15 finished with value: 0.06347048282623291 and parameters: {'n_lstm_layers': 1, 'lstm_units': 48, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4417141991811425, 'dense_units_0': 43, 'dense_dropout_0': 0.40213356807866635, 'learning_rate': 0.0010155653354267783}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:15,734] Trial 16 finished with value: 0.05892118811607361 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3675862468486055, 'learning_rate': 0.005916663168712089}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:20,147] Trial 17 finished with value: 0.06179671734571457 and parameters: {'n_lstm_layers': 1, 'lstm_units': 64, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3515753217035035, 'dense_units_0': 16, 'dense_dropout_0': 0.26185087350558184, 'learning_rate': 0.0021594692907117015}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:24,872] Trial 18 finished with value: 0.06721962988376617 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 1, 'lstm_dropout_0': 0.446527446733902, 'dense_units_0': 45, 'dense_dropout_0': 0.40508631330567674, 'learning_rate': 0.0007095039845958852}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:29,110] Trial 19 finished with value: 0.05722618103027344 and parameters: {'n_lstm_layers': 1, 'lstm_units': 86, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4667715913108437, 'learning_rate': 0.005827028165381529}. Best is trial 11 with value: 0.053224772214889526.

Trial 16: Validation Score (mae, scaled) = 0.111456

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.093692

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.085973

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.084799

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.091106

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.088809

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.091280

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.095657

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.091221

--- Best Results for Feeder=2, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.084799
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 100
  n_dense_layers: 1
  lstm_dropout_0: 0.31919056548067415
  lstm_dropout_1: 0.2566754956483025
  dense_units_0: 64
  dense_dropout_0: 0.10831157130924224
  learning_rate: 0.0054834224985391014

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=2, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 2, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=2, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=2, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 3 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 148, Version: v1.1_Final_Forecasting_20250414170405, Path Info: models/feeder_3/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170405.pkl
Loading artifact(s) based on path info: models/feeder_3/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170405.pkl
Detected single pickle artifact path: models/feeder_3/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170405.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170405.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170405.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.049656

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.048753

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.061605

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.049123

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.048916

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.051340

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.059589

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.059506

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.056210

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.061129

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.047948

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.047793

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.047901

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.049714

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.047703

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.047145

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.047741

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.050671

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.047401

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.047237

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.051742

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.047360

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.047345

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.047495

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.048193

--- Best Results for Feeder=3, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.047145
Best Hyperparameters:
  n_estimators: 223
  learning_rate: 0.06856482671559008
  num_leaves: 21
  max_depth: 5
  min_child_samples: 13
[I 2025-04-14 17:53:33,246] Trial 20 finished with value: 0.05511754751205444 and parameters: {'n_lstm_layers': 1, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2517728420350636, 'dense_units_0': 64, 'dense_dropout_0': 0.19371641485709967, 'learning_rate': 0.002978751239685945}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:37,686] Trial 21 finished with value: 0.05440990626811981 and parameters: {'n_lstm_layers': 1, 'lstm_units': 66, 'n_dense_layers': 1, 'lstm_dropout_0': 0.491021929641484, 'dense_units_0': 48, 'dense_dropout_0': 0.49209378108562735, 'learning_rate': 0.006631757660451084}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:42,048] Trial 22 finished with value: 0.055351220071315765 and parameters: {'n_lstm_layers': 1, 'lstm_units': 68, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4104953168292835, 'dense_units_0': 54, 'dense_dropout_0': 0.4213192940287616, 'learning_rate': 0.0036241595527738454}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:46,107] Trial 23 finished with value: 0.06368362903594971 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 2, 'lstm_dropout_0': 0.49769944436182945, 'dense_units_0': 38, 'dense_dropout_0': 0.4452397191199861, 'dense_units_1': 16, 'dense_dropout_1': 0.4895326219817201, 'learning_rate': 0.0068789661179436785}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:50,575] Trial 24 finished with value: 0.05602114647626877 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 1, 'lstm_dropout_0': 0.36496750192499927, 'dense_units_0': 53, 'dense_dropout_0': 0.35474593121248865, 'learning_rate': 0.0028184311636754874}. Best is trial 11 with value: 0.053224772214889526.
[I 2025-04-14 17:53:52,651] A new study created in memory with name: tune-3-LSTM_Change_in_Load-24hr
[I 2025-04-14 17:53:57,456] Trial 0 finished with value: 0.048619113862514496 and parameters: {'n_lstm_layers': 1, 'lstm_units': 106, 'n_dense_layers': 2, 'lstm_dropout_0': 0.224872131637592, 'dense_units_0': 59, 'dense_dropout_0': 0.16488458519661486, 'dense_units_1': 24, 'dense_dropout_1': 0.43241864400490493, 'learning_rate': 0.0013446315886841}. Best is trial 0 with value: 0.048619113862514496.
[I 2025-04-14 17:54:04,594] Trial 1 finished with value: 0.04676440358161926 and parameters: {'n_lstm_layers': 2, 'lstm_units': 84, 'n_dense_layers': 1, 'lstm_dropout_0': 0.11770619554909466, 'lstm_dropout_1': 0.2195583513648831, 'dense_units_0': 29, 'dense_dropout_0': 0.2197876541786779, 'learning_rate': 0.0020792315257988753}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:09,722] Trial 2 finished with value: 0.14473748207092285 and parameters: {'n_lstm_layers': 1, 'lstm_units': 115, 'n_dense_layers': 2, 'lstm_dropout_0': 0.21061459374170166, 'dense_units_0': 50, 'dense_dropout_0': 0.485569919658168, 'dense_units_1': 26, 'dense_dropout_1': 0.12481014923166348, 'learning_rate': 0.00016006379161032878}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:13,564] Trial 3 finished with value: 0.059517811983823776 and parameters: {'n_lstm_layers': 1, 'lstm_units': 35, 'n_dense_layers': 0, 'lstm_dropout_0': 0.16153157942835775, 'learning_rate': 0.0006000568970958033}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:18,092] Trial 4 finished with value: 0.049311257898807526 and parameters: {'n_lstm_layers': 1, 'lstm_units': 36, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2568239090277512, 'learning_rate': 0.0017046462561140204}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:25,347] Trial 5 finished with value: 0.19139021635055542 and parameters: {'n_lstm_layers': 2, 'lstm_units': 40, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3524599026225633, 'lstm_dropout_1': 0.163544467622233, 'dense_units_0': 16, 'dense_dropout_0': 0.38289722721204467, 'dense_units_1': 38, 'dense_dropout_1': 0.38063989606139825, 'learning_rate': 0.0001870812643265775}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:29,658] Trial 6 finished with value: 0.049758829176425934 and parameters: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4515689937426045, 'learning_rate': 0.0015134028031581937}. Best is trial 1 with value: 0.04676440358161926.
[I 2025-04-14 17:54:36,577] Trial 7 finished with value: 0.04669523984193802 and parameters: {'n_lstm_layers': 2, 'lstm_units': 98, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3134648773385953, 'lstm_dropout_1': 0.3406482569491852, 'dense_units_0': 52, 'dense_dropout_0': 0.4382279340235842, 'learning_rate': 0.0019571603820659647}. Best is trial 7 with value: 0.04669523984193802.
[I 2025-04-14 17:54:43,415] Trial 8 finished with value: 0.045438461005687714 and parameters: {'n_lstm_layers': 2, 'lstm_units': 99, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4697552948415591, 'lstm_dropout_1': 0.15422906776756104, 'dense_units_0': 25, 'dense_dropout_0': 0.14613632006201846, 'dense_units_1': 61, 'dense_dropout_1': 0.49004996966238556, 'learning_rate': 0.0028657223637856585}. Best is trial 8 with value: 0.045438461005687714.
[I 2025-04-14 17:54:50,270] Trial 9 finished with value: 0.04527979716658592 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3563482998650518, 'lstm_dropout_1': 0.2296013864939691, 'learning_rate': 0.004131767404512714}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:54:56,667] Trial 10 finished with value: 0.04536386579275131 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 0, 'lstm_dropout_0': 0.38654055304154644, 'lstm_dropout_1': 0.4988343436378009, 'learning_rate': 0.00986598391782636}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:03,364] Trial 11 finished with value: 0.045368045568466187 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3923303734378563, 'lstm_dropout_1': 0.4779138642038021, 'learning_rate': 0.009993348920828524}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:09,672] Trial 12 finished with value: 0.046076223254203796 and parameters: {'n_lstm_layers': 2, 'lstm_units': 62, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3984473009405575, 'lstm_dropout_1': 0.3125365757201983, 'dense_units_0': 16, 'dense_dropout_0': 0.303850773923627, 'learning_rate': 0.009383964513922717}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:15,987] Trial 13 finished with value: 0.04533674567937851 and parameters: {'n_lstm_layers': 2, 'lstm_units': 50, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32941403965566046, 'lstm_dropout_1': 0.48734169192937016, 'learning_rate': 0.004626255556956728}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:22,233] Trial 14 finished with value: 0.04557986557483673 and parameters: {'n_lstm_layers': 2, 'lstm_units': 46, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3032434318644351, 'lstm_dropout_1': 0.39315823057809873, 'learning_rate': 0.0043363619395779835}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:29,172] Trial 15 finished with value: 0.05998215824365616 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3273138253802329, 'lstm_dropout_1': 0.24404412591245458, 'dense_units_0': 38, 'dense_dropout_0': 0.30089495477524153, 'learning_rate': 0.0007080344719958371}. Best is trial 9 with value: 0.04527979716658592.
[I 2025-04-14 17:55:36,394] Trial 16 finished with value: 0.04508097097277641 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2674524414312311, 'lstm_dropout_1': 0.10002270904965499, 'learning_rate': 0.004524347631653716}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:55:43,031] Trial 17 finished with value: 0.046332377940416336 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2616129492143574, 'lstm_dropout_1': 0.10132949703563206, 'dense_units_0': 23, 'dense_dropout_0': 0.22346421994993806, 'learning_rate': 0.0051741165426529186}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:55:50,083] Trial 18 finished with value: 0.051665760576725006 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.26584353300632774, 'lstm_dropout_1': 0.10085817508378753, 'learning_rate': 0.0003295082161370516}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:55:56,764] Trial 19 finished with value: 0.04569569602608681 and parameters: {'n_lstm_layers': 2, 'lstm_units': 71, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4295478036239053, 'lstm_dropout_1': 0.2563970303124201, 'learning_rate': 0.0029533982290627613}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:56:01,162] Trial 20 finished with value: 0.050059061497449875 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.19388359134447924, 'dense_units_0': 41, 'dense_dropout_0': 0.3624469003573317, 'learning_rate': 0.0008592307378867801}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:56:08,029] Trial 21 finished with value: 0.045195478945970535 and parameters: {'n_lstm_layers': 2, 'lstm_units': 49, 'n_dense_layers': 0, 'lstm_dropout_0': 0.36203868295293834, 'lstm_dropout_1': 0.4143596958321133, 'learning_rate': 0.0051879382411484}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:56:14,571] Trial 22 finished with value: 0.0454573817551136 and parameters: {'n_lstm_layers': 2, 'lstm_units': 49, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3547221883566788, 'lstm_dropout_1': 0.4080271262243595, 'learning_rate': 0.0062762733736991825}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:56:21,870] Trial 23 finished with value: 0.045321062207221985 and parameters: {'n_lstm_layers': 2, 'lstm_units': 61, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2856242612061995, 'lstm_dropout_1': 0.18662758885155617, 'learning_rate': 0.0031440727367013136}. Best is trial 16 with value: 0.04508097097277641.
[I 2025-04-14 17:56:29,064] Trial 24 finished with value: 0.04528135806322098 and parameters: {'n_lstm_layers': 2, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3697719058482063, 'lstm_dropout_1': 0.37036829436994445, 'learning_rate': 0.006357433980944923}. Best is trial 16 with value: 0.04508097097277641.
  subsample: 0.5829821236998173
  colsample_bytree: 0.9072033258167731
  reg_alpha: 1.4896384584284221e-06
  reg_lambda: 0.024113614875541957

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=3, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=3, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=3, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 149, Version: v1.1_Final_Forecasting_20250414170409, Path Info: {"keras_model": "models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409.keras", "scalers_pkl": "models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409.keras', 'scalers_pkl': 'models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409_scalers.pkl'}
Detected separate Keras model (models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409.keras) and scalers (models/feeder_3/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170409_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.076553

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.127290

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.123589

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.058056

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.066464

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.089040

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.053615

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.056187

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.103871

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.054431

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.056120

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.053225

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.057361

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.054022

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.057257

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.063470

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.058921

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.061797

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.067220

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.057226
[I 2025-04-14 17:56:29,966] A new study created in memory with name: tune-4-LightGBM_Baseline-24hr
[I 2025-04-14 17:56:30,763] Trial 0 finished with value: 0.19927490308638607 and parameters: {'n_estimators': 173, 'learning_rate': 0.012294735850954877, 'num_leaves': 45, 'max_depth': 5, 'min_child_samples': 31, 'subsample': 0.741636731365251, 'colsample_bytree': 0.7415162239181319, 'reg_alpha': 0.011356688609484704, 'reg_lambda': 0.0033582076994081765}. Best is trial 0 with value: 0.19927490308638607.
[I 2025-04-14 17:56:31,425] Trial 1 finished with value: 0.20281094388333484 and parameters: {'n_estimators': 88, 'learning_rate': 0.019371052875162775, 'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 29, 'subsample': 0.822835560680786, 'colsample_bytree': 0.8152942563384624, 'reg_alpha': 7.798539057995337e-08, 'reg_lambda': 0.00012018995797952776}. Best is trial 0 with value: 0.19927490308638607.
[I 2025-04-14 17:56:32,857] Trial 2 finished with value: 0.2767602664193734 and parameters: {'n_estimators': 241, 'learning_rate': 0.0013312729958918417, 'num_leaves': 31, 'max_depth': 8, 'min_child_samples': 16, 'subsample': 0.6709260683048152, 'colsample_bytree': 0.5076354472747551, 'reg_alpha': 5.1171565116619895e-06, 'reg_lambda': 1.9605238506510782e-08}. Best is trial 0 with value: 0.19927490308638607.
[I 2025-04-14 17:56:34,078] Trial 3 finished with value: 0.1814901561689032 and parameters: {'n_estimators': 264, 'learning_rate': 0.13706306478377003, 'num_leaves': 32, 'max_depth': 3, 'min_child_samples': 20, 'subsample': 0.7750832995280661, 'colsample_bytree': 0.8301244815381548, 'reg_alpha': 0.005498580615046728, 'reg_lambda': 1.2344656614838719e-08}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:35,644] Trial 4 finished with value: 0.18613847792269947 and parameters: {'n_estimators': 144, 'learning_rate': 0.2610243958889865, 'num_leaves': 15, 'max_depth': 10, 'min_child_samples': 9, 'subsample': 0.8269747824573004, 'colsample_bytree': 0.7433803260519242, 'reg_alpha': 0.29274529438496755, 'reg_lambda': 2.1071434082937962e-07}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:36,301] Trial 5 finished with value: 0.18606582336253163 and parameters: {'n_estimators': 171, 'learning_rate': 0.06537438250039719, 'num_leaves': 25, 'max_depth': 4, 'min_child_samples': 39, 'subsample': 0.6868852900163203, 'colsample_bytree': 0.6367481146732992, 'reg_alpha': 5.753130203874825e-07, 'reg_lambda': 1.8269717297087582e-05}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:36,630] Trial 6 finished with value: 0.26878154387663367 and parameters: {'n_estimators': 65, 'learning_rate': 0.03995092483713419, 'num_leaves': 14, 'max_depth': 4, 'min_child_samples': 46, 'subsample': 0.9919958607102084, 'colsample_bytree': 0.73282331915938, 'reg_alpha': 0.0008146934542887219, 'reg_lambda': 0.005460192790689091}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:38,477] Trial 7 finished with value: 0.18594589308324916 and parameters: {'n_estimators': 279, 'learning_rate': 0.022620473828641043, 'num_leaves': 24, 'max_depth': 10, 'min_child_samples': 14, 'subsample': 0.8510019825030901, 'colsample_bytree': 0.5300025498348067, 'reg_alpha': 8.745924048098801e-06, 'reg_lambda': 0.013572450576242442}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:39,528] Trial 8 finished with value: 0.18295584969862344 and parameters: {'n_estimators': 245, 'learning_rate': 0.10030229581875628, 'num_leaves': 13, 'max_depth': 6, 'min_child_samples': 30, 'subsample': 0.8856856760830452, 'colsample_bytree': 0.7874166137341887, 'reg_alpha': 0.09335263730525543, 'reg_lambda': 0.16703763266894261}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:39,919] Trial 9 finished with value: 0.264018461671311 and parameters: {'n_estimators': 92, 'learning_rate': 0.04974123640783147, 'num_leaves': 30, 'max_depth': 4, 'min_child_samples': 48, 'subsample': 0.5660222658174794, 'colsample_bytree': 0.7788617872483026, 'reg_alpha': 5.412705430067716e-07, 'reg_lambda': 0.5816084833180356}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:41,432] Trial 10 finished with value: 0.2046545458693918 and parameters: {'n_estimators': 298, 'learning_rate': 0.004932150048269499, 'num_leaves': 58, 'max_depth': 8, 'min_child_samples': 22, 'subsample': 0.5521609069485586, 'colsample_bytree': 0.9806615787262365, 'reg_alpha': 0.0015955929560039271, 'reg_lambda': 9.393984284143949e-07}. Best is trial 3 with value: 0.1814901561689032.
[I 2025-04-14 17:56:42,690] Trial 11 finished with value: 0.1805710277800642 and parameters: {'n_estimators': 236, 'learning_rate': 0.2891874557120938, 'num_leaves': 43, 'max_depth': 6, 'min_child_samples': 23, 'subsample': 0.9266744852958987, 'colsample_bytree': 0.9014508188889362, 'reg_alpha': 0.9153281537337985, 'reg_lambda': 0.45567184251439646}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:43,920] Trial 12 finished with value: 0.18382113255748403 and parameters: {'n_estimators': 245, 'learning_rate': 0.2836591941490602, 'num_leaves': 44, 'max_depth': 3, 'min_child_samples': 21, 'subsample': 0.9882117684825517, 'colsample_bytree': 0.9214390842679514, 'reg_alpha': 0.5178269510427332, 'reg_lambda': 7.20153642812139e-05}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:46,910] Trial 13 finished with value: 0.18766484292512575 and parameters: {'n_estimators': 211, 'learning_rate': 0.1403696778549827, 'num_leaves': 43, 'max_depth': 7, 'min_child_samples': 5, 'subsample': 0.9326452988830971, 'colsample_bytree': 0.8665401480923285, 'reg_alpha': 0.017892150005754278, 'reg_lambda': 2.4685772262810978e-06}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:48,027] Trial 14 finished with value: 0.1849627484334373 and parameters: {'n_estimators': 209, 'learning_rate': 0.157572991194352, 'num_leaves': 52, 'max_depth': 3, 'min_child_samples': 22, 'subsample': 0.7506830201937942, 'colsample_bytree': 0.8906793449864214, 'reg_alpha': 0.00026325655808984063, 'reg_lambda': 1.570843923191658e-08}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:49,127] Trial 15 finished with value: 0.1826738232370564 and parameters: {'n_estimators': 269, 'learning_rate': 0.2962029070513608, 'num_leaves': 38, 'max_depth': 6, 'min_child_samples': 36, 'subsample': 0.9148186208531224, 'colsample_bytree': 0.9949963494364038, 'reg_alpha': 0.013930119447545151, 'reg_lambda': 0.0005742918821638336}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:50,717] Trial 16 finished with value: 0.20187999707852158 and parameters: {'n_estimators': 215, 'learning_rate': 0.007311582383815892, 'num_leaves': 39, 'max_depth': 12, 'min_child_samples': 16, 'subsample': 0.7641267660638091, 'colsample_bytree': 0.8432349133848118, 'reg_alpha': 4.5969750415124096e-05, 'reg_lambda': 0.130557382829953}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:51,584] Trial 17 finished with value: 0.18377296110311425 and parameters: {'n_estimators': 136, 'learning_rate': 0.09341133806905277, 'num_leaves': 51, 'max_depth': 9, 'min_child_samples': 23, 'subsample': 0.6237124505269694, 'colsample_bytree': 0.6823117941207815, 'reg_alpha': 0.06271736900132026, 'reg_lambda': 8.282388636611294e-06}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:52,844] Trial 18 finished with value: 0.18510925846182977 and parameters: {'n_estimators': 297, 'learning_rate': 0.03134389942893662, 'num_leaves': 22, 'max_depth': 6, 'min_child_samples': 36, 'subsample': 0.7993770322071643, 'colsample_bytree': 0.9211144096109799, 'reg_alpha': 0.9636606456737905, 'reg_lambda': 1.4438762290446405e-07}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:55,456] Trial 19 finished with value: 0.18515733880327345 and parameters: {'n_estimators': 268, 'learning_rate': 0.1670947102401374, 'num_leaves': 50, 'max_depth': 7, 'min_child_samples': 11, 'subsample': 0.9374330643736583, 'colsample_bytree': 0.9261026252157366, 'reg_alpha': 0.0018933803342363832, 'reg_lambda': 0.032305652764704935}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:56,599] Trial 20 finished with value: 0.2858336352741185 and parameters: {'n_estimators': 223, 'learning_rate': 0.0010993621323568028, 'num_leaves': 60, 'max_depth': 3, 'min_child_samples': 26, 'subsample': 0.8638036497612268, 'colsample_bytree': 0.639080186722518, 'reg_alpha': 0.08107099328620361, 'reg_lambda': 0.0008208020334860657}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:57,769] Trial 21 finished with value: 0.18415630613199552 and parameters: {'n_estimators': 263, 'learning_rate': 0.29912018209066715, 'num_leaves': 37, 'max_depth': 6, 'min_child_samples': 37, 'subsample': 0.9180854380954468, 'colsample_bytree': 0.9852587908019357, 'reg_alpha': 0.008021332179978144, 'reg_lambda': 0.00046566418128543324}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:56:58,895] Trial 22 finished with value: 0.18373394716090985 and parameters: {'n_estimators': 275, 'learning_rate': 0.17786161734489705, 'num_leaves': 37, 'max_depth': 5, 'min_child_samples': 42, 'subsample': 0.8876514889023616, 'colsample_bytree': 0.9675601983708292, 'reg_alpha': 0.0066101025360592175, 'reg_lambda': 0.0008794318624082515}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:57:00,029] Trial 23 finished with value: 0.18218583712921385 and parameters: {'n_estimators': 192, 'learning_rate': 0.10043856026756995, 'num_leaves': 40, 'max_depth': 7, 'min_child_samples': 26, 'subsample': 0.9478635921825117, 'colsample_bytree': 0.8806946092652737, 'reg_alpha': 9.829464734575768e-05, 'reg_lambda': 0.6885819565048951}. Best is trial 11 with value: 0.1805710277800642.
[I 2025-04-14 17:57:01,387] Trial 24 finished with value: 0.1838060637382415 and parameters: {'n_estimators': 193, 'learning_rate': 0.07850657671971363, 'num_leaves': 28, 'max_depth': 9, 'min_child_samples': 18, 'subsample': 0.9646162608843553, 'colsample_bytree': 0.8440112438159499, 'reg_alpha': 6.64931900319882e-05, 'reg_lambda': 0.9121940092633462}. Best is trial 11 with value: 0.1805710277800642.

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.055118

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.054410

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.055351

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.063684

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.056021

--- Best Results for Feeder=3, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.053225
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 73
  n_dense_layers: 1
  lstm_dropout_0: 0.3728473852130089
  dense_units_0: 47
  dense_dropout_0: 0.3847274684317129
  learning_rate: 0.008504021355281777

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=3, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=3, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 150, Version: v1.1_Final_Forecasting_20250414170417, Path Info: {"keras_model": "models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417.keras", "scalers_pkl": "models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417.keras', 'scalers_pkl': 'models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417_scalers.pkl'}
Detected separate Keras model (models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417.keras) and scalers (models/feeder_3/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170417_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.048619

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.046764

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.144737

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.059518

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.049311

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.191390

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.049759

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.046695

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.045438

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.045280

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.045364

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.045368

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.046076

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.045337

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.045580

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.059982

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.045081

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.046332

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.051666

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.045696

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.050059

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.045195

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.045457

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.045321

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.045281

--- Best Results for Feeder=3, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.045081
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 47
  n_dense_layers: 0
  lstm_dropout_0: 0.2674524414312311
  lstm_dropout_1: 0.10002270904965499
  learning_rate: 0.004524347631653716

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=3, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
[I 2025-04-14 17:57:05,088] A new study created in memory with name: tune-4-LSTM_Baseload-24hr
[I 2025-04-14 17:57:11,357] Trial 0 finished with value: 0.2658168077468872 and parameters: {'n_lstm_layers': 2, 'lstm_units': 96, 'n_dense_layers': 0, 'lstm_dropout_0': 0.471545809200255, 'lstm_dropout_1': 0.2865546002096333, 'learning_rate': 0.0007404588169270818}. Best is trial 0 with value: 0.2658168077468872.
[I 2025-04-14 17:57:19,175] Trial 1 finished with value: 0.26580941677093506 and parameters: {'n_lstm_layers': 2, 'lstm_units': 91, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2792279479018405, 'lstm_dropout_1': 0.3236650996333833, 'learning_rate': 0.00017501452119969102}. Best is trial 1 with value: 0.26580941677093506.
[I 2025-04-14 17:57:24,218] Trial 2 finished with value: 0.36886662244796753 and parameters: {'n_lstm_layers': 1, 'lstm_units': 64, 'n_dense_layers': 1, 'lstm_dropout_0': 0.37399609270976963, 'dense_units_0': 16, 'dense_dropout_0': 0.24966587882632052, 'learning_rate': 0.00025439297108192623}. Best is trial 1 with value: 0.26580941677093506.
[I 2025-04-14 17:57:28,833] Trial 3 finished with value: 0.16781757771968842 and parameters: {'n_lstm_layers': 1, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3590813858165105, 'dense_units_0': 31, 'dense_dropout_0': 0.21284717344122217, 'learning_rate': 0.006903839646376025}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:57:35,432] Trial 4 finished with value: 0.2326744645833969 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3272889213892224, 'lstm_dropout_1': 0.27161414296323405, 'dense_units_0': 28, 'dense_dropout_0': 0.48815338169148503, 'dense_units_1': 51, 'dense_dropout_1': 0.4366308916994456, 'learning_rate': 0.005436078801657627}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:57:43,088] Trial 5 finished with value: 0.17155636847019196 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 2, 'lstm_dropout_0': 0.16223841799398966, 'lstm_dropout_1': 0.33712479895594855, 'dense_units_0': 36, 'dense_dropout_0': 0.13964108833140654, 'dense_units_1': 25, 'dense_dropout_1': 0.29621167314792435, 'learning_rate': 0.003566763427797038}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:57:48,166] Trial 6 finished with value: 0.49353936314582825 and parameters: {'n_lstm_layers': 1, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.12782559741719127, 'dense_units_0': 24, 'dense_dropout_0': 0.36906594702236195, 'learning_rate': 0.00010819099438068342}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:57:55,879] Trial 7 finished with value: 0.26926612854003906 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3157552373011431, 'lstm_dropout_1': 0.30165854250949076, 'dense_units_0': 38, 'dense_dropout_0': 0.2471125994114478, 'learning_rate': 0.00027688412272739154}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:03,297] Trial 8 finished with value: 0.28858739137649536 and parameters: {'n_lstm_layers': 2, 'lstm_units': 67, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17891083390912024, 'lstm_dropout_1': 0.45675536224255686, 'learning_rate': 0.00019411717877185016}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:07,088] Trial 9 finished with value: 0.241171732544899 and parameters: {'n_lstm_layers': 1, 'lstm_units': 125, 'n_dense_layers': 2, 'lstm_dropout_0': 0.11913322447163709, 'dense_units_0': 22, 'dense_dropout_0': 0.4189358268369908, 'dense_units_1': 61, 'dense_dropout_1': 0.13078639039852585, 'learning_rate': 0.007139023580108519}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:11,471] Trial 10 finished with value: 0.19558608531951904 and parameters: {'n_lstm_layers': 1, 'lstm_units': 35, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4807533504359094, 'dense_units_0': 61, 'dense_dropout_0': 0.1397800241330075, 'learning_rate': 0.0019786550829338106}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:16,219] Trial 11 finished with value: 0.18644186854362488 and parameters: {'n_lstm_layers': 1, 'lstm_units': 123, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2149247015737533, 'dense_units_0': 41, 'dense_dropout_0': 0.10273433708696358, 'dense_units_1': 18, 'dense_dropout_1': 0.2897177336429681, 'learning_rate': 0.0028205019473088624}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:20,878] Trial 12 finished with value: 0.21689681708812714 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 2, 'lstm_dropout_0': 0.410954760716427, 'dense_units_0': 38, 'dense_dropout_0': 0.19034011245582794, 'dense_units_1': 24, 'dense_dropout_1': 0.29204536679167703, 'learning_rate': 0.00892926762184159}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:28,625] Trial 13 finished with value: 0.17086762189865112 and parameters: {'n_lstm_layers': 2, 'lstm_units': 101, 'n_dense_layers': 1, 'lstm_dropout_0': 0.25098978399347144, 'lstm_dropout_1': 0.10033713486903217, 'dense_units_0': 56, 'dense_dropout_0': 0.20277888891773016, 'learning_rate': 0.0032358804481415547}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:36,174] Trial 14 finished with value: 0.17091704905033112 and parameters: {'n_lstm_layers': 2, 'lstm_units': 103, 'n_dense_layers': 1, 'lstm_dropout_0': 0.25267908405617967, 'lstm_dropout_1': 0.10545220199343047, 'dense_units_0': 58, 'dense_dropout_0': 0.3024208587700649, 'learning_rate': 0.0013822777878874106}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:40,994] Trial 15 finished with value: 0.18181711435317993 and parameters: {'n_lstm_layers': 1, 'lstm_units': 109, 'n_dense_layers': 1, 'lstm_dropout_0': 0.36418164438391837, 'dense_units_0': 48, 'dense_dropout_0': 0.21260759623373038, 'learning_rate': 0.0007236775560426284}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:45,928] Trial 16 finished with value: 0.16843606531620026 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.24544662483452312, 'learning_rate': 0.004073039859149476}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:50,406] Trial 17 finished with value: 0.18069809675216675 and parameters: {'n_lstm_layers': 1, 'lstm_units': 35, 'n_dense_layers': 0, 'lstm_dropout_0': 0.416683004909571, 'learning_rate': 0.0048577740089396125}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:54,612] Trial 18 finished with value: 0.18067613244056702 and parameters: {'n_lstm_layers': 1, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.22166848501017755, 'learning_rate': 0.0098533204817497}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:58:59,353] Trial 19 finished with value: 0.17257286608219147 and parameters: {'n_lstm_layers': 1, 'lstm_units': 52, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3380771961592547, 'learning_rate': 0.001723855240903172}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:59:03,912] Trial 20 finished with value: 0.17593905329704285 and parameters: {'n_lstm_layers': 1, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.28587411673726254, 'learning_rate': 0.0010028264801904914}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:59:10,477] Trial 21 finished with value: 0.2104509025812149 and parameters: {'n_lstm_layers': 2, 'lstm_units': 71, 'n_dense_layers': 1, 'lstm_dropout_0': 0.24089769625787183, 'lstm_dropout_1': 0.12151398893622112, 'dense_units_0': 29, 'dense_dropout_0': 0.30754810534197813, 'learning_rate': 0.002889960804567493}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:59:14,384] Trial 22 finished with value: 0.17475885152816772 and parameters: {'n_lstm_layers': 1, 'lstm_units': 90, 'n_dense_layers': 1, 'lstm_dropout_0': 0.18999477996477573, 'dense_units_0': 50, 'dense_dropout_0': 0.18790409813627945, 'learning_rate': 0.005153260149481194}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:59:19,330] Trial 23 finished with value: 0.17411307990550995 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2689579770110725, 'dense_units_0': 20, 'dense_dropout_0': 0.2559913871525643, 'learning_rate': 0.003896893013531558}. Best is trial 3 with value: 0.16781757771968842.
[I 2025-04-14 17:59:25,841] Trial 24 finished with value: 0.21686333417892456 and parameters: {'n_lstm_layers': 2, 'lstm_units': 110, 'n_dense_layers': 1, 'lstm_dropout_0': 0.37310395367579496, 'lstm_dropout_1': 0.20443347782063723, 'dense_units_0': 31, 'dense_dropout_0': 0.3452743721836845, 'learning_rate': 0.002247660137101923}. Best is trial 3 with value: 0.16781757771968842.
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 3, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=3, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=3, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 4 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 152, Version: v1.1_Final_Forecasting_20250414170431, Path Info: models/feeder_4/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170431.pkl
Loading artifact(s) based on path info: models/feeder_4/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170431.pkl
Detected single pickle artifact path: models/feeder_4/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170431.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170431.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170431.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (29, 177), y shape (29, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.199275

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.202811

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.276760

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.181490

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.186138

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.186066

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.268782

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.185946

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.182956

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.264018

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.204655

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.180571

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.183821

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.187665

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.184963

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.182674

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.201880

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.183773

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.185109

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.185157

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.285834

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.184156

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.183734

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.182186

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.183806

--- Best Results for Feeder=4, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.180571
Best Hyperparameters:
  n_estimators: 236
  learning_rate: 0.2891874557120938
  num_leaves: 43
  max_depth: 6
  min_child_samples: 23
  subsample: 0.9266744852958987
  colsample_bytree: 0.9014508188889362
  reg_alpha: 0.9153281537337985
  reg_lambda: 0.45567184251439646

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=4, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=4, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Baseload, Scenario: Night, Version: None
[I 2025-04-14 17:59:28,203] A new study created in memory with name: tune-4-LSTM_Change_in_Load-24hr
[I 2025-04-14 17:59:35,964] Trial 0 finished with value: 0.18883422017097473 and parameters: {'n_lstm_layers': 2, 'lstm_units': 99, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1711172871832638, 'lstm_dropout_1': 0.23974259550244015, 'dense_units_0': 51, 'dense_dropout_0': 0.16369421713044688, 'learning_rate': 0.0001288059278531982}. Best is trial 0 with value: 0.18883422017097473.
[I 2025-04-14 17:59:43,848] Trial 1 finished with value: 0.32494744658470154 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 2, 'lstm_dropout_0': 0.10134156957405804, 'lstm_dropout_1': 0.2510611553111178, 'dense_units_0': 29, 'dense_dropout_0': 0.44082327470732596, 'dense_units_1': 18, 'dense_dropout_1': 0.23115346119640445, 'learning_rate': 0.00012224537389140503}. Best is trial 0 with value: 0.18883422017097473.
[I 2025-04-14 17:59:47,807] Trial 2 finished with value: 0.14254294335842133 and parameters: {'n_lstm_layers': 1, 'lstm_units': 100, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4475992901949488, 'dense_units_0': 17, 'dense_dropout_0': 0.19609142566210466, 'learning_rate': 0.00571810814898635}. Best is trial 2 with value: 0.14254294335842133.
[I 2025-04-14 17:59:55,516] Trial 3 finished with value: 0.12558740377426147 and parameters: {'n_lstm_layers': 2, 'lstm_units': 102, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4781077779777104, 'lstm_dropout_1': 0.2190766355876661, 'learning_rate': 0.00802278581458081}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:00,633] Trial 4 finished with value: 0.36418673396110535 and parameters: {'n_lstm_layers': 1, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.22294144843510472, 'dense_units_0': 36, 'dense_dropout_0': 0.35020110464070275, 'dense_units_1': 20, 'dense_dropout_1': 0.2581896963381548, 'learning_rate': 0.00010996695372417819}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:05,473] Trial 5 finished with value: 0.17265859246253967 and parameters: {'n_lstm_layers': 1, 'lstm_units': 52, 'n_dense_layers': 2, 'lstm_dropout_0': 0.29757252252184446, 'dense_units_0': 23, 'dense_dropout_0': 0.14434163613065812, 'dense_units_1': 26, 'dense_dropout_1': 0.29803486235045107, 'learning_rate': 0.00047115620627259696}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:10,643] Trial 6 finished with value: 0.1359703242778778 and parameters: {'n_lstm_layers': 1, 'lstm_units': 61, 'n_dense_layers': 2, 'lstm_dropout_0': 0.42575436550561496, 'dense_units_0': 20, 'dense_dropout_0': 0.3181510147190344, 'dense_units_1': 19, 'dense_dropout_1': 0.2227951264067901, 'learning_rate': 0.003993226078540213}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:15,629] Trial 7 finished with value: 0.208953395485878 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4086840687935255, 'dense_units_0': 25, 'dense_dropout_0': 0.44954617087167614, 'learning_rate': 0.0003428909233662971}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:23,126] Trial 8 finished with value: 0.20913003385066986 and parameters: {'n_lstm_layers': 2, 'lstm_units': 36, 'n_dense_layers': 1, 'lstm_dropout_0': 0.30730084836350113, 'lstm_dropout_1': 0.1664616764952292, 'dense_units_0': 34, 'dense_dropout_0': 0.20065325967186834, 'learning_rate': 0.00013130644530693968}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:27,999] Trial 9 finished with value: 0.14038138091564178 and parameters: {'n_lstm_layers': 1, 'lstm_units': 85, 'n_dense_layers': 0, 'lstm_dropout_0': 0.479319769557931, 'learning_rate': 0.000794808780078692}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:35,134] Trial 10 finished with value: 0.1270512342453003 and parameters: {'n_lstm_layers': 2, 'lstm_units': 121, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3514712946027312, 'lstm_dropout_1': 0.47384169298356416, 'learning_rate': 0.0023611401693022466}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:42,055] Trial 11 finished with value: 0.12671814858913422 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3567991998946338, 'lstm_dropout_1': 0.4720536218828796, 'learning_rate': 0.002407462250762434}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:49,688] Trial 12 finished with value: 0.1259458363056183 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 0, 'lstm_dropout_0': 0.36887755520674814, 'lstm_dropout_1': 0.4475897908758452, 'learning_rate': 0.002078813957480833}. Best is trial 3 with value: 0.12558740377426147.
[I 2025-04-14 18:00:57,185] Trial 13 finished with value: 0.12377367913722992 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 0, 'lstm_dropout_0': 0.48305198166393737, 'lstm_dropout_1': 0.35685418309562467, 'learning_rate': 0.0087421903775116}. Best is trial 13 with value: 0.12377367913722992.
[I 2025-04-14 18:01:04,413] Trial 14 finished with value: 0.12148760259151459 and parameters: {'n_lstm_layers': 2, 'lstm_units': 83, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4912371753978999, 'lstm_dropout_1': 0.3439956026283413, 'learning_rate': 0.008642039575007658}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:11,457] Trial 15 finished with value: 0.12333600223064423 and parameters: {'n_lstm_layers': 2, 'lstm_units': 81, 'n_dense_layers': 0, 'lstm_dropout_0': 0.47690070754787883, 'lstm_dropout_1': 0.3706025931547165, 'learning_rate': 0.008695082667981923}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:18,789] Trial 16 finished with value: 0.12295418977737427 and parameters: {'n_lstm_layers': 2, 'lstm_units': 81, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40351486728026686, 'lstm_dropout_1': 0.35791169778724036, 'learning_rate': 0.004050523905392589}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:26,428] Trial 17 finished with value: 0.13776347041130066 and parameters: {'n_lstm_layers': 2, 'lstm_units': 48, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3989618697027496, 'lstm_dropout_1': 0.33078236718083137, 'dense_units_0': 63, 'dense_dropout_0': 0.3895441274756626, 'learning_rate': 0.0012929835180384064}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:33,539] Trial 18 finished with value: 0.1262994408607483 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 0, 'lstm_dropout_0': 0.291227101434153, 'lstm_dropout_1': 0.4003429761100298, 'learning_rate': 0.0040902955412715665}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:41,676] Trial 19 finished with value: 0.1221010684967041 and parameters: {'n_lstm_layers': 2, 'lstm_units': 70, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4295520536742931, 'lstm_dropout_1': 0.2884907247330861, 'learning_rate': 0.003948977366703462}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:49,326] Trial 20 finished with value: 0.14071109890937805 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 1, 'lstm_dropout_0': 0.44921941543143484, 'lstm_dropout_1': 0.2923824449356517, 'dense_units_0': 44, 'dense_dropout_0': 0.26307553590045724, 'learning_rate': 0.0013863798543421576}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:01:56,823] Trial 21 finished with value: 0.12244171649217606 and parameters: {'n_lstm_layers': 2, 'lstm_units': 69, 'n_dense_layers': 0, 'lstm_dropout_0': 0.39173981711530004, 'lstm_dropout_1': 0.3015948303119193, 'learning_rate': 0.004017900717438221}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:02:04,240] Trial 22 finished with value: 0.12494344264268875 and parameters: {'n_lstm_layers': 2, 'lstm_units': 67, 'n_dense_layers': 0, 'lstm_dropout_0': 0.44008853935167286, 'lstm_dropout_1': 0.31254132231667414, 'learning_rate': 0.00567330110008373}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:02:11,065] Trial 23 finished with value: 0.12577490508556366 and parameters: {'n_lstm_layers': 2, 'lstm_units': 88, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4995239400413427, 'lstm_dropout_1': 0.2897288951436006, 'learning_rate': 0.005565275686837131}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:02:18,319] Trial 24 finished with value: 0.12465588748455048 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3786172785407973, 'lstm_dropout_1': 0.17560630700568625, 'learning_rate': 0.002964190264334615}. Best is trial 14 with value: 0.12148760259151459.
[I 2025-04-14 18:02:19,420] A new study created in memory with name: tune-5-LightGBM_Baseline-24hr
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=4, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 153, Version: v1.1_Final_Forecasting_20250414170435, Path Info: {"keras_model": "models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435.keras", "scalers_pkl": "models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435.keras', 'scalers_pkl': 'models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435_scalers.pkl'}
Detected separate Keras model (models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435.keras) and scalers (models/feeder_4/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170435_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (29, 177), y shape (29, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.265817

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.265809

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.368867

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.167818

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.232674

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.171556

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.493539

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.269266

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.288587

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.241172

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.195586

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.186442

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.216897

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.170868

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.170917

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.181817

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.168436

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.180698

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.180676

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.172573

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.175939

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.210451

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.174759

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.174113

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.216863

--- Best Results for Feeder=4, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.167818
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 82
  n_dense_layers: 1
  lstm_dropout_0: 0.3590813858165105
  dense_units_0: 31
  dense_dropout_0: 0.21284717344122217
  learning_rate: 0.006903839646376025

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=4, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=4, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
[I 2025-04-14 18:02:23,923] Trial 0 finished with value: 0.12535127566397458 and parameters: {'n_estimators': 225, 'learning_rate': 0.012655819545709598, 'num_leaves': 17, 'max_depth': 9, 'min_child_samples': 19, 'subsample': 0.9853311724632021, 'colsample_bytree': 0.9283740806256735, 'reg_alpha': 0.17851298517225228, 'reg_lambda': 0.15869660977778643}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:24,425] Trial 1 finished with value: 0.16942813438582596 and parameters: {'n_estimators': 124, 'learning_rate': 0.01752490602969578, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 44, 'subsample': 0.6884590964350605, 'colsample_bytree': 0.7056115273857522, 'reg_alpha': 2.686951007115948e-08, 'reg_lambda': 0.00012601652256023587}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:25,374] Trial 2 finished with value: 0.12802718082350353 and parameters: {'n_estimators': 106, 'learning_rate': 0.12951925870919087, 'num_leaves': 11, 'max_depth': 12, 'min_child_samples': 12, 'subsample': 0.594753820191577, 'colsample_bytree': 0.6557879428083672, 'reg_alpha': 0.002015725209795392, 'reg_lambda': 8.562331754935852e-07}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:26,183] Trial 3 finished with value: 0.17748872432031185 and parameters: {'n_estimators': 216, 'learning_rate': 0.006574285503056732, 'num_leaves': 57, 'max_depth': 7, 'min_child_samples': 46, 'subsample': 0.803249178635672, 'colsample_bytree': 0.6971560834094732, 'reg_alpha': 1.1131910623467869e-05, 'reg_lambda': 3.4373911580825324e-08}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:27,120] Trial 4 finished with value: 0.16970502258305728 and parameters: {'n_estimators': 179, 'learning_rate': 0.0033851780881025756, 'num_leaves': 51, 'max_depth': 3, 'min_child_samples': 27, 'subsample': 0.8100188027764974, 'colsample_bytree': 0.558722002381551, 'reg_alpha': 8.831350745003453e-06, 'reg_lambda': 0.005426464402630967}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:28,332] Trial 5 finished with value: 0.13628682326400732 and parameters: {'n_estimators': 219, 'learning_rate': 0.007212890743153144, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 22, 'subsample': 0.9316178083128241, 'colsample_bytree': 0.6734779154121895, 'reg_alpha': 0.00012028016824345735, 'reg_lambda': 1.1055057068446371e-06}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:29,038] Trial 6 finished with value: 0.19370620171858843 and parameters: {'n_estimators': 218, 'learning_rate': 0.002989353856008278, 'num_leaves': 54, 'max_depth': 10, 'min_child_samples': 50, 'subsample': 0.50858101587196, 'colsample_bytree': 0.7037302669218098, 'reg_alpha': 2.5881454773733602e-06, 'reg_lambda': 2.903600142264515e-08}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:29,523] Trial 7 finished with value: 0.20180022981581525 and parameters: {'n_estimators': 121, 'learning_rate': 0.0026934390558994345, 'num_leaves': 20, 'max_depth': 7, 'min_child_samples': 49, 'subsample': 0.6988818293860404, 'colsample_bytree': 0.6754418689978309, 'reg_alpha': 0.0016136155423812626, 'reg_lambda': 2.0548990312190968e-07}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:30,090] Trial 8 finished with value: 0.1287084167347052 and parameters: {'n_estimators': 80, 'learning_rate': 0.2857764356342961, 'num_leaves': 29, 'max_depth': 4, 'min_child_samples': 18, 'subsample': 0.7767492622437732, 'colsample_bytree': 0.7940906276624773, 'reg_alpha': 0.0006339281674977482, 'reg_lambda': 3.5724999753567505e-06}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:30,511] Trial 9 finished with value: 0.2083983780355878 and parameters: {'n_estimators': 57, 'learning_rate': 0.0010476694113701274, 'num_leaves': 11, 'max_depth': 5, 'min_child_samples': 34, 'subsample': 0.7290400136954761, 'colsample_bytree': 0.546972124409101, 'reg_alpha': 4.4662956827818505e-06, 'reg_lambda': 0.000801814099658279}. Best is trial 0 with value: 0.12535127566397458.
[I 2025-04-14 18:02:34,211] Trial 10 finished with value: 0.12280915210331993 and parameters: {'n_estimators': 299, 'learning_rate': 0.0372447781109477, 'num_leaves': 27, 'max_depth': 10, 'min_child_samples': 6, 'subsample': 0.9819728894538458, 'colsample_bytree': 0.9515739032443672, 'reg_alpha': 0.07629500245337609, 'reg_lambda': 0.9332073418930624}. Best is trial 10 with value: 0.12280915210331993.
[I 2025-04-14 18:02:37,674] Trial 11 finished with value: 0.12373979161267269 and parameters: {'n_estimators': 281, 'learning_rate': 0.04377862234460991, 'num_leaves': 28, 'max_depth': 10, 'min_child_samples': 5, 'subsample': 0.9936200391369003, 'colsample_bytree': 0.9829033653320705, 'reg_alpha': 0.7351012150702633, 'reg_lambda': 0.6261785727105698}. Best is trial 10 with value: 0.12280915210331993.
[I 2025-04-14 18:02:41,261] Trial 12 finished with value: 0.12338980249030025 and parameters: {'n_estimators': 285, 'learning_rate': 0.045272087638729815, 'num_leaves': 30, 'max_depth': 11, 'min_child_samples': 5, 'subsample': 0.898939290019514, 'colsample_bytree': 0.9664576327681763, 'reg_alpha': 0.7825003412072545, 'reg_lambda': 0.5867892335992901}. Best is trial 10 with value: 0.12280915210331993.
[I 2025-04-14 18:02:45,436] Trial 13 finished with value: 0.12406103320339418 and parameters: {'n_estimators': 288, 'learning_rate': 0.0546202328013419, 'num_leaves': 38, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.8894131095212268, 'colsample_bytree': 0.8478594880008181, 'reg_alpha': 0.05457169100176897, 'reg_lambda': 0.01860786809350375}. Best is trial 10 with value: 0.12280915210331993.
[I 2025-04-14 18:02:47,648] Trial 14 finished with value: 0.1241916261682018 and parameters: {'n_estimators': 263, 'learning_rate': 0.03862727357728401, 'num_leaves': 28, 'max_depth': 11, 'min_child_samples': 12, 'subsample': 0.8820236550479346, 'colsample_bytree': 0.8973485673320033, 'reg_alpha': 0.015086795892134542, 'reg_lambda': 0.8776401106683456}. Best is trial 10 with value: 0.12280915210331993.
[I 2025-04-14 18:02:50,314] Trial 15 finished with value: 0.12278394645823805 and parameters: {'n_estimators': 300, 'learning_rate': 0.10834825588926199, 'num_leaves': 45, 'max_depth': 10, 'min_child_samples': 11, 'subsample': 0.8788691939078704, 'colsample_bytree': 0.98568776942349, 'reg_alpha': 0.636347899690809, 'reg_lambda': 0.049135787765231205}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:02:52,704] Trial 16 finished with value: 0.12500960389906374 and parameters: {'n_estimators': 250, 'learning_rate': 0.1252090371251902, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 12, 'subsample': 0.8428013643751825, 'colsample_bytree': 0.8458983215706758, 'reg_alpha': 0.010915134145736192, 'reg_lambda': 0.037573826247532624}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:02:53,572] Trial 17 finished with value: 0.12309012365816978 and parameters: {'n_estimators': 160, 'learning_rate': 0.11500308218302749, 'num_leaves': 44, 'max_depth': 9, 'min_child_samples': 32, 'subsample': 0.9459210372886822, 'colsample_bytree': 0.9907406304375315, 'reg_alpha': 0.02885023445441567, 'reg_lambda': 0.0016848128725001712}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:02:56,797] Trial 18 finished with value: 0.12679294656649556 and parameters: {'n_estimators': 300, 'learning_rate': 0.2364277051082563, 'num_leaves': 34, 'max_depth': 10, 'min_child_samples': 10, 'subsample': 0.8583628130680382, 'colsample_bytree': 0.8948367338344089, 'reg_alpha': 0.1070034887100087, 'reg_lambda': 3.807848554499491e-05}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:02:58,416] Trial 19 finished with value: 0.1238807393413703 and parameters: {'n_estimators': 257, 'learning_rate': 0.02301324076183054, 'num_leaves': 23, 'max_depth': 6, 'min_child_samples': 18, 'subsample': 0.9536676735595149, 'colsample_bytree': 0.7843081799920925, 'reg_alpha': 2.0254784001743964e-08, 'reg_lambda': 0.04236229951599453}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:02:59,467] Trial 20 finished with value: 0.12559123824124313 and parameters: {'n_estimators': 183, 'learning_rate': 0.07021063594300866, 'num_leaves': 44, 'max_depth': 8, 'min_child_samples': 23, 'subsample': 0.6314512576600765, 'colsample_bytree': 0.9378374825489894, 'reg_alpha': 2.847780299655135e-07, 'reg_lambda': 0.00022126219297594196}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:03:00,224] Trial 21 finished with value: 0.12312029313450912 and parameters: {'n_estimators': 157, 'learning_rate': 0.10503246944336092, 'num_leaves': 43, 'max_depth': 9, 'min_child_samples': 35, 'subsample': 0.9426334978915639, 'colsample_bytree': 0.996799557683252, 'reg_alpha': 0.015197273634799665, 'reg_lambda': 0.0015770732945670453}. Best is trial 15 with value: 0.12278394645823805.
[I 2025-04-14 18:03:00,964] Trial 22 finished with value: 0.12192878834879757 and parameters: {'n_estimators': 160, 'learning_rate': 0.08104720597193384, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 36, 'subsample': 0.9987047668065785, 'colsample_bytree': 0.938909597553705, 'reg_alpha': 0.21715489940211094, 'reg_lambda': 0.005657074435522317}. Best is trial 22 with value: 0.12192878834879757.
[I 2025-04-14 18:03:01,813] Trial 23 finished with value: 0.12152016150106992 and parameters: {'n_estimators': 196, 'learning_rate': 0.028185632368471845, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 38, 'subsample': 0.9722910966716541, 'colsample_bytree': 0.8527236004809267, 'reg_alpha': 0.2919728256814584, 'reg_lambda': 0.0961960751689055}. Best is trial 23 with value: 0.12152016150106992.
[I 2025-04-14 18:03:02,649] Trial 24 finished with value: 0.12239177253179516 and parameters: {'n_estimators': 195, 'learning_rate': 0.024262591274705585, 'num_leaves': 59, 'max_depth': 11, 'min_child_samples': 39, 'subsample': 0.9222669414462193, 'colsample_bytree': 0.858861696233264, 'reg_alpha': 0.8457592648364314, 'reg_lambda': 0.10377546333429624}. Best is trial 23 with value: 0.12152016150106992.
Selected Model ID: 154, Version: v1.1_Final_Forecasting_20250414170444, Path Info: {"keras_model": "models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444.keras", "scalers_pkl": "models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444.keras', 'scalers_pkl': 'models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444_scalers.pkl'}
Detected separate Keras model (models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444.keras) and scalers (models/feeder_4/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170444_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (29, 177), y shape (29, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.188834

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.324947

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.142543

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.125587

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.364187

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.172659

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.135970

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.208953

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.209130

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.140381

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.127051

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.126718

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.125946

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.123774

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.121488

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.123336

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.122954

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.137763

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.126299

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.122101

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.140711

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.122442

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.124943

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.125775

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.124656

--- Best Results for Feeder=4, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.121488
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 83
  n_dense_layers: 0
  lstm_dropout_0: 0.4912371753978999
  lstm_dropout_1: 0.3439956026283413
  learning_rate: 0.008642039575007658

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=4, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 4, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=4, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=4, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 5 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 156, Version: v1.1_Final_Forecasting_20250414170458, Path Info: models/feeder_5/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170458.pkl
Loading artifact(s) based on path info: models/feeder_5/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170458.pkl
Detected single pickle artifact path: models/feeder_5/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170458.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170458.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170458.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
[I 2025-04-14 18:03:05,388] A new study created in memory with name: tune-5-LSTM_Baseload-24hr
[I 2025-04-14 18:03:09,563] Trial 0 finished with value: 0.15229664742946625 and parameters: {'n_lstm_layers': 1, 'lstm_units': 66, 'n_dense_layers': 2, 'lstm_dropout_0': 0.19116283973199777, 'dense_units_0': 24, 'dense_dropout_0': 0.4381518195329054, 'dense_units_1': 47, 'dense_dropout_1': 0.349699880824903, 'learning_rate': 0.0033523344586069096}. Best is trial 0 with value: 0.15229664742946625.
[I 2025-04-14 18:03:14,031] Trial 1 finished with value: 0.14656701683998108 and parameters: {'n_lstm_layers': 1, 'lstm_units': 33, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2425406603101825, 'dense_units_0': 32, 'dense_dropout_0': 0.37300737115464655, 'learning_rate': 0.0014392978323062094}. Best is trial 1 with value: 0.14656701683998108.
[I 2025-04-14 18:03:21,288] Trial 2 finished with value: 0.19509369134902954 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3046445579483611, 'lstm_dropout_1': 0.3748748832150012, 'learning_rate': 0.00021943162364527206}. Best is trial 1 with value: 0.14656701683998108.
[I 2025-04-14 18:03:28,748] Trial 3 finished with value: 0.2594614326953888 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3538432067182793, 'lstm_dropout_1': 0.31767876728331773, 'dense_units_0': 49, 'dense_dropout_0': 0.17593972066126798, 'dense_units_1': 19, 'dense_dropout_1': 0.24581523588232895, 'learning_rate': 0.00026232933985324266}. Best is trial 1 with value: 0.14656701683998108.
[I 2025-04-14 18:03:36,211] Trial 4 finished with value: 0.1254481077194214 and parameters: {'n_lstm_layers': 2, 'lstm_units': 108, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1702998075739121, 'lstm_dropout_1': 0.2739042036232272, 'learning_rate': 0.0016927465122475217}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:03:40,476] Trial 5 finished with value: 0.14235323667526245 and parameters: {'n_lstm_layers': 1, 'lstm_units': 104, 'n_dense_layers': 2, 'lstm_dropout_0': 0.30369961639519116, 'dense_units_0': 18, 'dense_dropout_0': 0.4334100473453585, 'dense_units_1': 43, 'dense_dropout_1': 0.10022833187551089, 'learning_rate': 0.0036358885342869358}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:03:48,146] Trial 6 finished with value: 0.16541209816932678 and parameters: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 2, 'lstm_dropout_0': 0.33876976139048187, 'lstm_dropout_1': 0.4080426373122651, 'dense_units_0': 53, 'dense_dropout_0': 0.36404419580435143, 'dense_units_1': 20, 'dense_dropout_1': 0.2888321533602692, 'learning_rate': 0.0006020388665060687}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:03:55,592] Trial 7 finished with value: 0.29124587774276733 and parameters: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2592066324133526, 'lstm_dropout_1': 0.3635156360029893, 'dense_units_0': 40, 'dense_dropout_0': 0.18715269026996828, 'dense_units_1': 25, 'dense_dropout_1': 0.2808083268447364, 'learning_rate': 0.00014507542374006375}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:02,585] Trial 8 finished with value: 0.139516681432724 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40463934684294534, 'lstm_dropout_1': 0.3703447767600706, 'learning_rate': 0.00887107137299647}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:06,927] Trial 9 finished with value: 0.12739625573158264 and parameters: {'n_lstm_layers': 1, 'lstm_units': 87, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2809613309326908, 'learning_rate': 0.0036226312114557772}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:14,570] Trial 10 finished with value: 0.1475183665752411 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 1, 'lstm_dropout_0': 0.10075756375643176, 'lstm_dropout_1': 0.13858743860381598, 'dense_units_0': 16, 'dense_dropout_0': 0.2544228926917206, 'learning_rate': 0.0007338913847436274}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:18,875] Trial 11 finished with value: 0.13228818774223328 and parameters: {'n_lstm_layers': 1, 'lstm_units': 95, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4886456126370703, 'learning_rate': 0.002054717216080878}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:23,355] Trial 12 finished with value: 0.12770409882068634 and parameters: {'n_lstm_layers': 1, 'lstm_units': 94, 'n_dense_layers': 0, 'lstm_dropout_0': 0.14583025596342802, 'learning_rate': 0.009489042728328883}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:28,134] Trial 13 finished with value: 0.13508793711662292 and parameters: {'n_lstm_layers': 1, 'lstm_units': 124, 'n_dense_layers': 1, 'lstm_dropout_0': 0.19920752325013885, 'dense_units_0': 27, 'dense_dropout_0': 0.11893827884635394, 'learning_rate': 0.004227438029632248}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:35,177] Trial 14 finished with value: 0.13150282204151154 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21759269366584624, 'lstm_dropout_1': 0.19175666759438043, 'learning_rate': 0.0014634948269754882}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:39,848] Trial 15 finished with value: 0.13781829178333282 and parameters: {'n_lstm_layers': 1, 'lstm_units': 54, 'n_dense_layers': 0, 'lstm_dropout_0': 0.14010431570037385, 'learning_rate': 0.0005837244876256853}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:47,299] Trial 16 finished with value: 0.1268148422241211 and parameters: {'n_lstm_layers': 2, 'lstm_units': 106, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3731700288024761, 'lstm_dropout_1': 0.49710049756036273, 'dense_units_0': 59, 'dense_dropout_0': 0.4992065126632123, 'learning_rate': 0.005261199547001121}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:04:54,012] Trial 17 finished with value: 0.14654478430747986 and parameters: {'n_lstm_layers': 2, 'lstm_units': 112, 'n_dense_layers': 1, 'lstm_dropout_0': 0.40444938805529423, 'lstm_dropout_1': 0.4826041975781888, 'dense_units_0': 40, 'dense_dropout_0': 0.4830487940460782, 'learning_rate': 0.0018916078448542365}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:00,692] Trial 18 finished with value: 0.13574771583080292 and parameters: {'n_lstm_layers': 2, 'lstm_units': 108, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4630602904367415, 'lstm_dropout_1': 0.23912448202124512, 'dense_units_0': 63, 'dense_dropout_0': 0.31050077916730773, 'learning_rate': 0.005461780975396882}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:08,359] Trial 19 finished with value: 0.1336645632982254 and parameters: {'n_lstm_layers': 2, 'lstm_units': 97, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4045665073574667, 'lstm_dropout_1': 0.27451339163215593, 'dense_units_0': 64, 'dense_dropout_0': 0.2952977719904295, 'learning_rate': 0.000990956520062691}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:15,697] Trial 20 finished with value: 0.13300898671150208 and parameters: {'n_lstm_layers': 2, 'lstm_units': 57, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3585119878063313, 'lstm_dropout_1': 0.4956717499742994, 'dense_units_0': 38, 'dense_dropout_0': 0.48973196322244783, 'learning_rate': 0.005999755974921954}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:20,446] Trial 21 finished with value: 0.12807801365852356 and parameters: {'n_lstm_layers': 1, 'lstm_units': 85, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2698892190577187, 'learning_rate': 0.0024509902277217604}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:27,666] Trial 22 finished with value: 0.12679249048233032 and parameters: {'n_lstm_layers': 2, 'lstm_units': 87, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32182631429647773, 'lstm_dropout_1': 0.23148204733462713, 'learning_rate': 0.0029604162694561427}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:34,326] Trial 23 finished with value: 0.13109023869037628 and parameters: {'n_lstm_layers': 2, 'lstm_units': 110, 'n_dense_layers': 0, 'lstm_dropout_0': 0.44129194147592954, 'lstm_dropout_1': 0.227328876902495, 'learning_rate': 0.006099178445793942}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:41,688] Trial 24 finished with value: 0.12632928788661957 and parameters: {'n_lstm_layers': 2, 'lstm_units': 120, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32857051264173903, 'lstm_dropout_1': 0.165626280559304, 'learning_rate': 0.0026691371914707926}. Best is trial 4 with value: 0.1254481077194214.
[I 2025-04-14 18:05:43,454] A new study created in memory with name: tune-5-LSTM_Change_in_Load-24hr
Trial 0: Validation Score (mae, scaled) = 0.125351

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.169428

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.128027

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.177489

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.169705

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.136287

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.193706

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.201800

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.128708

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.208398

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.122809

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.123740

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.123390

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.124061

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.124192

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.122784

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.125010

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.123090

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.126793

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.123881

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.125591

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.123120

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.121929

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.121520

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.122392

--- Best Results for Feeder=5, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.121520
Best Hyperparameters:
  n_estimators: 196
  learning_rate: 0.028185632368471845
  num_leaves: 60
  max_depth: 11
  min_child_samples: 38
  subsample: 0.9722910966716541
  colsample_bytree: 0.8527236004809267
  reg_alpha: 0.2919728256814584
  reg_lambda: 0.0961960751689055

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=5, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=5, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=5, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 157, Version: v1.1_Final_Forecasting_20250414170501, Path Info: {"keras_model": "models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501.keras", "scalers_pkl": "models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501_scalers.pkl"}
[I 2025-04-14 18:05:50,668] Trial 0 finished with value: 0.14855808019638062 and parameters: {'n_lstm_layers': 2, 'lstm_units': 38, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2554650422487158, 'lstm_dropout_1': 0.41276510451123294, 'dense_units_0': 42, 'dense_dropout_0': 0.4203914466238393, 'learning_rate': 0.001083190398373034}. Best is trial 0 with value: 0.14855808019638062.
[I 2025-04-14 18:05:57,873] Trial 1 finished with value: 0.17214760184288025 and parameters: {'n_lstm_layers': 2, 'lstm_units': 78, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2714302245959018, 'lstm_dropout_1': 0.39316969307440086, 'learning_rate': 0.0001562180677952148}. Best is trial 0 with value: 0.14855808019638062.
[I 2025-04-14 18:06:02,666] Trial 2 finished with value: 0.14289817214012146 and parameters: {'n_lstm_layers': 1, 'lstm_units': 73, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4294546190610731, 'dense_units_0': 52, 'dense_dropout_0': 0.4954300958118426, 'learning_rate': 0.000978439848478922}. Best is trial 2 with value: 0.14289817214012146.
[I 2025-04-14 18:06:09,089] Trial 3 finished with value: 0.1450546830892563 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 0, 'lstm_dropout_0': 0.273909380388524, 'lstm_dropout_1': 0.47792718865496786, 'learning_rate': 0.006483822839460173}. Best is trial 2 with value: 0.14289817214012146.
[I 2025-04-14 18:06:14,154] Trial 4 finished with value: 0.1325194239616394 and parameters: {'n_lstm_layers': 1, 'lstm_units': 100, 'n_dense_layers': 2, 'lstm_dropout_0': 0.21514373138257503, 'dense_units_0': 16, 'dense_dropout_0': 0.20661912776540248, 'dense_units_1': 57, 'dense_dropout_1': 0.3230090141049391, 'learning_rate': 0.0034271740411407976}. Best is trial 4 with value: 0.1325194239616394.
[I 2025-04-14 18:06:21,666] Trial 5 finished with value: 0.2753864526748657 and parameters: {'n_lstm_layers': 2, 'lstm_units': 35, 'n_dense_layers': 2, 'lstm_dropout_0': 0.16467069172302584, 'lstm_dropout_1': 0.2980460874014868, 'dense_units_0': 37, 'dense_dropout_0': 0.37653501927890465, 'dense_units_1': 18, 'dense_dropout_1': 0.31573068538939053, 'learning_rate': 0.00010773537685762773}. Best is trial 4 with value: 0.1325194239616394.
[I 2025-04-14 18:06:28,883] Trial 6 finished with value: 0.14507457613945007 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 1, 'lstm_dropout_0': 0.20222178762163218, 'lstm_dropout_1': 0.1609181651298048, 'dense_units_0': 17, 'dense_dropout_0': 0.4066162565754018, 'learning_rate': 0.0011548972938136691}. Best is trial 4 with value: 0.1325194239616394.
[I 2025-04-14 18:06:36,134] Trial 7 finished with value: 0.12529078125953674 and parameters: {'n_lstm_layers': 2, 'lstm_units': 113, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3838231075975541, 'lstm_dropout_1': 0.17947824123883804, 'learning_rate': 0.0016457850438383406}. Best is trial 7 with value: 0.12529078125953674.
[I 2025-04-14 18:06:41,050] Trial 8 finished with value: 0.1507030576467514 and parameters: {'n_lstm_layers': 1, 'lstm_units': 40, 'n_dense_layers': 2, 'lstm_dropout_0': 0.47866958679907967, 'dense_units_0': 19, 'dense_dropout_0': 0.3671990699946516, 'dense_units_1': 38, 'dense_dropout_1': 0.2217700438501444, 'learning_rate': 0.0011490382213108364}. Best is trial 7 with value: 0.12529078125953674.
[I 2025-04-14 18:06:48,637] Trial 9 finished with value: 0.15553805232048035 and parameters: {'n_lstm_layers': 2, 'lstm_units': 35, 'n_dense_layers': 2, 'lstm_dropout_0': 0.37816593371008966, 'lstm_dropout_1': 0.4177368757819123, 'dense_units_0': 25, 'dense_dropout_0': 0.4277483314204521, 'dense_units_1': 34, 'dense_dropout_1': 0.4952855375474887, 'learning_rate': 0.0012821133372213518}. Best is trial 7 with value: 0.12529078125953674.
[I 2025-04-14 18:06:53,121] Trial 10 finished with value: 0.16229143738746643 and parameters: {'n_lstm_layers': 1, 'lstm_units': 52, 'n_dense_layers': 0, 'lstm_dropout_0': 0.37148157352243344, 'learning_rate': 0.00034580637098995207}. Best is trial 7 with value: 0.12529078125953674.
[I 2025-04-14 18:06:58,166] Trial 11 finished with value: 0.12406259030103683 and parameters: {'n_lstm_layers': 1, 'lstm_units': 125, 'n_dense_layers': 1, 'lstm_dropout_0': 0.34760072522146035, 'dense_units_0': 26, 'dense_dropout_0': 0.15790577911335507, 'learning_rate': 0.00559840652887624}. Best is trial 11 with value: 0.12406259030103683.
[I 2025-04-14 18:07:02,493] Trial 12 finished with value: 0.12204661965370178 and parameters: {'n_lstm_layers': 1, 'lstm_units': 128, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3517153260762815, 'learning_rate': 0.0038926344681391462}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:07,019] Trial 13 finished with value: 0.12592613697052002 and parameters: {'n_lstm_layers': 1, 'lstm_units': 123, 'n_dense_layers': 1, 'lstm_dropout_0': 0.32027660823214305, 'dense_units_0': 27, 'dense_dropout_0': 0.10064737341554097, 'learning_rate': 0.009188843909760219}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:11,808] Trial 14 finished with value: 0.12331090867519379 and parameters: {'n_lstm_layers': 1, 'lstm_units': 96, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3336000905472795, 'learning_rate': 0.003306907085333242}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:16,349] Trial 15 finished with value: 0.125516876578331 and parameters: {'n_lstm_layers': 1, 'lstm_units': 96, 'n_dense_layers': 0, 'lstm_dropout_0': 0.11182012747371933, 'learning_rate': 0.003051082478785937}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:21,197] Trial 16 finished with value: 0.1253705769777298 and parameters: {'n_lstm_layers': 1, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.43608794264594686, 'learning_rate': 0.002579134108991452}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:25,950] Trial 17 finished with value: 0.13811077177524567 and parameters: {'n_lstm_layers': 1, 'lstm_units': 96, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3128270420097802, 'learning_rate': 0.0006191857147637873}. Best is trial 12 with value: 0.12204661965370178.
[I 2025-04-14 18:07:30,672] Trial 18 finished with value: 0.1203041672706604 and parameters: {'n_lstm_layers': 1, 'lstm_units': 107, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4304650216554355, 'learning_rate': 0.004524594816263526}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:34,999] Trial 19 finished with value: 0.13203421235084534 and parameters: {'n_lstm_layers': 1, 'lstm_units': 112, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4275797006602169, 'dense_units_0': 61, 'dense_dropout_0': 0.2863213736249667, 'learning_rate': 0.005112953589910524}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:39,471] Trial 20 finished with value: 0.12601202726364136 and parameters: {'n_lstm_layers': 1, 'lstm_units': 48, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49541666139821067, 'learning_rate': 0.008866543096140817}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:44,302] Trial 21 finished with value: 0.12257011979818344 and parameters: {'n_lstm_layers': 1, 'lstm_units': 90, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40477562113400845, 'learning_rate': 0.002184589218645363}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:49,006] Trial 22 finished with value: 0.12440647184848785 and parameters: {'n_lstm_layers': 1, 'lstm_units': 85, 'n_dense_layers': 0, 'lstm_dropout_0': 0.451477777102201, 'learning_rate': 0.0020688605511119226}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:53,543] Trial 23 finished with value: 0.12214412540197372 and parameters: {'n_lstm_layers': 1, 'lstm_units': 69, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40186700526732155, 'learning_rate': 0.004350886750197093}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:58,037] Trial 24 finished with value: 0.12221700698137283 and parameters: {'n_lstm_layers': 1, 'lstm_units': 69, 'n_dense_layers': 0, 'lstm_dropout_0': 0.46425010034960895, 'learning_rate': 0.004683793397788938}. Best is trial 18 with value: 0.1203041672706604.
[I 2025-04-14 18:07:58,911] A new study created in memory with name: tune-6-LightGBM_Baseline-24hr
[I 2025-04-14 18:07:59,766] Trial 0 finished with value: 0.2807636631758554 and parameters: {'n_estimators': 188, 'learning_rate': 0.0014494401474325102, 'num_leaves': 44, 'max_depth': 5, 'min_child_samples': 31, 'subsample': 0.7355455899851553, 'colsample_bytree': 0.5114974866528916, 'reg_alpha': 2.9285146919418402e-05, 'reg_lambda': 0.007264236854012963}. Best is trial 0 with value: 0.2807636631758554.
[I 2025-04-14 18:08:02,419] Trial 1 finished with value: 0.1423549598515212 and parameters: {'n_estimators': 234, 'learning_rate': 0.2014868411071364, 'num_leaves': 40, 'max_depth': 7, 'min_child_samples': 9, 'subsample': 0.7982416687853502, 'colsample_bytree': 0.7602601242794526, 'reg_alpha': 0.017633528588711308, 'reg_lambda': 0.0002139442374069866}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:03,592] Trial 2 finished with value: 0.17344402100266076 and parameters: {'n_estimators': 291, 'learning_rate': 0.0982346597050807, 'num_leaves': 22, 'max_depth': 9, 'min_child_samples': 34, 'subsample': 0.6295918133088569, 'colsample_bytree': 0.7286353283317245, 'reg_alpha': 2.2712381957177185e-08, 'reg_lambda': 0.535597646677309}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:04,286] Trial 3 finished with value: 0.29290118880341703 and parameters: {'n_estimators': 121, 'learning_rate': 0.0011144557350468605, 'num_leaves': 14, 'max_depth': 5, 'min_child_samples': 25, 'subsample': 0.8428718641346045, 'colsample_bytree': 0.8313722252024704, 'reg_alpha': 0.35263186156792525, 'reg_lambda': 1.9099326428662668e-07}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:04,984] Trial 4 finished with value: 0.19764459423306277 and parameters: {'n_estimators': 178, 'learning_rate': 0.09749269960560669, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 46, 'subsample': 0.9794630368414763, 'colsample_bytree': 0.7472427224059999, 'reg_alpha': 0.015517156749243474, 'reg_lambda': 2.9188087289587687e-06}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:06,720] Trial 5 finished with value: 0.194182808712945 and parameters: {'n_estimators': 237, 'learning_rate': 0.007626455727845952, 'num_leaves': 29, 'max_depth': 8, 'min_child_samples': 15, 'subsample': 0.5882253946023658, 'colsample_bytree': 0.7017145616715355, 'reg_alpha': 2.553813047327402e-07, 'reg_lambda': 0.233350878839258}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:07,094] Trial 6 finished with value: 0.28209805756418604 and parameters: {'n_estimators': 65, 'learning_rate': 0.004023308092844111, 'num_leaves': 29, 'max_depth': 7, 'min_child_samples': 39, 'subsample': 0.5351377848921559, 'colsample_bytree': 0.5854160732852276, 'reg_alpha': 1.3258899281721093e-08, 'reg_lambda': 5.891016280077198e-08}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:07,614] Trial 7 finished with value: 0.19955700479398056 and parameters: {'n_estimators': 89, 'learning_rate': 0.024562384977225894, 'num_leaves': 37, 'max_depth': 3, 'min_child_samples': 32, 'subsample': 0.7102408220296734, 'colsample_bytree': 0.7831014271696706, 'reg_alpha': 5.7822544017921114e-08, 'reg_lambda': 4.456389430755517e-08}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:08,954] Trial 8 finished with value: 0.2507291319071853 and parameters: {'n_estimators': 280, 'learning_rate': 0.002282689735098149, 'num_leaves': 21, 'max_depth': 9, 'min_child_samples': 25, 'subsample': 0.7484293904879973, 'colsample_bytree': 0.7805211336915399, 'reg_alpha': 0.25828979982755057, 'reg_lambda': 0.03227906695891303}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:09,418] Trial 9 finished with value: 0.1895609642739693 and parameters: {'n_estimators': 73, 'learning_rate': 0.050506259653398805, 'num_leaves': 54, 'max_depth': 4, 'min_child_samples': 35, 'subsample': 0.6671808886455713, 'colsample_bytree': 0.6333511587394737, 'reg_alpha': 0.0072509727870922035, 'reg_lambda': 1.0876751302635398e-07}. Best is trial 1 with value: 0.1423549598515212.
[I 2025-04-14 18:08:12,433] Trial 10 finished with value: 0.13827987293197874 and parameters: {'n_estimators': 216, 'learning_rate': 0.218165145659631, 'num_leaves': 60, 'max_depth': 12, 'min_child_samples': 7, 'subsample': 0.8512534149042106, 'colsample_bytree': 0.954307520591761, 'reg_alpha': 0.00016379432651583142, 'reg_lambda': 0.00016806734532247508}. Best is trial 10 with value: 0.13827987293197874.
[I 2025-04-14 18:08:16,210] Trial 11 finished with value: 0.13722516645013813 and parameters: {'n_estimators': 221, 'learning_rate': 0.29412065584796626, 'num_leaves': 60, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.8589033775257118, 'colsample_bytree': 0.9853840950612022, 'reg_alpha': 0.0001616246331479262, 'reg_lambda': 0.00017329853695252005}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:20,219] Trial 12 finished with value: 0.13966551885462178 and parameters: {'n_estimators': 222, 'learning_rate': 0.2632578459893276, 'num_leaves': 59, 'max_depth': 12, 'min_child_samples': 6, 'subsample': 0.8874858160094808, 'colsample_bytree': 0.9899457317889317, 'reg_alpha': 4.656372225185219e-05, 'reg_lambda': 0.00011486004059161992}. Best is trial 11 with value: 0.13722516645013813.
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501.keras', 'scalers_pkl': 'models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501_scalers.pkl'}
Detected separate Keras model (models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501.keras) and scalers (models/feeder_5/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170501_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.152297

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.146567

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.195094

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.259461

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.125448

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.142353

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.165412

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.291246

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.139517

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.127396

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.147518

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.132288

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.127704

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.135088

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.131503

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.137818

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.126815

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.146545

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.135748

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.133665

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.133009

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.128078

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.126792

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.131090

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.126329

--- Best Results for Feeder=5, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.125448
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 108
  n_dense_layers: 0
  lstm_dropout_0: 0.1702998075739121
  lstm_dropout_1: 0.2739042036232272
  learning_rate: 0.0016927465122475217

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=5, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=5, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 158, Version: v1.1_Final_Forecasting_20250414170510, Path Info: {"keras_model": "models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510.keras", "scalers_pkl": "models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510.keras', 'scalers_pkl': 'models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510_scalers.pkl'}
Detected separate Keras model (models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510.keras) and scalers (models/feeder_5/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170510_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
[I 2025-04-14 18:08:21,468] Trial 13 finished with value: 0.1469420253988691 and parameters: {'n_estimators': 143, 'learning_rate': 0.2693494512972031, 'num_leaves': 53, 'max_depth': 11, 'min_child_samples': 16, 'subsample': 0.9272450143693377, 'colsample_bytree': 0.9978523874919925, 'reg_alpha': 3.4809504559210943e-06, 'reg_lambda': 1.380772955751217e-05}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:23,042] Trial 14 finished with value: 0.15849176710241653 and parameters: {'n_estimators': 197, 'learning_rate': 0.02495273429106795, 'num_leaves': 48, 'max_depth': 10, 'min_child_samples': 17, 'subsample': 0.8267142632289745, 'colsample_bytree': 0.9104565488717868, 'reg_alpha': 0.0008202634289481034, 'reg_lambda': 0.0010120321188089331}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:25,750] Trial 15 finished with value: 0.1440084205146354 and parameters: {'n_estimators': 261, 'learning_rate': 0.07735696190960717, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 11, 'subsample': 0.9879107514623318, 'colsample_bytree': 0.9067947821299144, 'reg_alpha': 0.000553325593621412, 'reg_lambda': 7.1547081498139225e-06}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:28,198] Trial 16 finished with value: 0.1397247992356235 and parameters: {'n_estimators': 147, 'learning_rate': 0.13155046134272044, 'num_leaves': 48, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.9014879188078483, 'colsample_bytree': 0.9006887104842016, 'reg_alpha': 2.8535704687552164e-06, 'reg_lambda': 0.0017424411094461773}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:30,524] Trial 17 finished with value: 0.14689862908113946 and parameters: {'n_estimators': 213, 'learning_rate': 0.050324088940428474, 'num_leaves': 54, 'max_depth': 10, 'min_child_samples': 12, 'subsample': 0.7897256333295087, 'colsample_bytree': 0.9483050883364755, 'reg_alpha': 0.000472505112193958, 'reg_lambda': 1.0331778620891632e-06}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:32,009] Trial 18 finished with value: 0.16913775331672176 and parameters: {'n_estimators': 255, 'learning_rate': 0.015671430046617828, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 22, 'subsample': 0.8571655114948526, 'colsample_bytree': 0.8510962755955345, 'reg_alpha': 6.787672781990435e-06, 'reg_lambda': 2.926897296999219e-05}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:33,164] Trial 19 finished with value: 0.1540078901604701 and parameters: {'n_estimators': 154, 'learning_rate': 0.1629057041795089, 'num_leaves': 48, 'max_depth': 10, 'min_child_samples': 20, 'subsample': 0.9320526420756124, 'colsample_bytree': 0.9471550568715813, 'reg_alpha': 5.104251641771688e-07, 'reg_lambda': 0.0004588458019824413}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:33,937] Trial 20 finished with value: 0.20292750316201272 and parameters: {'n_estimators': 208, 'learning_rate': 0.05052230400740554, 'num_leaves': 54, 'max_depth': 8, 'min_child_samples': 49, 'subsample': 0.8086718757748931, 'colsample_bytree': 0.8459104141693045, 'reg_alpha': 0.004102269703547504, 'reg_lambda': 0.007135736759384669}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:37,671] Trial 21 finished with value: 0.13950099925792447 and parameters: {'n_estimators': 227, 'learning_rate': 0.2987529060809185, 'num_leaves': 60, 'max_depth': 12, 'min_child_samples': 6, 'subsample': 0.8866487628925627, 'colsample_bytree': 0.9747610594728273, 'reg_alpha': 6.167566162838338e-05, 'reg_lambda': 0.00010604199931431371}. Best is trial 11 with value: 0.13722516645013813.
[I 2025-04-14 18:08:41,990] Trial 22 finished with value: 0.13308493203446017 and parameters: {'n_estimators': 253, 'learning_rate': 0.29471490959730323, 'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.870653286534444, 'colsample_bytree': 0.9497587992545666, 'reg_alpha': 0.0001289760492381335, 'reg_lambda': 5.059092462761579e-05}. Best is trial 22 with value: 0.13308493203446017.
[I 2025-04-14 18:08:44,713] Trial 23 finished with value: 0.13714144112124588 and parameters: {'n_estimators': 257, 'learning_rate': 0.15534282642146022, 'num_leaves': 51, 'max_depth': 11, 'min_child_samples': 10, 'subsample': 0.9434431749951101, 'colsample_bytree': 0.9354009409502453, 'reg_alpha': 0.0002653121638668085, 'reg_lambda': 3.79037835056983e-05}. Best is trial 22 with value: 0.13308493203446017.
[I 2025-04-14 18:08:47,215] Trial 24 finished with value: 0.14310045529366414 and parameters: {'n_estimators': 265, 'learning_rate': 0.13910380481448328, 'num_leaves': 43, 'max_depth': 11, 'min_child_samples': 12, 'subsample': 0.9372471480466211, 'colsample_bytree': 0.8960310507307275, 'reg_alpha': 0.002073436061591255, 'reg_lambda': 8.512270132499527e-07}. Best is trial 22 with value: 0.13308493203446017.
[I 2025-04-14 18:08:50,467] A new study created in memory with name: tune-6-LSTM_Baseload-24hr
[I 2025-04-14 18:08:58,332] Trial 0 finished with value: 0.28255125880241394 and parameters: {'n_lstm_layers': 2, 'lstm_units': 35, 'n_dense_layers': 2, 'lstm_dropout_0': 0.11691409775732856, 'lstm_dropout_1': 0.3309995032431835, 'dense_units_0': 27, 'dense_dropout_0': 0.40354069616942556, 'dense_units_1': 30, 'dense_dropout_1': 0.3382731481969308, 'learning_rate': 0.00029043235255807944}. Best is trial 0 with value: 0.28255125880241394.
[I 2025-04-14 18:09:03,319] Trial 1 finished with value: 0.15399815142154694 and parameters: {'n_lstm_layers': 1, 'lstm_units': 44, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1361843572874642, 'dense_units_0': 27, 'dense_dropout_0': 0.4179055910890306, 'learning_rate': 0.0007129262490002157}. Best is trial 1 with value: 0.15399815142154694.
[I 2025-04-14 18:09:08,111] Trial 2 finished with value: 0.2329527884721756 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 2, 'lstm_dropout_0': 0.19276187222888486, 'dense_units_0': 56, 'dense_dropout_0': 0.19413521419402047, 'dense_units_1': 54, 'dense_dropout_1': 0.2912144806668818, 'learning_rate': 0.0001673511210366919}. Best is trial 1 with value: 0.15399815142154694.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.148558

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.172148

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.142898

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.145055

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.132519

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.275386

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.145075

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.125291

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.150703

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.155538

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.162291

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.124063

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.122047

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.125926

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.123311

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.125517

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.125371

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.138111

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.120304

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.132034

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.126012

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.122570

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.124406

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.122144

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.122217

--- Best Results for Feeder=5, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.120304
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 107
  n_dense_layers: 0
  lstm_dropout_0: 0.4304650216554355
  learning_rate: 0.004524594816263526

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=5, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 5, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=5, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=5, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 6 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 160, Version: v1.1_Final_Forecasting_20250414170525, Path Info: models/feeder_6/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170525.pkl
Loading artifact(s) based on path info: models/feeder_6/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170525.pkl
Detected single pickle artifact path: models/feeder_6/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170525.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170525.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170525.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.280764

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.142355

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.173444

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.292901

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.197645

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.194183

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.282098

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.199557

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.250729

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.189561

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.138280

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.137225

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.139666

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
[I 2025-04-14 18:09:15,652] Trial 3 finished with value: 0.13758300244808197 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4609926632285267, 'lstm_dropout_1': 0.19462054498999942, 'dense_units_0': 60, 'dense_dropout_0': 0.43603719128778295, 'learning_rate': 0.0012017271312937082}. Best is trial 3 with value: 0.13758300244808197.
[I 2025-04-14 18:09:20,211] Trial 4 finished with value: 0.1721278429031372 and parameters: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3191251639114938, 'dense_units_0': 19, 'dense_dropout_0': 0.4437751952016852, 'learning_rate': 0.0009927080176202919}. Best is trial 3 with value: 0.13758300244808197.
[I 2025-04-14 18:09:27,793] Trial 5 finished with value: 0.1015990599989891 and parameters: {'n_lstm_layers': 2, 'lstm_units': 101, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4607434836545944, 'lstm_dropout_1': 0.10127039430369172, 'learning_rate': 0.004123758270745923}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:09:32,768] Trial 6 finished with value: 0.23083555698394775 and parameters: {'n_lstm_layers': 1, 'lstm_units': 85, 'n_dense_layers': 0, 'lstm_dropout_0': 0.29075199362879167, 'learning_rate': 0.00010325863411043172}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:09:39,789] Trial 7 finished with value: 0.10681606829166412 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40325899361840356, 'lstm_dropout_1': 0.16190646526245997, 'learning_rate': 0.009095777312490387}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:09:44,636] Trial 8 finished with value: 0.10789396613836288 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 0, 'lstm_dropout_0': 0.45560766924666984, 'learning_rate': 0.0014794214685436298}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:09:49,356] Trial 9 finished with value: 0.20599859952926636 and parameters: {'n_lstm_layers': 1, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18831334033952885, 'learning_rate': 0.00016903055622181885}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:09:56,625] Trial 10 finished with value: 0.10572919249534607 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3542572599355109, 'lstm_dropout_1': 0.47552118763420664, 'learning_rate': 0.006930544315970393}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:03,866] Trial 11 finished with value: 0.10778063535690308 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 0, 'lstm_dropout_0': 0.35795283078308404, 'lstm_dropout_1': 0.4621271524790077, 'learning_rate': 0.008346422873669941}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:11,239] Trial 12 finished with value: 0.11278387159109116 and parameters: {'n_lstm_layers': 2, 'lstm_units': 98, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49988035997420327, 'lstm_dropout_1': 0.4953480754901823, 'learning_rate': 0.003794936074714008}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:18,881] Trial 13 finished with value: 0.1192198395729065 and parameters: {'n_lstm_layers': 2, 'lstm_units': 102, 'n_dense_layers': 1, 'lstm_dropout_0': 0.38780462585639985, 'lstm_dropout_1': 0.32800367754605275, 'dense_units_0': 16, 'dense_dropout_0': 0.1166480508837176, 'learning_rate': 0.003211500123464183}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:26,247] Trial 14 finished with value: 0.10628819465637207 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 0, 'lstm_dropout_0': 0.27991514400909934, 'lstm_dropout_1': 0.2517746080611267, 'learning_rate': 0.0040104617275117755}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:33,779] Trial 15 finished with value: 0.1107071191072464 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 1, 'lstm_dropout_0': 0.42510232188540875, 'lstm_dropout_1': 0.11404813686071502, 'dense_units_0': 42, 'dense_dropout_0': 0.28861662440861824, 'learning_rate': 0.0023337213841472357}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:40,088] Trial 16 finished with value: 0.15952208638191223 and parameters: {'n_lstm_layers': 2, 'lstm_units': 78, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3497059908140048, 'lstm_dropout_1': 0.40051063436347645, 'learning_rate': 0.006917059334057334}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:47,725] Trial 17 finished with value: 0.11372267454862595 and parameters: {'n_lstm_layers': 2, 'lstm_units': 111, 'n_dense_layers': 2, 'lstm_dropout_0': 0.24454773735456836, 'lstm_dropout_1': 0.3900028565362797, 'dense_units_0': 37, 'dense_dropout_0': 0.2951940898293457, 'dense_units_1': 16, 'dense_dropout_1': 0.10131694056015858, 'learning_rate': 0.005141581144483929}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:10:54,482] Trial 18 finished with value: 0.1752745509147644 and parameters: {'n_lstm_layers': 2, 'lstm_units': 57, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4609106990438617, 'lstm_dropout_1': 0.2560610533707969, 'dense_units_0': 21, 'dense_dropout_0': 0.49727718732893506, 'learning_rate': 0.0022284307595166813}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:11:01,986] Trial 19 finished with value: 0.11751087754964828 and parameters: {'n_lstm_layers': 2, 'lstm_units': 90, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49586241050388186, 'lstm_dropout_1': 0.39690206821810586, 'learning_rate': 0.0007129189858497897}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:11:09,027] Trial 20 finished with value: 0.11405812203884125 and parameters: {'n_lstm_layers': 2, 'lstm_units': 74, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3668569884853882, 'lstm_dropout_1': 0.12199606796599335, 'dense_units_0': 44, 'dense_dropout_0': 0.21318810133027194, 'learning_rate': 0.0021690553941128093}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:11:16,310] Trial 21 finished with value: 0.10770632326602936 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2736070167086259, 'lstm_dropout_1': 0.24138260845643825, 'learning_rate': 0.005008015432713736}. Best is trial 5 with value: 0.1015990599989891.
[I 2025-04-14 18:11:23,666] Trial 22 finished with value: 0.0951991081237793 and parameters: {'n_lstm_layers': 2, 'lstm_units': 113, 'n_dense_layers': 0, 'lstm_dropout_0': 0.24453837958067076, 'lstm_dropout_1': 0.2660251228172408, 'learning_rate': 0.005286364249348776}. Best is trial 22 with value: 0.0951991081237793.
[I 2025-04-14 18:11:31,136] Trial 23 finished with value: 0.08877730369567871 and parameters: {'n_lstm_layers': 2, 'lstm_units': 118, 'n_dense_layers': 0, 'lstm_dropout_0': 0.23404914145337877, 'lstm_dropout_1': 0.19981906966616403, 'learning_rate': 0.006267757934529045}. Best is trial 23 with value: 0.08877730369567871.
[I 2025-04-14 18:11:38,101] Trial 24 finished with value: 0.10097891092300415 and parameters: {'n_lstm_layers': 2, 'lstm_units': 113, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2289563664020055, 'lstm_dropout_1': 0.1801104660131314, 'learning_rate': 0.0056137962115745295}. Best is trial 23 with value: 0.08877730369567871.
[I 2025-04-14 18:11:39,433] A new study created in memory with name: tune-6-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:11:47,217] Trial 0 finished with value: 0.20764800906181335 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3395131860898207, 'lstm_dropout_1': 0.15304736448160305, 'dense_units_0': 42, 'dense_dropout_0': 0.4005572449472782, 'dense_units_1': 44, 'dense_dropout_1': 0.4337019069070803, 'learning_rate': 0.0001067575715840105}. Best is trial 0 with value: 0.20764800906181335.
[I 2025-04-14 18:11:50,918] Trial 1 finished with value: 0.10777954012155533 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3991982412609115, 'dense_units_0': 25, 'dense_dropout_0': 0.28295116723417446, 'learning_rate': 0.0061533039563138655}. Best is trial 1 with value: 0.10777954012155533.
[I 2025-04-14 18:11:55,370] Trial 2 finished with value: 0.10423583537340164 and parameters: {'n_lstm_layers': 1, 'lstm_units': 53, 'n_dense_layers': 0, 'lstm_dropout_0': 0.22818178628370164, 'learning_rate': 0.005720679797679945}. Best is trial 2 with value: 0.10423583537340164.
[I 2025-04-14 18:11:59,820] Trial 3 finished with value: 0.11198043078184128 and parameters: {'n_lstm_layers': 1, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.13691975759340358, 'dense_units_0': 28, 'dense_dropout_0': 0.42565101069127, 'learning_rate': 0.0012312326222018515}. Best is trial 2 with value: 0.10423583537340164.
[I 2025-04-14 18:12:07,120] Trial 4 finished with value: 0.10057272017002106 and parameters: {'n_lstm_layers': 2, 'lstm_units': 116, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49562958928984724, 'lstm_dropout_1': 0.14974988853790872, 'learning_rate': 0.000537599716249571}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:11,242] Trial 5 finished with value: 0.10708869248628616 and parameters: {'n_lstm_layers': 1, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.41493321439753783, 'learning_rate': 0.0015238194872878952}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:16,090] Trial 6 finished with value: 0.12079279124736786 and parameters: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3435539730317654, 'dense_units_0': 62, 'dense_dropout_0': 0.344944624249388, 'learning_rate': 0.0004274973492408192}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:23,371] Trial 7 finished with value: 0.11316223442554474 and parameters: {'n_lstm_layers': 2, 'lstm_units': 74, 'n_dense_layers': 0, 'lstm_dropout_0': 0.30970956782737585, 'lstm_dropout_1': 0.1927801015782812, 'learning_rate': 0.0002664883311427592}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:27,861] Trial 8 finished with value: 0.16430149972438812 and parameters: {'n_lstm_layers': 1, 'lstm_units': 94, 'n_dense_layers': 1, 'lstm_dropout_0': 0.47113042076940503, 'dense_units_0': 51, 'dense_dropout_0': 0.4172916545543772, 'learning_rate': 0.00018695945053059926}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:34,977] Trial 9 finished with value: 0.11818588525056839 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2585965302830862, 'lstm_dropout_1': 0.33724770379420344, 'dense_units_0': 25, 'dense_dropout_0': 0.2849270017302008, 'learning_rate': 0.0008734179069135108}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:42,522] Trial 10 finished with value: 0.10303056985139847 and parameters: {'n_lstm_layers': 2, 'lstm_units': 128, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4765066093874943, 'lstm_dropout_1': 0.48351515303768794, 'dense_units_0': 17, 'dense_dropout_0': 0.10793394473131002, 'dense_units_1': 19, 'dense_dropout_1': 0.11247468665026378, 'learning_rate': 0.0033272215509209035}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:50,174] Trial 11 finished with value: 0.10487771034240723 and parameters: {'n_lstm_layers': 2, 'lstm_units': 118, 'n_dense_layers': 2, 'lstm_dropout_0': 0.49319366488985966, 'lstm_dropout_1': 0.4696748729527754, 'dense_units_0': 16, 'dense_dropout_0': 0.10124219532760409, 'dense_units_1': 16, 'dense_dropout_1': 0.11397491958221434, 'learning_rate': 0.0027336991877197794}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:12:57,713] Trial 12 finished with value: 0.12554454803466797 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4258229032353207, 'lstm_dropout_1': 0.49214898418153247, 'dense_units_0': 17, 'dense_dropout_0': 0.12116246418687673, 'dense_units_1': 19, 'dense_dropout_1': 0.10134848420696496, 'learning_rate': 0.0005746965058444918}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:04,887] Trial 13 finished with value: 0.10211926698684692 and parameters: {'n_lstm_layers': 2, 'lstm_units': 86, 'n_dense_layers': 0, 'lstm_dropout_0': 0.48147036066212323, 'lstm_dropout_1': 0.3155794783480735, 'learning_rate': 0.002776705815115965}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:12,083] Trial 14 finished with value: 0.1017829030752182 and parameters: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3849798526770651, 'lstm_dropout_1': 0.2893068857807282, 'learning_rate': 0.0022436912405107037}. Best is trial 4 with value: 0.10057272017002106.
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.146942

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.158492

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.144008

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.139725

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.146899

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.169138

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.154008

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.202928

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.139501

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.133085

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.137141

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.143100

--- Best Results for Feeder=6, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.133085
Best Hyperparameters:
  n_estimators: 253
  learning_rate: 0.29471490959730323
  num_leaves: 56
  max_depth: 12
  min_child_samples: 5
  subsample: 0.870653286534444
  colsample_bytree: 0.9497587992545666
  reg_alpha: 0.0001289760492381335
  reg_lambda: 5.059092462761579e-05

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=6, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=6, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=6, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 161, Version: v1.1_Final_Forecasting_20250414170528, Path Info: {"keras_model": "models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528.keras", "scalers_pkl": "models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528.keras', 'scalers_pkl': 'models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528_scalers.pkl'}
Detected separate Keras model (models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528.keras) and scalers (models/feeder_6/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170528_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.282551

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.153998

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.232953
[I 2025-04-14 18:13:19,276] Trial 15 finished with value: 0.10570193827152252 and parameters: {'n_lstm_layers': 2, 'lstm_units': 74, 'n_dense_layers': 0, 'lstm_dropout_0': 0.38300650723125157, 'lstm_dropout_1': 0.2239056112784309, 'learning_rate': 0.0006623357008659084}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:26,192] Trial 16 finished with value: 0.10525070130825043 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 0, 'lstm_dropout_0': 0.19268687986525396, 'lstm_dropout_1': 0.2585939971628339, 'learning_rate': 0.0016601360513095063}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:33,822] Trial 17 finished with value: 0.10125391185283661 and parameters: {'n_lstm_layers': 2, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3656487384488486, 'lstm_dropout_1': 0.1009194316513683, 'learning_rate': 0.009833767256745235}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:41,022] Trial 18 finished with value: 0.1024659126996994 and parameters: {'n_lstm_layers': 2, 'lstm_units': 33, 'n_dense_layers': 0, 'lstm_dropout_0': 0.100377282093945, 'lstm_dropout_1': 0.10770191640619181, 'learning_rate': 0.008995500493658128}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:48,798] Trial 19 finished with value: 0.11285805702209473 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4424396083404383, 'lstm_dropout_1': 0.1064803362608631, 'dense_units_0': 37, 'dense_dropout_0': 0.2085696405442401, 'learning_rate': 0.0003364848640834929}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:13:56,619] Trial 20 finished with value: 0.12618952989578247 and parameters: {'n_lstm_layers': 2, 'lstm_units': 48, 'n_dense_layers': 0, 'lstm_dropout_0': 0.27793388403630737, 'lstm_dropout_1': 0.16481299141415623, 'learning_rate': 0.0001377814692214853}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:14:03,916] Trial 21 finished with value: 0.1014573946595192 and parameters: {'n_lstm_layers': 2, 'lstm_units': 76, 'n_dense_layers': 0, 'lstm_dropout_0': 0.37174458479692496, 'lstm_dropout_1': 0.35014685298021775, 'learning_rate': 0.004256523472169394}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:14:10,928] Trial 22 finished with value: 0.10297276079654694 and parameters: {'n_lstm_layers': 2, 'lstm_units': 67, 'n_dense_layers': 0, 'lstm_dropout_0': 0.35908175840946177, 'lstm_dropout_1': 0.38357811989013435, 'learning_rate': 0.0093520229222013}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:14:17,572] Trial 23 finished with value: 0.10157984495162964 and parameters: {'n_lstm_layers': 2, 'lstm_units': 107, 'n_dense_layers': 0, 'lstm_dropout_0': 0.31300007688821585, 'lstm_dropout_1': 0.4138339790145748, 'learning_rate': 0.005981907694411558}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:14:24,505] Trial 24 finished with value: 0.1026884913444519 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 0, 'lstm_dropout_0': 0.45611165360075556, 'lstm_dropout_1': 0.3619148723780537, 'learning_rate': 0.00423029673256659}. Best is trial 4 with value: 0.10057272017002106.
[I 2025-04-14 18:14:25,422] A new study created in memory with name: tune-7-LightGBM_Baseline-24hr
[I 2025-04-14 18:14:29,496] Trial 0 finished with value: 0.2888699647514969 and parameters: {'n_estimators': 256, 'learning_rate': 0.004410599358283486, 'num_leaves': 42, 'max_depth': 3, 'min_child_samples': 45, 'subsample': 0.6577518959036579, 'colsample_bytree': 0.9296506464360568, 'reg_alpha': 2.173444040222774e-05, 'reg_lambda': 0.001107247765835592}. Best is trial 0 with value: 0.2888699647514969.
[I 2025-04-14 18:14:30,323] Trial 1 finished with value: 0.30211514316933935 and parameters: {'n_estimators': 190, 'learning_rate': 0.0011258654224151855, 'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 29, 'subsample': 0.6154537093801637, 'colsample_bytree': 0.7055751664108263, 'reg_alpha': 0.02466064655564216, 'reg_lambda': 1.5250136641884477e-08}. Best is trial 0 with value: 0.2888699647514969.
[I 2025-04-14 18:14:31,608] Trial 2 finished with value: 0.19353995581593694 and parameters: {'n_estimators': 289, 'learning_rate': 0.0152059201893336, 'num_leaves': 46, 'max_depth': 12, 'min_child_samples': 26, 'subsample': 0.5166422373042475, 'colsample_bytree': 0.5485361583314154, 'reg_alpha': 1.0921965079267233e-06, 'reg_lambda': 9.195175305906326e-07}. Best is trial 2 with value: 0.19353995581593694.
[I 2025-04-14 18:14:32,097] Trial 3 finished with value: 0.3013589578499645 and parameters: {'n_estimators': 107, 'learning_rate': 0.002347229616277772, 'num_leaves': 40, 'max_depth': 6, 'min_child_samples': 37, 'subsample': 0.9511901799993523, 'colsample_bytree': 0.5934982987604003, 'reg_alpha': 0.00013459408801269984, 'reg_lambda': 1.6553781455547134e-08}. Best is trial 2 with value: 0.19353995581593694.
[I 2025-04-14 18:14:33,504] Trial 4 finished with value: 0.15702259304228627 and parameters: {'n_estimators': 235, 'learning_rate': 0.07800728249470384, 'num_leaves': 43, 'max_depth': 3, 'min_child_samples': 7, 'subsample': 0.9722194394732815, 'colsample_bytree': 0.5809902022022366, 'reg_alpha': 0.02978434624210623, 'reg_lambda': 0.0007997067289328278}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:34,040] Trial 5 finished with value: 0.29644343275718554 and parameters: {'n_estimators': 61, 'learning_rate': 0.0038447161962566487, 'num_leaves': 38, 'max_depth': 10, 'min_child_samples': 18, 'subsample': 0.599386675383411, 'colsample_bytree': 0.8623188541700422, 'reg_alpha': 1.6031420789657498e-08, 'reg_lambda': 0.00316754796842966}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:34,783] Trial 6 finished with value: 0.2898545243380489 and parameters: {'n_estimators': 79, 'learning_rate': 0.003825595846294991, 'num_leaves': 27, 'max_depth': 6, 'min_child_samples': 13, 'subsample': 0.623201487102157, 'colsample_bytree': 0.6256088038350754, 'reg_alpha': 0.0060310798357938716, 'reg_lambda': 0.0063912209437311214}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:35,710] Trial 7 finished with value: 0.2333995954974385 and parameters: {'n_estimators': 103, 'learning_rate': 0.010266330104402942, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 11, 'subsample': 0.7682375592507785, 'colsample_bytree': 0.5509102299560311, 'reg_alpha': 0.39429139515425665, 'reg_lambda': 9.9841308384003e-08}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:37,033] Trial 8 finished with value: 0.16211010671851975 and parameters: {'n_estimators': 267, 'learning_rate': 0.06615716198416434, 'num_leaves': 13, 'max_depth': 3, 'min_child_samples': 21, 'subsample': 0.970840253815547, 'colsample_bytree': 0.6584185608710391, 'reg_alpha': 0.0016407917108946229, 'reg_lambda': 0.11043508155791511}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:37,579] Trial 9 finished with value: 0.16234483846284534 and parameters: {'n_estimators': 70, 'learning_rate': 0.1958941917553744, 'num_leaves': 49, 'max_depth': 11, 'min_child_samples': 19, 'subsample': 0.6590523143579458, 'colsample_bytree': 0.734073316511743, 'reg_alpha': 0.16992517933055698, 'reg_lambda': 3.4469061936541035e-08}. Best is trial 4 with value: 0.15702259304228627.
[I 2025-04-14 18:14:39,913] Trial 10 finished with value: 0.15371848538443478 and parameters: {'n_estimators': 211, 'learning_rate': 0.06871052706811402, 'num_leaves': 59, 'max_depth': 5, 'min_child_samples': 5, 'subsample': 0.8238362885685595, 'colsample_bytree': 0.820370608163606, 'reg_alpha': 0.00016783814431510662, 'reg_lambda': 1.1517755638726528e-05}. Best is trial 10 with value: 0.15371848538443478.
[I 2025-04-14 18:14:41,675] Trial 11 finished with value: 0.15306525899547843 and parameters: {'n_estimators': 198, 'learning_rate': 0.0712077716299931, 'num_leaves': 60, 'max_depth': 4, 'min_child_samples': 5, 'subsample': 0.8535759889033576, 'colsample_bytree': 0.8376771882983307, 'reg_alpha': 0.00046509175327640517, 'reg_lambda': 1.1379492797485943e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:43,639] Trial 12 finished with value: 0.1569416780163149 and parameters: {'n_estimators': 178, 'learning_rate': 0.04805903274115697, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 5, 'subsample': 0.843988614761576, 'colsample_bytree': 0.8308534221469397, 'reg_alpha': 0.00011686613283951238, 'reg_lambda': 1.2568738101105482e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:45,319] Trial 13 finished with value: 0.1632248919428056 and parameters: {'n_estimators': 145, 'learning_rate': 0.2843489006005632, 'num_leaves': 57, 'max_depth': 5, 'min_child_samples': 5, 'subsample': 0.8539535914224607, 'colsample_bytree': 0.8213855154827034, 'reg_alpha': 3.4288364122471723e-06, 'reg_lambda': 1.6263522523310285e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:46,956] Trial 14 finished with value: 0.1619716307327297 and parameters: {'n_estimators': 210, 'learning_rate': 0.02776910021014526, 'num_leaves': 53, 'max_depth': 5, 'min_child_samples': 13, 'subsample': 0.8557637603309903, 'colsample_bytree': 0.9925155117827575, 'reg_alpha': 0.0008905646510425524, 'reg_lambda': 1.8172192200276565e-06}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:47,552] Trial 15 finished with value: 0.25656210321272194 and parameters: {'n_estimators': 151, 'learning_rate': 0.12133299270026028, 'num_leaves': 60, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.7874026228816657, 'colsample_bytree': 0.772164760981907, 'reg_alpha': 2.476718576389073e-07, 'reg_lambda': 6.654668057178423e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:48,655] Trial 16 finished with value: 0.18588626974638378 and parameters: {'n_estimators': 232, 'learning_rate': 0.02958785253594773, 'num_leaves': 21, 'max_depth': 4, 'min_child_samples': 28, 'subsample': 0.8955084366661434, 'colsample_bytree': 0.9034467644153512, 'reg_alpha': 1.9057242651481388e-05, 'reg_lambda': 8.1492598431728e-07}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:49,381] Trial 17 finished with value: 0.1930640513475371 and parameters: {'n_estimators': 153, 'learning_rate': 0.11952753008771207, 'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 36, 'subsample': 0.7172678013568073, 'colsample_bytree': 0.7774794910265507, 'reg_alpha': 0.000497105565813633, 'reg_lambda': 5.795024437315089e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:50,971] Trial 18 finished with value: 0.1577138980039193 and parameters: {'n_estimators': 210, 'learning_rate': 0.03839393228986802, 'num_leaves': 54, 'max_depth': 4, 'min_child_samples': 10, 'subsample': 0.907552790114694, 'colsample_bytree': 0.96140450161763, 'reg_alpha': 1.4296892844196207e-05, 'reg_lambda': 5.815550822038658e-06}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:52,490] Trial 19 finished with value: 0.1758566225475671 and parameters: {'n_estimators': 210, 'learning_rate': 0.0139870169839135, 'num_leaves': 33, 'max_depth': 6, 'min_child_samples': 16, 'subsample': 0.8062156194022772, 'colsample_bytree': 0.8819211132138476, 'reg_alpha': 0.006162587992706761, 'reg_lambda': 0.9562734794803945}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:53,293] Trial 20 finished with value: 0.1668858888241367 and parameters: {'n_estimators': 130, 'learning_rate': 0.1319766977181512, 'num_leaves': 51, 'max_depth': 4, 'min_child_samples': 23, 'subsample': 0.7302584092175809, 'colsample_bytree': 0.8087284726229288, 'reg_alpha': 1.2545799197671322e-07, 'reg_lambda': 0.00033363411551355816}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:55,309] Trial 21 finished with value: 0.15668842679716707 and parameters: {'n_estimators': 178, 'learning_rate': 0.05414639506613722, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 5, 'subsample': 0.8424762455605671, 'colsample_bytree': 0.8364962929023345, 'reg_alpha': 0.00011619016869572268, 'reg_lambda': 1.665431536911648e-05}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:56,994] Trial 22 finished with value: 0.15880161829666153 and parameters: {'n_estimators': 184, 'learning_rate': 0.06394357027724495, 'num_leaves': 57, 'max_depth': 5, 'min_child_samples': 9, 'subsample': 0.9143200659987409, 'colsample_bytree': 0.711279161863153, 'reg_alpha': 0.00019360875652916576, 'reg_lambda': 1.7976385178102675e-07}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:14:58,866] Trial 23 finished with value: 0.1642377378832781 and parameters: {'n_estimators': 227, 'learning_rate': 0.022136131858098453, 'num_leaves': 60, 'max_depth': 8, 'min_child_samples': 15, 'subsample': 0.8222760015491654, 'colsample_bytree': 0.8521842916215433, 'reg_alpha': 3.019233173320975e-05, 'reg_lambda': 4.070014921169851e-06}. Best is trial 11 with value: 0.15306525899547843.
[I 2025-04-14 18:15:00,522] Trial 24 finished with value: 0.15647579857575278 and parameters: {'n_estimators': 168, 'learning_rate': 0.09127932016095937, 'num_leaves': 56, 'max_depth': 4, 'min_child_samples': 5, 'subsample': 0.881266353391594, 'colsample_bytree': 0.7911267524625724, 'reg_alpha': 0.003137300913685536, 'reg_lambda': 0.00011888500536778827}. Best is trial 11 with value: 0.15306525899547843.

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.137583

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.172128

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.101599

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.230836

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.106816

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.107894

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.205999

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.105729

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.107781

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.112784

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.119220

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.106288

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.110707

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.159522

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.113723

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.175275

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.117511

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.114058

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.107706

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.095199

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.088777

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.100979

--- Best Results for Feeder=6, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.088777
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 118
  n_dense_layers: 0
  lstm_dropout_0: 0.23404914145337877
  lstm_dropout_1: 0.19981906966616403
  learning_rate: 0.006267757934529045

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=6, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=6, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 162, Version: v1.1_Final_Forecasting_20250414170537, Path Info: {"keras_model": "models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537.keras", "scalers_pkl": "models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537.keras', 'scalers_pkl': 'models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537_scalers.pkl'}
Detected separate Keras model (models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537.keras) and scalers (models/feeder_6/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170537_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.207648

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.107780

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.104236

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.111980

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.100573

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.107089

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.120793

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.113162

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.164301

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.118186

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.103031

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.104878

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.125545

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.102119

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.101783

--- Optuna Trial 15 for LSTM_Change_in_Load ---
[I 2025-04-14 18:15:04,234] A new study created in memory with name: tune-7-LSTM_Baseload-24hr
[I 2025-04-14 18:15:11,768] Trial 0 finished with value: 0.6290760636329651 and parameters: {'n_lstm_layers': 2, 'lstm_units': 68, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3508864884754487, 'lstm_dropout_1': 0.4404723985889377, 'dense_units_0': 38, 'dense_dropout_0': 0.2667342987909145, 'dense_units_1': 19, 'dense_dropout_1': 0.27426225831128487, 'learning_rate': 0.00010129367058452655}. Best is trial 0 with value: 0.6290760636329651.
[I 2025-04-14 18:15:16,355] Trial 1 finished with value: 0.23896579444408417 and parameters: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 2, 'lstm_dropout_0': 0.36532146440102686, 'dense_units_0': 24, 'dense_dropout_0': 0.3391104842025792, 'dense_units_1': 16, 'dense_dropout_1': 0.2597465795388354, 'learning_rate': 0.00923817930620616}. Best is trial 1 with value: 0.23896579444408417.
[I 2025-04-14 18:15:21,271] Trial 2 finished with value: 0.27297693490982056 and parameters: {'n_lstm_layers': 1, 'lstm_units': 33, 'n_dense_layers': 2, 'lstm_dropout_0': 0.45834528073577496, 'dense_units_0': 19, 'dense_dropout_0': 0.17726125608838453, 'dense_units_1': 43, 'dense_dropout_1': 0.2369064375495718, 'learning_rate': 0.0004972193826108034}. Best is trial 1 with value: 0.23896579444408417.
[I 2025-04-14 18:15:28,618] Trial 3 finished with value: 0.31032902002334595 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4471379129881329, 'lstm_dropout_1': 0.38513227354504176, 'learning_rate': 0.00013635012410955226}. Best is trial 1 with value: 0.23896579444408417.
[I 2025-04-14 18:15:35,884] Trial 4 finished with value: 0.16104084253311157 and parameters: {'n_lstm_layers': 2, 'lstm_units': 89, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3010824698451565, 'lstm_dropout_1': 0.17728220024850008, 'learning_rate': 0.003241378034797008}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:15:41,442] Trial 5 finished with value: 0.24881775677204132 and parameters: {'n_lstm_layers': 1, 'lstm_units': 37, 'n_dense_layers': 2, 'lstm_dropout_0': 0.44790793542044083, 'dense_units_0': 33, 'dense_dropout_0': 0.4017924366695037, 'dense_units_1': 25, 'dense_dropout_1': 0.18979387303533063, 'learning_rate': 0.0006901597957969998}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:15:45,854] Trial 6 finished with value: 0.1613345444202423 and parameters: {'n_lstm_layers': 1, 'lstm_units': 86, 'n_dense_layers': 0, 'lstm_dropout_0': 0.25412506497645737, 'learning_rate': 0.007596198377611623}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:15:50,343] Trial 7 finished with value: 0.16645479202270508 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.16014362151450837, 'dense_units_0': 55, 'dense_dropout_0': 0.2788915137174883, 'learning_rate': 0.0026404695259812224}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:15:58,257] Trial 8 finished with value: 0.2995217740535736 and parameters: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1962760421353917, 'lstm_dropout_1': 0.286949027808326, 'dense_units_0': 59, 'dense_dropout_0': 0.11481287294574033, 'learning_rate': 0.00013362826218744046}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:16:05,465] Trial 9 finished with value: 0.2307271510362625 and parameters: {'n_lstm_layers': 2, 'lstm_units': 35, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4884033445161945, 'lstm_dropout_1': 0.3538361304902141, 'dense_units_0': 22, 'dense_dropout_0': 0.1315900040620866, 'learning_rate': 0.0009917581122439387}. Best is trial 4 with value: 0.16104084253311157.
[I 2025-04-14 18:16:17,943] Trial 10 finished with value: 0.1422305405139923 and parameters: {'n_lstm_layers': 2, 'lstm_units': 123, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10571270722215823, 'lstm_dropout_1': 0.10645533192594242, 'learning_rate': 0.0026145123566707726}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:16:26,536] Trial 11 finished with value: 0.1504553109407425 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10879453088089207, 'lstm_dropout_1': 0.11313345915065508, 'learning_rate': 0.002806413957173153}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:16:33,402] Trial 12 finished with value: 0.1460414081811905 and parameters: {'n_lstm_layers': 2, 'lstm_units': 123, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10641137054968362, 'lstm_dropout_1': 0.10445394730619233, 'learning_rate': 0.002524582746550795}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:16:41,214] Trial 13 finished with value: 0.14564523100852966 and parameters: {'n_lstm_layers': 2, 'lstm_units': 121, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10785979859645804, 'lstm_dropout_1': 0.10910797711615419, 'learning_rate': 0.001690505373481494}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:16:49,160] Trial 14 finished with value: 0.1607101410627365 and parameters: {'n_lstm_layers': 2, 'lstm_units': 106, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2018679328219042, 'lstm_dropout_1': 0.2161688660159498, 'learning_rate': 0.0014161927319184307}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:16:57,155] Trial 15 finished with value: 0.27389299869537354 and parameters: {'n_lstm_layers': 2, 'lstm_units': 46, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1554111123967803, 'lstm_dropout_1': 0.2016660852833091, 'dense_units_0': 41, 'dense_dropout_0': 0.476706067911562, 'learning_rate': 0.00041429119971712436}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:17:05,122] Trial 16 finished with value: 0.16849929094314575 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 0, 'lstm_dropout_0': 0.24545223466849525, 'lstm_dropout_1': 0.14496434438445133, 'learning_rate': 0.0048974732840951956}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:17:13,341] Trial 17 finished with value: 0.19617757201194763 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 1, 'lstm_dropout_0': 0.149174118824262, 'lstm_dropout_1': 0.25155957873400203, 'dense_units_0': 16, 'dense_dropout_0': 0.4970803693378662, 'learning_rate': 0.0013095723915996413}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:17:21,109] Trial 18 finished with value: 0.2418881356716156 and parameters: {'n_lstm_layers': 2, 'lstm_units': 102, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2217134268771682, 'lstm_dropout_1': 0.1659973969502766, 'learning_rate': 0.0002672245902566555}. Best is trial 10 with value: 0.1422305405139923.
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.105702

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.105251

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.101254

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.102466

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.112858

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.126190

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.101457

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.102973

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.101580

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.102688

--- Best Results for Feeder=6, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.100573
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 116
  n_dense_layers: 0
  lstm_dropout_0: 0.49562958928984724
  lstm_dropout_1: 0.14974988853790872
  learning_rate: 0.000537599716249571

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=6, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 6, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=6, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=6, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 7 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 164, Version: v1.1_Final_Forecasting_20250414170550, Path Info: models/feeder_7/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170550.pkl
Loading artifact(s) based on path info: models/feeder_7/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170550.pkl
Detected single pickle artifact path: models/feeder_7/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170550.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170550.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170550.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.288870

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.302115

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.193540

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.301359

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.157023

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.296443

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.289855

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.233400

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.162110

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.162345

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.153718

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.153065

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.156942

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.163225

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.161972

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.256562

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.185886

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.193064

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.157714

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.175857

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.166886

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.156688

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.158802

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.164238

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.156476

--- Best Results for Feeder=7, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.153065
Best Hyperparameters:
  n_estimators: 198
[I 2025-04-14 18:17:28,647] Trial 19 finished with value: 0.15903808176517487 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.29624128410335365, 'lstm_dropout_1': 0.10848644346282275, 'dense_units_0': 26, 'dense_dropout_0': 0.2042763860078881, 'learning_rate': 0.004617586555329417}. Best is trial 10 with value: 0.1422305405139923.
[I 2025-04-14 18:17:33,319] Trial 20 finished with value: 0.13978862762451172 and parameters: {'n_lstm_layers': 1, 'lstm_units': 114, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10550129428397861, 'learning_rate': 0.001634085467102943}. Best is trial 20 with value: 0.13978862762451172.
[I 2025-04-14 18:17:38,099] Trial 21 finished with value: 0.1467779129743576 and parameters: {'n_lstm_layers': 1, 'lstm_units': 112, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10106039024396586, 'learning_rate': 0.001833540851305143}. Best is trial 20 with value: 0.13978862762451172.
[I 2025-04-14 18:17:43,418] Trial 22 finished with value: 0.14807520806789398 and parameters: {'n_lstm_layers': 1, 'lstm_units': 117, 'n_dense_layers': 0, 'lstm_dropout_0': 0.15004669227595174, 'learning_rate': 0.0009401142028296035}. Best is trial 20 with value: 0.13978862762451172.
[I 2025-04-14 18:17:48,408] Trial 23 finished with value: 0.13920839130878448 and parameters: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 0, 'lstm_dropout_0': 0.13541453088745595, 'learning_rate': 0.0017748430448362071}. Best is trial 23 with value: 0.13920839130878448.
[I 2025-04-14 18:17:53,184] Trial 24 finished with value: 0.14384682476520538 and parameters: {'n_lstm_layers': 1, 'lstm_units': 95, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17547236224372784, 'learning_rate': 0.005343501332714874}. Best is trial 23 with value: 0.13920839130878448.
[I 2025-04-14 18:17:54,765] A new study created in memory with name: tune-7-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:18:02,481] Trial 0 finished with value: 0.17564034461975098 and parameters: {'n_lstm_layers': 2, 'lstm_units': 63, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2338965637751053, 'lstm_dropout_1': 0.14747152859134213, 'dense_units_0': 62, 'dense_dropout_0': 0.11219207044345457, 'learning_rate': 0.00032489002038244436}. Best is trial 0 with value: 0.17564034461975098.
[I 2025-04-14 18:18:10,218] Trial 1 finished with value: 0.14522674679756165 and parameters: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.19387745256884942, 'lstm_dropout_1': 0.10935096370405498, 'learning_rate': 0.0005876701351168696}. Best is trial 1 with value: 0.14522674679756165.
[I 2025-04-14 18:18:15,318] Trial 2 finished with value: 0.11693631857633591 and parameters: {'n_lstm_layers': 1, 'lstm_units': 71, 'n_dense_layers': 0, 'lstm_dropout_0': 0.33405743004242, 'learning_rate': 0.0015407990674613063}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:23,939] Trial 3 finished with value: 0.2508009672164917 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 2, 'lstm_dropout_0': 0.10735329698891466, 'lstm_dropout_1': 0.13452873198239132, 'dense_units_0': 45, 'dense_dropout_0': 0.22093315905812322, 'dense_units_1': 16, 'dense_dropout_1': 0.2014642559958762, 'learning_rate': 0.0002279276194910384}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:31,959] Trial 4 finished with value: 0.1538238823413849 and parameters: {'n_lstm_layers': 2, 'lstm_units': 33, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3315725144160615, 'lstm_dropout_1': 0.38213136167374173, 'dense_units_0': 33, 'dense_dropout_0': 0.4457435693582167, 'dense_units_1': 34, 'dense_dropout_1': 0.17222209160730118, 'learning_rate': 0.0011265692569404153}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:37,466] Trial 5 finished with value: 0.12852880358695984 and parameters: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 2, 'lstm_dropout_0': 0.40606825363493637, 'dense_units_0': 29, 'dense_dropout_0': 0.2760813315973828, 'dense_units_1': 47, 'dense_dropout_1': 0.17744767310506676, 'learning_rate': 0.004434211764416298}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:45,536] Trial 6 finished with value: 0.20392853021621704 and parameters: {'n_lstm_layers': 2, 'lstm_units': 116, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18652655779715968, 'lstm_dropout_1': 0.12352370397359143, 'learning_rate': 0.00011894231521340617}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:53,590] Trial 7 finished with value: 0.17348241806030273 and parameters: {'n_lstm_layers': 2, 'lstm_units': 71, 'n_dense_layers': 1, 'lstm_dropout_0': 0.45661986126826315, 'lstm_dropout_1': 0.116441515841287, 'dense_units_0': 16, 'dense_dropout_0': 0.4709005768046457, 'learning_rate': 0.0007048706044974772}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:18:59,138] Trial 8 finished with value: 0.2755689024925232 and parameters: {'n_lstm_layers': 1, 'lstm_units': 64, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2157860149768138, 'dense_units_0': 28, 'dense_dropout_0': 0.22432594371692915, 'dense_units_1': 34, 'dense_dropout_1': 0.3392579191344354, 'learning_rate': 0.00010089642919906023}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:07,595] Trial 9 finished with value: 0.22699959576129913 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 2, 'lstm_dropout_0': 0.12745469646868576, 'lstm_dropout_1': 0.177275142144829, 'dense_units_0': 16, 'dense_dropout_0': 0.192832851208512, 'dense_units_1': 22, 'dense_dropout_1': 0.35758256694647417, 'learning_rate': 0.00022495876919878755}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:12,514] Trial 10 finished with value: 0.11803150177001953 and parameters: {'n_lstm_layers': 1, 'lstm_units': 45, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3303884147744588, 'learning_rate': 0.0031914701125662936}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:17,618] Trial 11 finished with value: 0.11870376765727997 and parameters: {'n_lstm_layers': 1, 'lstm_units': 44, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32994694262956076, 'learning_rate': 0.003220891730301912}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:21,544] Trial 12 finished with value: 0.12919537723064423 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 0, 'lstm_dropout_0': 0.37881451686695045, 'learning_rate': 0.00969299814130653}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:26,462] Trial 13 finished with value: 0.13522087037563324 and parameters: {'n_lstm_layers': 1, 'lstm_units': 49, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26515955146668085, 'dense_units_0': 22, 'dense_dropout_0': 0.34489068547055707, 'learning_rate': 0.0018715545562871306}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:31,310] Trial 14 finished with value: 0.13123026490211487 and parameters: {'n_lstm_layers': 1, 'lstm_units': 36, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49492730334077634, 'learning_rate': 0.0021230805423863883}. Best is trial 2 with value: 0.11693631857633591.
[I 2025-04-14 18:19:35,812] Trial 15 finished with value: 0.1137830838561058 and parameters: {'n_lstm_layers': 1, 'lstm_units': 87, 'n_dense_layers': 0, 'lstm_dropout_0': 0.28668509036197204, 'learning_rate': 0.005932343474320879}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:19:40,919] Trial 16 finished with value: 0.12650033831596375 and parameters: {'n_lstm_layers': 1, 'lstm_units': 93, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2798899412315026, 'dense_units_0': 64, 'dense_dropout_0': 0.3780667873144618, 'learning_rate': 0.009685571539756134}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:19:45,590] Trial 17 finished with value: 0.11677651107311249 and parameters: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3834600598697249, 'learning_rate': 0.005140450086057357}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:19:50,374] Trial 18 finished with value: 0.12075197696685791 and parameters: {'n_lstm_layers': 1, 'lstm_units': 91, 'n_dense_layers': 1, 'lstm_dropout_0': 0.39845401386525964, 'dense_units_0': 44, 'dense_dropout_0': 0.11178815947355203, 'learning_rate': 0.005231388822262214}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:19:54,081] Trial 19 finished with value: 0.12257542461156845 and parameters: {'n_lstm_layers': 1, 'lstm_units': 102, 'n_dense_layers': 0, 'lstm_dropout_0': 0.457259999953298, 'learning_rate': 0.005870161758106344}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:19:58,872] Trial 20 finished with value: 0.13648809492588043 and parameters: {'n_lstm_layers': 1, 'lstm_units': 81, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3739871656702304, 'dense_units_0': 22, 'dense_dropout_0': 0.391091059304574, 'learning_rate': 0.006856428094038995}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:20:03,953] Trial 21 finished with value: 0.11760406196117401 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3076151622561947, 'learning_rate': 0.0016469082515981196}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:20:08,839] Trial 22 finished with value: 0.11395635455846786 and parameters: {'n_lstm_layers': 1, 'lstm_units': 69, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3577850152264406, 'learning_rate': 0.003463306315052967}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:20:13,640] Trial 23 finished with value: 0.11722278594970703 and parameters: {'n_lstm_layers': 1, 'lstm_units': 111, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4263495777979493, 'learning_rate': 0.0027535850156729653}. Best is trial 15 with value: 0.1137830838561058.
[I 2025-04-14 18:20:18,642] Trial 24 finished with value: 0.11932441592216492 and parameters: {'n_lstm_layers': 1, 'lstm_units': 55, 'n_dense_layers': 0, 'lstm_dropout_0': 0.36071643432195616, 'learning_rate': 0.004167198722423464}. Best is trial 15 with value: 0.1137830838561058.
  learning_rate: 0.0712077716299931
  num_leaves: 60
  max_depth: 4
  min_child_samples: 5
  subsample: 0.8535759889033576
  colsample_bytree: 0.8376771882983307
  reg_alpha: 0.00046509175327640517
  reg_lambda: 1.1379492797485943e-05

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=7, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=7, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=7, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 165, Version: v1.1_Final_Forecasting_20250414170554, Path Info: {"keras_model": "models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554.keras", "scalers_pkl": "models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554.keras', 'scalers_pkl': 'models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554_scalers.pkl'}
Detected separate Keras model (models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554.keras) and scalers (models/feeder_7/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170554_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.629076

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.238966

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.272977

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.310329

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.161041

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.248818

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.161335

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.166455

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.299522

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.230727

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.142231

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.150455

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.146041

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.145645

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.160710

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.273893

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.168499

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.196178

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.241888
[I 2025-04-14 18:20:19,749] A new study created in memory with name: tune-8-LightGBM_Baseline-24hr
[I 2025-04-14 18:20:24,192] Trial 0 finished with value: 0.19045043842494516 and parameters: {'n_estimators': 204, 'learning_rate': 0.14204998344011394, 'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 44, 'subsample': 0.8084873357789248, 'colsample_bytree': 0.5346954510349626, 'reg_alpha': 3.0738526334074497e-07, 'reg_lambda': 0.03622704422340544}. Best is trial 0 with value: 0.19045043842494516.
[I 2025-04-14 18:20:24,968] Trial 1 finished with value: 0.19328533103200266 and parameters: {'n_estimators': 186, 'learning_rate': 0.012481479762961736, 'num_leaves': 57, 'max_depth': 6, 'min_child_samples': 45, 'subsample': 0.7594788034111425, 'colsample_bytree': 0.8422652022380889, 'reg_alpha': 0.07402220965776747, 'reg_lambda': 0.014630816352218499}. Best is trial 0 with value: 0.19045043842494516.
[I 2025-04-14 18:20:26,505] Trial 2 finished with value: 0.14025204620652756 and parameters: {'n_estimators': 95, 'learning_rate': 0.011839812059972957, 'num_leaves': 20, 'max_depth': 7, 'min_child_samples': 5, 'subsample': 0.6247500483907487, 'colsample_bytree': 0.8681093920768927, 'reg_alpha': 6.265838024761421e-05, 'reg_lambda': 0.16942210002377317}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:27,396] Trial 3 finished with value: 0.19346844704331365 and parameters: {'n_estimators': 268, 'learning_rate': 0.021373730668581545, 'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 47, 'subsample': 0.5249993671009302, 'colsample_bytree': 0.5345275369343466, 'reg_alpha': 0.00010732371199861266, 'reg_lambda': 0.022390198764109512}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:27,916] Trial 4 finished with value: 0.16076876864205095 and parameters: {'n_estimators': 60, 'learning_rate': 0.03721285080432289, 'num_leaves': 18, 'max_depth': 10, 'min_child_samples': 27, 'subsample': 0.7743713963412927, 'colsample_bytree': 0.7290086821457542, 'reg_alpha': 0.3002105353585964, 'reg_lambda': 0.42516628535699663}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:29,420] Trial 5 finished with value: 0.18746647649652115 and parameters: {'n_estimators': 276, 'learning_rate': 0.0013896701534976933, 'num_leaves': 39, 'max_depth': 6, 'min_child_samples': 39, 'subsample': 0.8958154388681396, 'colsample_bytree': 0.8962955529887398, 'reg_alpha': 0.6291971827647913, 'reg_lambda': 2.6643293728291097e-08}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:30,798] Trial 6 finished with value: 0.18518255825169114 and parameters: {'n_estimators': 162, 'learning_rate': 0.001512218763877242, 'num_leaves': 53, 'max_depth': 12, 'min_child_samples': 19, 'subsample': 0.5754447224350765, 'colsample_bytree': 0.8642504000437183, 'reg_alpha': 0.0007452250705041515, 'reg_lambda': 7.114814489625423e-06}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:31,299] Trial 7 finished with value: 0.17009498936537504 and parameters: {'n_estimators': 94, 'learning_rate': 0.020809871015406087, 'num_leaves': 15, 'max_depth': 5, 'min_child_samples': 36, 'subsample': 0.7855422436261035, 'colsample_bytree': 0.9590871031661043, 'reg_alpha': 1.566322995973773e-08, 'reg_lambda': 4.94671966399595e-07}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:34,178] Trial 8 finished with value: 0.15055232131388496 and parameters: {'n_estimators': 281, 'learning_rate': 0.0032788689767914835, 'num_leaves': 20, 'max_depth': 10, 'min_child_samples': 14, 'subsample': 0.5138266387100273, 'colsample_bytree': 0.91115187945558, 'reg_alpha': 2.2110381767787913e-08, 'reg_lambda': 4.063561446632423e-05}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:34,895] Trial 9 finished with value: 0.1928950255339027 and parameters: {'n_estimators': 150, 'learning_rate': 0.035497236737014784, 'num_leaves': 13, 'max_depth': 9, 'min_child_samples': 45, 'subsample': 0.6202763383121008, 'colsample_bytree': 0.6435138216779686, 'reg_alpha': 3.5849758631943996e-05, 'reg_lambda': 1.0887166347000436e-06}. Best is trial 2 with value: 0.14025204620652756.
[I 2025-04-14 18:20:35,807] Trial 10 finished with value: 0.11707447735964686 and parameters: {'n_estimators': 110, 'learning_rate': 0.2589233343252431, 'num_leaves': 27, 'max_depth': 3, 'min_child_samples': 5, 'subsample': 0.6650815773475358, 'colsample_bytree': 0.7622435472092128, 'reg_alpha': 3.058586414030353e-06, 'reg_lambda': 0.0007125278089305183}. Best is trial 10 with value: 0.11707447735964686.
[I 2025-04-14 18:20:36,697] Trial 11 finished with value: 0.11551248906312317 and parameters: {'n_estimators': 110, 'learning_rate': 0.2628108256631422, 'num_leaves': 27, 'max_depth': 3, 'min_child_samples': 5, 'subsample': 0.6706705358915175, 'colsample_bytree': 0.7667036853185443, 'reg_alpha': 2.8792669249886505e-06, 'reg_lambda': 0.00042952998352949233}. Best is trial 11 with value: 0.11551248906312317.
[I 2025-04-14 18:20:37,914] Trial 12 finished with value: 0.11879323854809859 and parameters: {'n_estimators': 121, 'learning_rate': 0.2749563692179023, 'num_leaves': 28, 'max_depth': 3, 'min_child_samples': 5, 'subsample': 0.6707432501690417, 'colsample_bytree': 0.7278086914343943, 'reg_alpha': 1.7112624108706165e-06, 'reg_lambda': 0.0009299233149644117}. Best is trial 11 with value: 0.11551248906312317.
[I 2025-04-14 18:20:38,635] Trial 13 finished with value: 0.11660593396585794 and parameters: {'n_estimators': 58, 'learning_rate': 0.09735274966793102, 'num_leaves': 45, 'max_depth': 3, 'min_child_samples': 14, 'subsample': 0.684243296266495, 'colsample_bytree': 0.7798865574773295, 'reg_alpha': 3.04129118708335e-06, 'reg_lambda': 0.000662746896881119}. Best is trial 11 with value: 0.11551248906312317.
[I 2025-04-14 18:20:39,205] Trial 14 finished with value: 0.11484404443114325 and parameters: {'n_estimators': 53, 'learning_rate': 0.08274679703664146, 'num_leaves': 45, 'max_depth': 4, 'min_child_samples': 16, 'subsample': 0.7052973498144763, 'colsample_bytree': 0.7873966100360492, 'reg_alpha': 0.001829701432791697, 'reg_lambda': 0.0005404293524667066}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:39,833] Trial 15 finished with value: 0.11740099296392954 and parameters: {'n_estimators': 50, 'learning_rate': 0.08007147164535362, 'num_leaves': 46, 'max_depth': 5, 'min_child_samples': 14, 'subsample': 0.873251800421528, 'colsample_bytree': 0.6394530557191007, 'reg_alpha': 0.006173172374510463, 'reg_lambda': 0.00010349160128634502}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:42,026] Trial 16 finished with value: 0.1437123415071572 and parameters: {'n_estimators': 225, 'learning_rate': 0.06547860923343096, 'num_leaves': 45, 'max_depth': 4, 'min_child_samples': 23, 'subsample': 0.9605715625775638, 'colsample_bytree': 0.6588202678100599, 'reg_alpha': 0.00384300946924152, 'reg_lambda': 0.0029131863037644644}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:43,460] Trial 17 finished with value: 0.11667063935227857 and parameters: {'n_estimators': 138, 'learning_rate': 0.12612589975759708, 'num_leaves': 35, 'max_depth': 4, 'min_child_samples': 10, 'subsample': 0.7163941468867702, 'colsample_bytree': 0.9938125132655187, 'reg_alpha': 0.020176852343745916, 'reg_lambda': 5.607376766547649e-05}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:44,178] Trial 18 finished with value: 0.11903482469637838 and parameters: {'n_estimators': 83, 'learning_rate': 0.19071974255453322, 'num_leaves': 51, 'max_depth': 5, 'min_child_samples': 19, 'subsample': 0.8329303116192253, 'colsample_bytree': 0.801399495247417, 'reg_alpha': 0.00036247914742053235, 'reg_lambda': 6.165049309885889e-06}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:45,207] Trial 19 finished with value: 0.1160687511764386 and parameters: {'n_estimators': 80, 'learning_rate': 0.04641431870849113, 'num_leaves': 25, 'max_depth': 7, 'min_child_samples': 10, 'subsample': 0.729961896940028, 'colsample_bytree': 0.7105459316814754, 'reg_alpha': 2.9029170753629614e-07, 'reg_lambda': 0.003270330522247345}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:46,053] Trial 20 finished with value: 0.1784306674604892 and parameters: {'n_estimators': 125, 'learning_rate': 0.005752999658447438, 'num_leaves': 41, 'max_depth': 4, 'min_child_samples': 30, 'subsample': 0.5769943979215035, 'colsample_bytree': 0.8075109604735583, 'reg_alpha': 1.3582901398364875e-05, 'reg_lambda': 0.00019734310850466649}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:47,325] Trial 21 finished with value: 0.11583842322185411 and parameters: {'n_estimators': 80, 'learning_rate': 0.04826347111490581, 'num_leaves': 24, 'max_depth': 7, 'min_child_samples': 10, 'subsample': 0.7148700237127069, 'colsample_bytree': 0.6917671408166963, 'reg_alpha': 1.5226753538420335e-07, 'reg_lambda': 0.00401314472527223}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:48,458] Trial 22 finished with value: 0.11617207365963027 and parameters: {'n_estimators': 76, 'learning_rate': 0.0648627807023534, 'num_leaves': 34, 'max_depth': 8, 'min_child_samples': 9, 'subsample': 0.7046831303182087, 'colsample_bytree': 0.59051916290018, 'reg_alpha': 2.2299535511191779e-07, 'reg_lambda': 0.007174423300130261}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:49,420] Trial 23 finished with value: 0.11716291574201686 and parameters: {'n_estimators': 107, 'learning_rate': 0.1464964580929241, 'num_leaves': 24, 'max_depth': 6, 'min_child_samples': 17, 'subsample': 0.6152705138319439, 'colsample_bytree': 0.7019605923886686, 'reg_alpha': 4.8950209090557e-08, 'reg_lambda': 0.11019087257376826}. Best is trial 14 with value: 0.11484404443114325.
[I 2025-04-14 18:20:50,064] Trial 24 finished with value: 0.15078835334904983 and parameters: {'n_estimators': 71, 'learning_rate': 0.04505580945191771, 'num_leaves': 30, 'max_depth': 4, 'min_child_samples': 23, 'subsample': 0.6508036485502561, 'colsample_bytree': 0.6819406589866116, 'reg_alpha': 1.0252286283382301e-05, 'reg_lambda': 0.00024364417784343182}. Best is trial 14 with value: 0.11484404443114325.

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.159038

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.139789

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.146778

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.148075

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.139208

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.143847

--- Best Results for Feeder=7, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.139208
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 97
  n_dense_layers: 0
  lstm_dropout_0: 0.13541453088745595
  learning_rate: 0.0017748430448362071

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=7, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=7, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 166, Version: v1.1_Final_Forecasting_20250414170603, Path Info: {"keras_model": "models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603.keras", "scalers_pkl": "models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603.keras', 'scalers_pkl': 'models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603_scalers.pkl'}
Detected separate Keras model (models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603.keras) and scalers (models/feeder_7/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170603_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.175640

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.145227

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.116936

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.250801

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.153824

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.128529

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.203929

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.173482

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.275569

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.227000

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.118032

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.118704

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.129195

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.135221

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.131230

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.113783

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.126500

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.116777

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.120752

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.122575

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.136488

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.117604

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.113956

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.117223

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.119324

--- Best Results for Feeder=7, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.113783
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 87
  n_dense_layers: 0
  lstm_dropout_0: 0.28668509036197204
  learning_rate: 0.005932343474320879

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=7, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
[I 2025-04-14 18:20:52,786] A new study created in memory with name: tune-8-LSTM_Baseload-24hr
[I 2025-04-14 18:20:59,783] Trial 0 finished with value: 0.13783417642116547 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 1, 'lstm_dropout_0': 0.23160273061626319, 'lstm_dropout_1': 0.1149883702119134, 'dense_units_0': 20, 'dense_dropout_0': 0.19957638734326522, 'learning_rate': 0.005276920259539561}. Best is trial 0 with value: 0.13783417642116547.
[I 2025-04-14 18:21:05,321] Trial 1 finished with value: 0.23475585877895355 and parameters: {'n_lstm_layers': 1, 'lstm_units': 50, 'n_dense_layers': 2, 'lstm_dropout_0': 0.40327435090984665, 'dense_units_0': 50, 'dense_dropout_0': 0.10104634063482627, 'dense_units_1': 39, 'dense_dropout_1': 0.22694513223147725, 'learning_rate': 0.00014232018383283625}. Best is trial 0 with value: 0.13783417642116547.
[I 2025-04-14 18:21:13,290] Trial 2 finished with value: 0.421806663274765 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 2, 'lstm_dropout_0': 0.215410407135693, 'lstm_dropout_1': 0.15969039266718174, 'dense_units_0': 20, 'dense_dropout_0': 0.2923985834142816, 'dense_units_1': 19, 'dense_dropout_1': 0.4973076568397178, 'learning_rate': 0.00010912123351456246}. Best is trial 0 with value: 0.13783417642116547.
[I 2025-04-14 18:21:21,039] Trial 3 finished with value: 0.21773618459701538 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2587798943605726, 'lstm_dropout_1': 0.15838808243498925, 'learning_rate': 0.00014205309767862135}. Best is trial 0 with value: 0.13783417642116547.
[I 2025-04-14 18:21:26,410] Trial 4 finished with value: 0.1320381909608841 and parameters: {'n_lstm_layers': 1, 'lstm_units': 112, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20656883449459917, 'learning_rate': 0.0027998977934862754}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:21:33,885] Trial 5 finished with value: 0.221269428730011 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 0, 'lstm_dropout_0': 0.29506375240988225, 'lstm_dropout_1': 0.10997205823230086, 'learning_rate': 0.00026990781302837076}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:21:40,938] Trial 6 finished with value: 0.1565241813659668 and parameters: {'n_lstm_layers': 2, 'lstm_units': 90, 'n_dense_layers': 0, 'lstm_dropout_0': 0.13560155417204728, 'lstm_dropout_1': 0.3020977744835652, 'learning_rate': 0.0037682383185095674}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:21:48,937] Trial 7 finished with value: 0.26343271136283875 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 1, 'lstm_dropout_0': 0.46204793309673475, 'lstm_dropout_1': 0.49377350647529483, 'dense_units_0': 25, 'dense_dropout_0': 0.3028218981369588, 'learning_rate': 0.00014989435506812472}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:21:56,550] Trial 8 finished with value: 0.14829665422439575 and parameters: {'n_lstm_layers': 2, 'lstm_units': 43, 'n_dense_layers': 2, 'lstm_dropout_0': 0.34249804289310526, 'lstm_dropout_1': 0.24997794627784697, 'dense_units_0': 30, 'dense_dropout_0': 0.22372222112508458, 'dense_units_1': 25, 'dense_dropout_1': 0.38284133376447216, 'learning_rate': 0.0009446548775650076}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:04,024] Trial 9 finished with value: 0.13531769812107086 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2702750155474554, 'lstm_dropout_1': 0.4531492881714577, 'dense_units_0': 27, 'dense_dropout_0': 0.32413583427951054, 'dense_units_1': 17, 'dense_dropout_1': 0.2230977995881463, 'learning_rate': 0.005343554818423554}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:08,521] Trial 10 finished with value: 0.1321677267551422 and parameters: {'n_lstm_layers': 1, 'lstm_units': 122, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10994970821152977, 'learning_rate': 0.0015775437414381735}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:13,464] Trial 11 finished with value: 0.1326265186071396 and parameters: {'n_lstm_layers': 1, 'lstm_units': 124, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10636195699534723, 'learning_rate': 0.0015211968183326703}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:17,986] Trial 12 finished with value: 0.14712823927402496 and parameters: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 1, 'lstm_dropout_0': 0.16605794502021043, 'dense_units_0': 61, 'dense_dropout_0': 0.4707204918752804, 'learning_rate': 0.0015549314077258547}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:22,769] Trial 13 finished with value: 0.15128718316555023 and parameters: {'n_lstm_layers': 1, 'lstm_units': 128, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18360264720721137, 'learning_rate': 0.000791458372784901}. Best is trial 4 with value: 0.1320381909608841.
[I 2025-04-14 18:22:27,484] Trial 14 finished with value: 0.12569957971572876 and parameters: {'n_lstm_layers': 1, 'lstm_units': 78, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10434836284218267, 'learning_rate': 0.00251665208851499}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:31,565] Trial 15 finished with value: 0.15961714088916779 and parameters: {'n_lstm_layers': 1, 'lstm_units': 70, 'n_dense_layers': 1, 'lstm_dropout_0': 0.17510817468393114, 'dense_units_0': 41, 'dense_dropout_0': 0.4671135405904747, 'learning_rate': 0.009654615381011866}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:36,045] Trial 16 finished with value: 0.14030027389526367 and parameters: {'n_lstm_layers': 1, 'lstm_units': 71, 'n_dense_layers': 0, 'lstm_dropout_0': 0.33481973322616254, 'learning_rate': 0.0027963360582193932}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:41,009] Trial 17 finished with value: 0.166477233171463 and parameters: {'n_lstm_layers': 1, 'lstm_units': 105, 'n_dense_layers': 1, 'lstm_dropout_0': 0.20927395112060113, 'dense_units_0': 39, 'dense_dropout_0': 0.3995448313072406, 'learning_rate': 0.000521458917309886}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:45,797] Trial 18 finished with value: 0.12806078791618347 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.146226877485463, 'learning_rate': 0.0028498477895534937}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:49,625] Trial 19 finished with value: 0.15698643028736115 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1439410452561963, 'dense_units_0': 17, 'dense_dropout_0': 0.13170162647216227, 'learning_rate': 0.008839158130055072}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:54,448] Trial 20 finished with value: 0.1304575800895691 and parameters: {'n_lstm_layers': 1, 'lstm_units': 65, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1084014599527173, 'learning_rate': 0.002541341218328841}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:22:59,191] Trial 21 finished with value: 0.12790842354297638 and parameters: {'n_lstm_layers': 1, 'lstm_units': 66, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1023593574751363, 'learning_rate': 0.0022629996791954767}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:23:03,716] Trial 22 finished with value: 0.12912598252296448 and parameters: {'n_lstm_layers': 1, 'lstm_units': 76, 'n_dense_layers': 0, 'lstm_dropout_0': 0.15060023626644028, 'learning_rate': 0.004728854168636407}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:23:08,503] Trial 23 finished with value: 0.1408107727766037 and parameters: {'n_lstm_layers': 1, 'lstm_units': 89, 'n_dense_layers': 0, 'lstm_dropout_0': 0.104201259010716, 'learning_rate': 0.0019814426146641134}. Best is trial 14 with value: 0.12569957971572876.
[I 2025-04-14 18:23:13,024] Trial 24 finished with value: 0.16738612949848175 and parameters: {'n_lstm_layers': 1, 'lstm_units': 61, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1420225816096828, 'learning_rate': 0.000592663206285523}. Best is trial 14 with value: 0.12569957971572876.
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 7, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=7, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=7, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 8 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 168, Version: v1.1_Final_Forecasting_20250414170615, Path Info: models/feeder_8/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170615.pkl
Loading artifact(s) based on path info: models/feeder_8/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170615.pkl
Detected single pickle artifact path: models/feeder_8/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170615.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170615.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170615.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.190450

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.193285

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.140252

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.193468

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.160769

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.187466

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.185183

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.170095

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.150552

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.192895

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.117074

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.115512

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.118793

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.116606

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.114844

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.117401

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.143712

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.116671

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.119035

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.116069

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.178431

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.115838

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.116172

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.117163

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.150788

--- Best Results for Feeder=8, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.114844
Best Hyperparameters:
  n_estimators: 53
  learning_rate: 0.08274679703664146
  num_leaves: 45
  max_depth: 4
  min_child_samples: 16
  subsample: 0.7052973498144763
  colsample_bytree: 0.7873966100360492
  reg_alpha: 0.001829701432791697
  reg_lambda: 0.0005404293524667066

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=8, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=8, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
[I 2025-04-14 18:23:15,320] A new study created in memory with name: tune-8-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:23:22,730] Trial 0 finished with value: 0.10886061936616898 and parameters: {'n_lstm_layers': 2, 'lstm_units': 36, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17682532547045013, 'lstm_dropout_1': 0.1994260227290724, 'learning_rate': 0.0024266902481477493}. Best is trial 0 with value: 0.10886061936616898.
[I 2025-04-14 18:23:29,908] Trial 1 finished with value: 0.10169016569852829 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 2, 'lstm_dropout_0': 0.20349762410736383, 'lstm_dropout_1': 0.403824111083975, 'dense_units_0': 39, 'dense_dropout_0': 0.4064176141030723, 'dense_units_1': 55, 'dense_dropout_1': 0.19439064550285712, 'learning_rate': 0.008220708982888044}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:23:37,116] Trial 2 finished with value: 0.11100710928440094 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 1, 'lstm_dropout_0': 0.13168863695896926, 'lstm_dropout_1': 0.11775657378654132, 'dense_units_0': 20, 'dense_dropout_0': 0.34664709828442763, 'learning_rate': 0.0016740457199304424}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:23:42,125] Trial 3 finished with value: 0.22324348986148834 and parameters: {'n_lstm_layers': 1, 'lstm_units': 104, 'n_dense_layers': 1, 'lstm_dropout_0': 0.19982963834271153, 'dense_units_0': 45, 'dense_dropout_0': 0.4587984638325766, 'learning_rate': 0.00011697052006990759}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:23:47,128] Trial 4 finished with value: 0.10912106931209564 and parameters: {'n_lstm_layers': 1, 'lstm_units': 66, 'n_dense_layers': 2, 'lstm_dropout_0': 0.20336074638617263, 'dense_units_0': 45, 'dense_dropout_0': 0.2326600729782876, 'dense_units_1': 29, 'dense_dropout_1': 0.4456738548722775, 'learning_rate': 0.0017883969056129037}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:23:54,667] Trial 5 finished with value: 0.1068025603890419 and parameters: {'n_lstm_layers': 2, 'lstm_units': 111, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1846085478941927, 'lstm_dropout_1': 0.3068555589815509, 'dense_units_0': 20, 'dense_dropout_0': 0.3717530276361485, 'dense_units_1': 17, 'dense_dropout_1': 0.3707449137850167, 'learning_rate': 0.005305925757840175}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:24:02,279] Trial 6 finished with value: 0.10505685210227966 and parameters: {'n_lstm_layers': 2, 'lstm_units': 103, 'n_dense_layers': 1, 'lstm_dropout_0': 0.48816457481786335, 'lstm_dropout_1': 0.32579400636439304, 'dense_units_0': 33, 'dense_dropout_0': 0.2844184504005614, 'learning_rate': 0.0017478772825886887}. Best is trial 1 with value: 0.10169016569852829.
[I 2025-04-14 18:24:09,679] Trial 7 finished with value: 0.09988164901733398 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 1, 'lstm_dropout_0': 0.28833376751242135, 'lstm_dropout_1': 0.13560188344451826, 'dense_units_0': 35, 'dense_dropout_0': 0.3146530144304064, 'learning_rate': 0.006327309528050936}. Best is trial 7 with value: 0.09988164901733398.
[I 2025-04-14 18:24:17,050] Trial 8 finished with value: 0.11361406743526459 and parameters: {'n_lstm_layers': 2, 'lstm_units': 87, 'n_dense_layers': 1, 'lstm_dropout_0': 0.46880168078700013, 'lstm_dropout_1': 0.4058854300173399, 'dense_units_0': 38, 'dense_dropout_0': 0.4055473380190239, 'learning_rate': 0.00107769186011839}. Best is trial 7 with value: 0.09988164901733398.
[I 2025-04-14 18:24:24,600] Trial 9 finished with value: 0.10111931711435318 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 2, 'lstm_dropout_0': 0.41269297440701624, 'lstm_dropout_1': 0.33037053066924066, 'dense_units_0': 37, 'dense_dropout_0': 0.23246835345434724, 'dense_units_1': 43, 'dense_dropout_1': 0.25809163441037664, 'learning_rate': 0.0037246328507036285}. Best is trial 7 with value: 0.09988164901733398.
[I 2025-04-14 18:24:29,084] Trial 10 finished with value: 0.14065329730510712 and parameters: {'n_lstm_layers': 1, 'lstm_units': 41, 'n_dense_layers': 0, 'lstm_dropout_0': 0.30881433454382307, 'learning_rate': 0.00036858374487491323}. Best is trial 7 with value: 0.09988164901733398.
[I 2025-04-14 18:24:36,888] Trial 11 finished with value: 0.0984063521027565 and parameters: {'n_lstm_layers': 2, 'lstm_units': 50, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3658954649238185, 'lstm_dropout_1': 0.21554559347667882, 'dense_units_0': 59, 'dense_dropout_0': 0.10073885924604259, 'dense_units_1': 51, 'dense_dropout_1': 0.10667216924023493, 'learning_rate': 0.0046435408312779595}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:24:44,145] Trial 12 finished with value: 0.10152619332075119 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3069711472826102, 'lstm_dropout_1': 0.17445253175989484, 'learning_rate': 0.009763490566940028}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:24:51,828] Trial 13 finished with value: 0.11127211898565292 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 1, 'lstm_dropout_0': 0.37669208527990267, 'lstm_dropout_1': 0.21913279198507057, 'dense_units_0': 60, 'dense_dropout_0': 0.11366297817480225, 'learning_rate': 0.0005551443835128169}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:24:56,593] Trial 14 finished with value: 0.10153314471244812 and parameters: {'n_lstm_layers': 1, 'lstm_units': 33, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3646953944468181, 'dense_units_0': 62, 'dense_dropout_0': 0.10039383618433992, 'dense_units_1': 64, 'dense_dropout_1': 0.11348168142189635, 'learning_rate': 0.0040650718939975235}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:04,430] Trial 15 finished with value: 0.10089944303035736 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2647044956301492, 'lstm_dropout_1': 0.10348152517667647, 'dense_units_0': 26, 'dense_dropout_0': 0.18088320122784965, 'learning_rate': 0.006272198412837198}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:12,033] Trial 16 finished with value: 0.10491783916950226 and parameters: {'n_lstm_layers': 2, 'lstm_units': 75, 'n_dense_layers': 2, 'lstm_dropout_0': 0.26027836653430425, 'lstm_dropout_1': 0.24595871982080098, 'dense_units_0': 25, 'dense_dropout_0': 0.29921654896558686, 'dense_units_1': 32, 'dense_dropout_1': 0.10640844121923873, 'learning_rate': 0.003485251906105848}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:16,506] Trial 17 finished with value: 0.11622340232133865 and parameters: {'n_lstm_layers': 1, 'lstm_units': 50, 'n_dense_layers': 0, 'lstm_dropout_0': 0.35485442174742593, 'learning_rate': 0.0007434819226127816}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:24,163] Trial 18 finished with value: 0.22763995826244354 and parameters: {'n_lstm_layers': 2, 'lstm_units': 41, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4299611699196711, 'lstm_dropout_1': 0.15417578033761567, 'dense_units_0': 52, 'dense_dropout_0': 0.49697595651363985, 'learning_rate': 0.00011812111297604793}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:31,616] Trial 19 finished with value: 0.24440765380859375 and parameters: {'n_lstm_layers': 2, 'lstm_units': 59, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26807409460323334, 'lstm_dropout_1': 0.492977727655024, 'dense_units_0': 16, 'dense_dropout_0': 0.1807489544437146, 'learning_rate': 0.0002143015444800196}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:36,786] Trial 20 finished with value: 0.10161712765693665 and parameters: {'n_lstm_layers': 1, 'lstm_units': 128, 'n_dense_layers': 2, 'lstm_dropout_0': 0.31312148755507946, 'dense_units_0': 28, 'dense_dropout_0': 0.22955985112478583, 'dense_units_1': 39, 'dense_dropout_1': 0.2779080950711127, 'learning_rate': 0.002565688952019054}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:44,168] Trial 21 finished with value: 0.09993212670087814 and parameters: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2412131084931815, 'lstm_dropout_1': 0.10860366214084892, 'dense_units_0': 25, 'dense_dropout_0': 0.1509642377699424, 'learning_rate': 0.00624377110136364}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:51,972] Trial 22 finished with value: 0.10226272791624069 and parameters: {'n_lstm_layers': 2, 'lstm_units': 41, 'n_dense_layers': 1, 'lstm_dropout_0': 0.23713871114714802, 'lstm_dropout_1': 0.14683148893708545, 'dense_units_0': 22, 'dense_dropout_0': 0.14043696127966093, 'learning_rate': 0.006162024902400143}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:25:59,565] Trial 23 finished with value: 0.10058610141277313 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3360319681711138, 'lstm_dropout_1': 0.26026348076432215, 'dense_units_0': 31, 'dense_dropout_0': 0.15791722362687366, 'learning_rate': 0.008832271132845388}. Best is trial 11 with value: 0.0984063521027565.
[I 2025-04-14 18:26:06,788] Trial 24 finished with value: 0.1003701314330101 and parameters: {'n_lstm_layers': 2, 'lstm_units': 72, 'n_dense_layers': 0, 'lstm_dropout_0': 0.11116782750785206, 'lstm_dropout_1': 0.10220896965441055, 'learning_rate': 0.0049119081285990815}. Best is trial 11 with value: 0.0984063521027565.
Selecting model for Feeder 8, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=8, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 169, Version: v1.1_Final_Forecasting_20250414170618, Path Info: {"keras_model": "models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618.keras", "scalers_pkl": "models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618.keras', 'scalers_pkl': 'models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618_scalers.pkl'}
Detected separate Keras model (models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618.keras) and scalers (models/feeder_8/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170618_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.137834

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.234756

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.421807

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.217736

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.132038

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.221269

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.156524

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.263433

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.148297

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.135318

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.132168

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.132627

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.147128

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.151287

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.125700

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.159617

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.140300

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.166477

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.128061

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.156986

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.130458

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.127908

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.129126

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.140811

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.167386

--- Best Results for Feeder=8, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.125700
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 78
  n_dense_layers: 0
  lstm_dropout_0: 0.10434836284218267
  learning_rate: 0.00251665208851499

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=8, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=8, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
[I 2025-04-14 18:26:08,310] A new study created in memory with name: tune-9-LightGBM_Baseline-24hr
[I 2025-04-14 18:26:12,523] Trial 0 finished with value: 0.11556555550830161 and parameters: {'n_estimators': 144, 'learning_rate': 0.02454361763907524, 'num_leaves': 27, 'max_depth': 12, 'min_child_samples': 13, 'subsample': 0.7588882106636787, 'colsample_bytree': 0.7706302603619485, 'reg_alpha': 0.00048051060871786677, 'reg_lambda': 2.0419385894660995e-07}. Best is trial 0 with value: 0.11556555550830161.
[I 2025-04-14 18:26:12,694] Trial 1 finished with value: 0.16672213078824574 and parameters: {'n_estimators': 102, 'learning_rate': 0.07131252970405262, 'num_leaves': 29, 'max_depth': 4, 'min_child_samples': 50, 'subsample': 0.9244643033958022, 'colsample_bytree': 0.5378890252727275, 'reg_alpha': 6.465761218294399e-07, 'reg_lambda': 0.0022754706939453005}. Best is trial 0 with value: 0.11556555550830161.
[I 2025-04-14 18:26:13,171] Trial 2 finished with value: 0.15664782013013992 and parameters: {'n_estimators': 145, 'learning_rate': 0.0012674008618034076, 'num_leaves': 11, 'max_depth': 5, 'min_child_samples': 20, 'subsample': 0.6453617885193486, 'colsample_bytree': 0.7271484234237622, 'reg_alpha': 0.0007581917069953434, 'reg_lambda': 0.00013573586412048903}. Best is trial 0 with value: 0.11556555550830161.
[I 2025-04-14 18:26:14,473] Trial 3 finished with value: 0.11733417081667663 and parameters: {'n_estimators': 178, 'learning_rate': 0.24936302218086942, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 5, 'subsample': 0.6687315620780427, 'colsample_bytree': 0.8573536595546227, 'reg_alpha': 0.005569625943730178, 'reg_lambda': 3.135225428320784e-08}. Best is trial 0 with value: 0.11556555550830161.
[I 2025-04-14 18:26:14,818] Trial 4 finished with value: 0.11450163699627809 and parameters: {'n_estimators': 77, 'learning_rate': 0.09788147429902692, 'num_leaves': 23, 'max_depth': 10, 'min_child_samples': 23, 'subsample': 0.974354356233927, 'colsample_bytree': 0.5030787717483867, 'reg_alpha': 2.732667434630833e-06, 'reg_lambda': 1.9857421215678946e-08}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:15,007] Trial 5 finished with value: 0.16672213078824574 and parameters: {'n_estimators': 186, 'learning_rate': 0.0026177631711555007, 'num_leaves': 20, 'max_depth': 5, 'min_child_samples': 46, 'subsample': 0.6583873873047414, 'colsample_bytree': 0.525476177989557, 'reg_alpha': 0.0018716592224809448, 'reg_lambda': 0.1656719675983863}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:15,295] Trial 6 finished with value: 0.11620998594062369 and parameters: {'n_estimators': 82, 'learning_rate': 0.10587998221873245, 'num_leaves': 11, 'max_depth': 3, 'min_child_samples': 32, 'subsample': 0.5011035405298991, 'colsample_bytree': 0.9427962347946703, 'reg_alpha': 4.1541250357001645e-08, 'reg_lambda': 0.22261468405054824}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:15,707] Trial 7 finished with value: 0.1446582829993173 and parameters: {'n_estimators': 144, 'learning_rate': 0.0035945035185679475, 'num_leaves': 37, 'max_depth': 3, 'min_child_samples': 36, 'subsample': 0.7147649276510084, 'colsample_bytree': 0.5742408137863162, 'reg_alpha': 0.06518315755189875, 'reg_lambda': 0.004466176753132216}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:16,503] Trial 8 finished with value: 0.11596757736807262 and parameters: {'n_estimators': 269, 'learning_rate': 0.09839496843645762, 'num_leaves': 59, 'max_depth': 7, 'min_child_samples': 22, 'subsample': 0.9881468321341244, 'colsample_bytree': 0.8190914597577856, 'reg_alpha': 0.428488735734852, 'reg_lambda': 1.5330008268095992e-07}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:16,926] Trial 9 finished with value: 0.13052167346202817 and parameters: {'n_estimators': 153, 'learning_rate': 0.007846882867077134, 'num_leaves': 42, 'max_depth': 11, 'min_child_samples': 31, 'subsample': 0.6955604300068767, 'colsample_bytree': 0.662318936206743, 'reg_alpha': 0.47247329953838163, 'reg_lambda': 0.5711858275284194}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:17,238] Trial 10 finished with value: 0.13682254273684538 and parameters: {'n_estimators': 59, 'learning_rate': 0.025212874231333914, 'num_leaves': 49, 'max_depth': 9, 'min_child_samples': 38, 'subsample': 0.859085519835447, 'colsample_bytree': 0.6550968697766747, 'reg_alpha': 5.244929796432908e-06, 'reg_lambda': 5.5061616375848445e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:17,929] Trial 11 finished with value: 0.11692717837797913 and parameters: {'n_estimators': 104, 'learning_rate': 0.029409292177399772, 'num_leaves': 22, 'max_depth': 12, 'min_child_samples': 10, 'subsample': 0.8192297067010426, 'colsample_bytree': 0.769130456494685, 'reg_alpha': 3.436695571669345e-05, 'reg_lambda': 6.722102742502736e-07}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:18,823] Trial 12 finished with value: 0.1175793705269863 and parameters: {'n_estimators': 232, 'learning_rate': 0.013293229016746433, 'num_leaves': 24, 'max_depth': 10, 'min_child_samples': 16, 'subsample': 0.804017769694632, 'colsample_bytree': 0.9169722992298482, 'reg_alpha': 4.5144066202621734e-05, 'reg_lambda': 1.169112133283051e-08}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:19,372] Trial 13 finished with value: 0.11469218860364816 and parameters: {'n_estimators': 115, 'learning_rate': 0.04793569186563179, 'num_leaves': 18, 'max_depth': 12, 'min_child_samples': 14, 'subsample': 0.9901561252853541, 'colsample_bytree': 0.6242654238819212, 'reg_alpha': 5.461859004927202e-07, 'reg_lambda': 3.286125710144068e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:19,668] Trial 14 finished with value: 0.11590580489032958 and parameters: {'n_estimators': 51, 'learning_rate': 0.29233368882513555, 'num_leaves': 16, 'max_depth': 8, 'min_child_samples': 25, 'subsample': 0.9697694893314653, 'colsample_bytree': 0.6195578938929172, 'reg_alpha': 1.4633612453487251e-08, 'reg_lambda': 6.535083151511587e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:20,139] Trial 15 finished with value: 0.11615144273129596 and parameters: {'n_estimators': 104, 'learning_rate': 0.061345636033248066, 'num_leaves': 18, 'max_depth': 11, 'min_child_samples': 18, 'subsample': 0.9059523648198896, 'colsample_bytree': 0.5080414665494896, 'reg_alpha': 3.244692454204268e-07, 'reg_lambda': 8.852253988415748e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:20,817] Trial 16 finished with value: 0.11639970836547231 and parameters: {'n_estimators': 81, 'learning_rate': 0.0513379928745508, 'num_leaves': 31, 'max_depth': 10, 'min_child_samples': 6, 'subsample': 0.9100862453223009, 'colsample_bytree': 0.5865252572975506, 'reg_alpha': 2.235857109401504e-06, 'reg_lambda': 8.227382961645681e-05}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:21,241] Trial 17 finished with value: 0.11523766017879146 and parameters: {'n_estimators': 120, 'learning_rate': 0.1555206524342385, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 27, 'subsample': 0.9990428511547992, 'colsample_bytree': 0.686677084077526, 'reg_alpha': 1.2400206778217916e-07, 'reg_lambda': 2.1640553687889985e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:22,268] Trial 18 finished with value: 0.11718235005097823 and parameters: {'n_estimators': 224, 'learning_rate': 0.01229169801744785, 'num_leaves': 43, 'max_depth': 11, 'min_child_samples': 12, 'subsample': 0.8543328172670257, 'colsample_bytree': 0.6000310566240614, 'reg_alpha': 2.3201054153673225e-06, 'reg_lambda': 6.843573346384197e-05}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:22,643] Trial 19 finished with value: 0.12045971150595164 and parameters: {'n_estimators': 71, 'learning_rate': 0.034269880678736965, 'num_leaves': 24, 'max_depth': 12, 'min_child_samples': 23, 'subsample': 0.5845742377864691, 'colsample_bytree': 0.5005759756584316, 'reg_alpha': 1.3859485749313884e-05, 'reg_lambda': 8.794648824391506e-08}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:23,686] Trial 20 finished with value: 0.12055268327922035 and parameters: {'n_estimators': 300, 'learning_rate': 0.006508790201580064, 'num_leaves': 36, 'max_depth': 9, 'min_child_samples': 16, 'subsample': 0.9397874442000477, 'colsample_bytree': 0.7020895325583061, 'reg_alpha': 0.00018282055281225096, 'reg_lambda': 1.0079739790729218e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:24,104] Trial 21 finished with value: 0.11627741156283411 and parameters: {'n_estimators': 123, 'learning_rate': 0.15005290546202119, 'num_leaves': 15, 'max_depth': 6, 'min_child_samples': 29, 'subsample': 0.9785997478816959, 'colsample_bytree': 0.6701312957037774, 'reg_alpha': 9.865865279023835e-08, 'reg_lambda': 1.2745966458507695e-06}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:24,532] Trial 22 finished with value: 0.1162906333259885 and parameters: {'n_estimators': 120, 'learning_rate': 0.18456727073254253, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 27, 'subsample': 0.9958686263708044, 'colsample_bytree': 0.5605508208296621, 'reg_alpha': 3.44658930981012e-07, 'reg_lambda': 1.1096004339971093e-08}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:24,941] Trial 23 finished with value: 0.11744897157049776 and parameters: {'n_estimators': 121, 'learning_rate': 0.12236114250115829, 'num_leaves': 12, 'max_depth': 10, 'min_child_samples': 36, 'subsample': 0.891485132831116, 'colsample_bytree': 0.6263901465275554, 'reg_alpha': 1.283803286111095e-08, 'reg_lambda': 0.0006249835356230295}. Best is trial 4 with value: 0.11450163699627809.
[I 2025-04-14 18:26:25,542] Trial 24 finished with value: 0.1146148566060504 and parameters: {'n_estimators': 199, 'learning_rate': 0.04720950142611617, 'num_leaves': 20, 'max_depth': 8, 'min_child_samples': 25, 'subsample': 0.9645396002245049, 'colsample_bytree': 0.7022459534347694, 'reg_alpha': 1.0836994751543816e-07, 'reg_lambda': 2.2848001164358234e-05}. Best is trial 4 with value: 0.11450163699627809.
Selecting model for Feeder 8, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 170, Version: v1.1_Final_Forecasting_20250414170626, Path Info: {"keras_model": "models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626.keras", "scalers_pkl": "models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626.keras', 'scalers_pkl': 'models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626_scalers.pkl'}
Detected separate Keras model (models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626.keras) and scalers (models/feeder_8/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170626_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.108861

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.101690

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.111007

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.223243

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.109121

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.106803

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.105057

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.099882

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.113614

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.101119

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.140653

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.098406

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.101526

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.111272

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.101533

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.100899

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.104918

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.116223

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.227640

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.244408

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.101617

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.099932

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.102263

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.100586

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.100370

--- Best Results for Feeder=8, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.098406
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 50
  n_dense_layers: 2
  lstm_dropout_0: 0.3658954649238185
  lstm_dropout_1: 0.21554559347667882
  dense_units_0: 59
  dense_dropout_0: 0.10073885924604259
  dense_units_1: 51
  dense_dropout_1: 0.10667216924023493
  learning_rate: 0.0046435408312779595

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=8, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 8, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=8, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=8, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 9 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 172, Version: v1.1_Final_Forecasting_20250414170639, Path Info: models/feeder_9/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170639.pkl
Loading artifact(s) based on path info: models/feeder_9/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170639.pkl
Detected single pickle artifact path: models/feeder_9/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170639.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170639.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170639.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
[I 2025-04-14 18:26:27,957] A new study created in memory with name: tune-9-LSTM_Baseload-24hr
[I 2025-04-14 18:26:32,163] Trial 0 finished with value: 0.1998172104358673 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.14766845934128714, 'dense_units_0': 50, 'dense_dropout_0': 0.12350576765247152, 'learning_rate': 0.00022920125014953713}. Best is trial 0 with value: 0.1998172104358673.
[I 2025-04-14 18:26:36,902] Trial 1 finished with value: 0.16793712973594666 and parameters: {'n_lstm_layers': 1, 'lstm_units': 84, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1832352295416694, 'learning_rate': 0.00010980672299879215}. Best is trial 1 with value: 0.16793712973594666.
[I 2025-04-14 18:26:44,268] Trial 2 finished with value: 0.4725308120250702 and parameters: {'n_lstm_layers': 2, 'lstm_units': 38, 'n_dense_layers': 2, 'lstm_dropout_0': 0.10818923545767745, 'lstm_dropout_1': 0.22846240965134454, 'dense_units_0': 21, 'dense_dropout_0': 0.4539620466606584, 'dense_units_1': 40, 'dense_dropout_1': 0.465504987154742, 'learning_rate': 0.00013575448041196035}. Best is trial 1 with value: 0.16793712973594666.
[I 2025-04-14 18:26:52,132] Trial 3 finished with value: 0.23061616718769073 and parameters: {'n_lstm_layers': 2, 'lstm_units': 67, 'n_dense_layers': 2, 'lstm_dropout_0': 0.37663733687455636, 'lstm_dropout_1': 0.3977623214844421, 'dense_units_0': 43, 'dense_dropout_0': 0.2250305052335353, 'dense_units_1': 18, 'dense_dropout_1': 0.25134194883395283, 'learning_rate': 0.0005225732892344257}. Best is trial 1 with value: 0.16793712973594666.
[I 2025-04-14 18:26:56,593] Trial 4 finished with value: 0.13944408297538757 and parameters: {'n_lstm_layers': 1, 'lstm_units': 55, 'n_dense_layers': 1, 'lstm_dropout_0': 0.49655956518224553, 'dense_units_0': 43, 'dense_dropout_0': 0.3789553271445735, 'learning_rate': 0.001918606253804309}. Best is trial 4 with value: 0.13944408297538757.
[I 2025-04-14 18:27:01,446] Trial 5 finished with value: 0.19983285665512085 and parameters: {'n_lstm_layers': 1, 'lstm_units': 55, 'n_dense_layers': 1, 'lstm_dropout_0': 0.40448070965993643, 'dense_units_0': 36, 'dense_dropout_0': 0.3775402375764708, 'learning_rate': 0.00045973091994962954}. Best is trial 4 with value: 0.13944408297538757.
[I 2025-04-14 18:27:07,980] Trial 6 finished with value: 0.12945881485939026 and parameters: {'n_lstm_layers': 2, 'lstm_units': 70, 'n_dense_layers': 2, 'lstm_dropout_0': 0.14901585656158584, 'lstm_dropout_1': 0.1085634717030508, 'dense_units_0': 23, 'dense_dropout_0': 0.296002237044793, 'dense_units_1': 36, 'dense_dropout_1': 0.27651052035195045, 'learning_rate': 0.0059868221762878465}. Best is trial 6 with value: 0.12945881485939026.
[I 2025-04-14 18:27:15,331] Trial 7 finished with value: 0.17050409317016602 and parameters: {'n_lstm_layers': 2, 'lstm_units': 43, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4059370920059703, 'lstm_dropout_1': 0.2687608664432566, 'dense_units_0': 43, 'dense_dropout_0': 0.11939028897624789, 'dense_units_1': 18, 'dense_dropout_1': 0.44077694844174353, 'learning_rate': 0.0015076822701801948}. Best is trial 6 with value: 0.12945881485939026.
[I 2025-04-14 18:27:20,178] Trial 8 finished with value: 0.14939577877521515 and parameters: {'n_lstm_layers': 1, 'lstm_units': 54, 'n_dense_layers': 2, 'lstm_dropout_0': 0.17788746321619753, 'dense_units_0': 54, 'dense_dropout_0': 0.14983684559307398, 'dense_units_1': 54, 'dense_dropout_1': 0.2525149722175388, 'learning_rate': 0.000493562432057802}. Best is trial 6 with value: 0.12945881485939026.
[I 2025-04-14 18:27:26,178] Trial 9 finished with value: 0.12441956996917725 and parameters: {'n_lstm_layers': 2, 'lstm_units': 113, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3404090612181371, 'lstm_dropout_1': 0.2656185384768937, 'learning_rate': 0.007582638673023543}. Best is trial 9 with value: 0.12441956996917725.
[I 2025-04-14 18:27:31,994] Trial 10 finished with value: 0.12708473205566406 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.27009312021213444, 'lstm_dropout_1': 0.41687127244523736, 'learning_rate': 0.00673279128547197}. Best is trial 9 with value: 0.12441956996917725.
[I 2025-04-14 18:27:39,209] Trial 11 finished with value: 0.11981435865163803 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2742595769742452, 'lstm_dropout_1': 0.48154187208487037, 'learning_rate': 0.008923888036289917}. Best is trial 11 with value: 0.11981435865163803.
[I 2025-04-14 18:27:45,227] Trial 12 finished with value: 0.12961268424987793 and parameters: {'n_lstm_layers': 2, 'lstm_units': 125, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2838768613100527, 'lstm_dropout_1': 0.49047325808637793, 'learning_rate': 0.009998851595054637}. Best is trial 11 with value: 0.11981435865163803.
[I 2025-04-14 18:27:52,561] Trial 13 finished with value: 0.1190260723233223 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3237453245326612, 'lstm_dropout_1': 0.3435250574112641, 'learning_rate': 0.003787752060730693}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:27:59,654] Trial 14 finished with value: 0.11994296312332153 and parameters: {'n_lstm_layers': 2, 'lstm_units': 96, 'n_dense_layers': 0, 'lstm_dropout_0': 0.23566308564703425, 'lstm_dropout_1': 0.38115638990326184, 'learning_rate': 0.003335814863838643}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:28:06,007] Trial 15 finished with value: 0.125778466463089 and parameters: {'n_lstm_layers': 2, 'lstm_units': 94, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32560441064101686, 'lstm_dropout_1': 0.4971591224445397, 'learning_rate': 0.0033389882947392558}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:28:13,428] Trial 16 finished with value: 0.12729395925998688 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2394719599187256, 'lstm_dropout_1': 0.33550424494275644, 'dense_units_0': 16, 'dense_dropout_0': 0.4791438803552193, 'learning_rate': 0.003570477112674069}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:28:20,458] Trial 17 finished with value: 0.12015771120786667 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 0, 'lstm_dropout_0': 0.46611339873508606, 'lstm_dropout_1': 0.17007850780132017, 'learning_rate': 0.0018012772073346822}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:28:27,690] Trial 18 finished with value: 0.12143261730670929 and parameters: {'n_lstm_layers': 2, 'lstm_units': 108, 'n_dense_layers': 1, 'lstm_dropout_0': 0.33292700698368133, 'lstm_dropout_1': 0.44006075579437565, 'dense_units_0': 27, 'dense_dropout_0': 0.23487785230731167, 'learning_rate': 0.004586289595013277}. Best is trial 13 with value: 0.1190260723233223.
[I 2025-04-14 18:28:34,807] Trial 19 finished with value: 0.1188216507434845 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2354281028791115, 'lstm_dropout_1': 0.33251150617828823, 'learning_rate': 0.001141397815731878}. Best is trial 19 with value: 0.1188216507434845.
[I 2025-04-14 18:28:38,379] Trial 20 finished with value: 0.13771620392799377 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2152159886261667, 'learning_rate': 0.0009072545405521158}. Best is trial 19 with value: 0.1188216507434845.
[I 2025-04-14 18:28:44,137] Trial 21 finished with value: 0.13420650362968445 and parameters: {'n_lstm_layers': 2, 'lstm_units': 93, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2773310174242138, 'lstm_dropout_1': 0.3225294409724807, 'learning_rate': 0.0025358018437725634}. Best is trial 19 with value: 0.1188216507434845.
[I 2025-04-14 18:28:50,255] Trial 22 finished with value: 0.13502256572246552 and parameters: {'n_lstm_layers': 2, 'lstm_units': 119, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3091459902369137, 'lstm_dropout_1': 0.36872706016069173, 'learning_rate': 0.0010358722253731771}. Best is trial 19 with value: 0.1188216507434845.
[I 2025-04-14 18:28:56,313] Trial 23 finished with value: 0.1442585587501526 and parameters: {'n_lstm_layers': 2, 'lstm_units': 102, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3637926270514258, 'lstm_dropout_1': 0.4441347840901667, 'learning_rate': 0.0009645160445527932}. Best is trial 19 with value: 0.1188216507434845.
[I 2025-04-14 18:29:03,078] Trial 24 finished with value: 0.1246839165687561 and parameters: {'n_lstm_layers': 2, 'lstm_units': 85, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26153132920008193, 'lstm_dropout_1': 0.29724158168475334, 'dense_units_0': 62, 'dense_dropout_0': 0.39878819465143894, 'learning_rate': 0.005054799244724986}. Best is trial 19 with value: 0.1188216507434845.
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.115566

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.166722

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.156648

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.117334

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.114502

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.166722

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.116210

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.144658

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.115968

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.130522

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.136823

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.116927

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.117579

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.114692

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.115906

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.116151

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.116400

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.115238

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.117182

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.120460

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.120553

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.116277

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.116291

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.117449

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.114615

--- Best Results for Feeder=9, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.114502
Best Hyperparameters:
  n_estimators: 77
  learning_rate: 0.09788147429902692
  num_leaves: 23
  max_depth: 10
  min_child_samples: 23
  subsample: 0.974354356233927
  colsample_bytree: 0.5030787717483867
  reg_alpha: 2.732667434630833e-06
  reg_lambda: 1.9857421215678946e-08

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=9, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=9, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=9, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
[I 2025-04-14 18:29:17,187] A new study created in memory with name: tune-9-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:29:24,569] Trial 0 finished with value: 0.1276763677597046 and parameters: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40338494013296133, 'lstm_dropout_1': 0.38331862101746206, 'learning_rate': 0.00035053283476950463}. Best is trial 0 with value: 0.1276763677597046.
[I 2025-04-14 18:29:28,826] Trial 1 finished with value: 0.12585382163524628 and parameters: {'n_lstm_layers': 1, 'lstm_units': 126, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32576590423701873, 'learning_rate': 0.0007820231629478935}. Best is trial 1 with value: 0.12585382163524628.
[I 2025-04-14 18:29:35,276] Trial 2 finished with value: 0.12453953176736832 and parameters: {'n_lstm_layers': 2, 'lstm_units': 37, 'n_dense_layers': 2, 'lstm_dropout_0': 0.13524358505079906, 'lstm_dropout_1': 0.21861244193115775, 'dense_units_0': 20, 'dense_dropout_0': 0.23012203685886093, 'dense_units_1': 49, 'dense_dropout_1': 0.24368594875621774, 'learning_rate': 0.007363757203892955}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:29:38,915] Trial 3 finished with value: 0.1286810338497162 and parameters: {'n_lstm_layers': 1, 'lstm_units': 68, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3650761715122376, 'dense_units_0': 42, 'dense_dropout_0': 0.35904320070669393, 'learning_rate': 0.002768846426771178}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:29:46,086] Trial 4 finished with value: 0.12649160623550415 and parameters: {'n_lstm_layers': 2, 'lstm_units': 75, 'n_dense_layers': 0, 'lstm_dropout_0': 0.38568647357141583, 'lstm_dropout_1': 0.19820337630386514, 'learning_rate': 0.00045121455371186577}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:29:50,899] Trial 5 finished with value: 0.22673746943473816 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2721069780277956, 'dense_units_0': 27, 'dense_dropout_0': 0.38108543783030735, 'dense_units_1': 17, 'dense_dropout_1': 0.3739198878540423, 'learning_rate': 0.0004963511884157282}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:29:58,400] Trial 6 finished with value: 0.13568848371505737 and parameters: {'n_lstm_layers': 2, 'lstm_units': 55, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2860417034357706, 'lstm_dropout_1': 0.2604340937869867, 'dense_units_0': 23, 'dense_dropout_0': 0.2000758292424664, 'dense_units_1': 57, 'dense_dropout_1': 0.43408957078941135, 'learning_rate': 0.000773141694478922}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:30:06,046] Trial 7 finished with value: 0.13501444458961487 and parameters: {'n_lstm_layers': 2, 'lstm_units': 94, 'n_dense_layers': 0, 'lstm_dropout_0': 0.45466981481805147, 'lstm_dropout_1': 0.34469609724259787, 'learning_rate': 0.0001038674652614236}. Best is trial 2 with value: 0.12453953176736832.
[I 2025-04-14 18:30:12,897] Trial 8 finished with value: 0.12324540317058563 and parameters: {'n_lstm_layers': 2, 'lstm_units': 68, 'n_dense_layers': 1, 'lstm_dropout_0': 0.43609471287415835, 'lstm_dropout_1': 0.2267972076553666, 'dense_units_0': 29, 'dense_dropout_0': 0.36106307228693313, 'learning_rate': 0.0057980703762919444}. Best is trial 8 with value: 0.12324540317058563.
[I 2025-04-14 18:30:20,406] Trial 9 finished with value: 0.1368733048439026 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 1, 'lstm_dropout_0': 0.29612337429058166, 'lstm_dropout_1': 0.10318076136394612, 'dense_units_0': 21, 'dense_dropout_0': 0.316837054056365, 'learning_rate': 0.0008210995690267977}. Best is trial 8 with value: 0.12324540317058563.
[I 2025-04-14 18:30:24,555] Trial 10 finished with value: 0.12428036332130432 and parameters: {'n_lstm_layers': 1, 'lstm_units': 52, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4935022119549719, 'dense_units_0': 63, 'dense_dropout_0': 0.4921128950019796, 'learning_rate': 0.009701861717777054}. Best is trial 8 with value: 0.12324540317058563.
[I 2025-04-14 18:30:28,302] Trial 11 finished with value: 0.12517113983631134 and parameters: {'n_lstm_layers': 1, 'lstm_units': 51, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4892203034758851, 'dense_units_0': 61, 'dense_dropout_0': 0.48459949277719927, 'learning_rate': 0.009860657546542254}. Best is trial 8 with value: 0.12324540317058563.
[I 2025-04-14 18:30:32,821] Trial 12 finished with value: 0.12281307578086853 and parameters: {'n_lstm_layers': 1, 'lstm_units': 51, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4956833017525194, 'dense_units_0': 35, 'dense_dropout_0': 0.483903382360438, 'learning_rate': 0.0034469041496794635}. Best is trial 12 with value: 0.12281307578086853.
[I 2025-04-14 18:30:37,725] Trial 13 finished with value: 0.12202033400535583 and parameters: {'n_lstm_layers': 1, 'lstm_units': 60, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4399016565785236, 'dense_units_0': 37, 'dense_dropout_0': 0.41526910795226674, 'learning_rate': 0.0026414574010104495}. Best is trial 13 with value: 0.12202033400535583.
[I 2025-04-14 18:30:41,991] Trial 14 finished with value: 0.13036377727985382 and parameters: {'n_lstm_layers': 1, 'lstm_units': 44, 'n_dense_layers': 1, 'lstm_dropout_0': 0.20197145175386091, 'dense_units_0': 39, 'dense_dropout_0': 0.44294296715224596, 'learning_rate': 0.002328423786688158}. Best is trial 13 with value: 0.12202033400535583.
[I 2025-04-14 18:30:46,534] Trial 15 finished with value: 0.12213915586471558 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 2, 'lstm_dropout_0': 0.436383063281733, 'dense_units_0': 39, 'dense_dropout_0': 0.4249157201555018, 'dense_units_1': 20, 'dense_dropout_1': 0.10730595445556926, 'learning_rate': 0.0026355196143767476}. Best is trial 13 with value: 0.12202033400535583.
[I 2025-04-14 18:30:51,321] Trial 16 finished with value: 0.12833291292190552 and parameters: {'n_lstm_layers': 1, 'lstm_units': 106, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3393685075211007, 'dense_units_0': 45, 'dense_dropout_0': 0.4126789258008044, 'dense_units_1': 19, 'dense_dropout_1': 0.10171996664186848, 'learning_rate': 0.0013742747445319868}. Best is trial 13 with value: 0.12202033400535583.
[I 2025-04-14 18:30:56,187] Trial 17 finished with value: 0.12288790196180344 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4281427088698534, 'dense_units_0': 16, 'dense_dropout_0': 0.11742429104257537, 'dense_units_1': 28, 'dense_dropout_1': 0.12752530191031372, 'learning_rate': 0.0017914093144232748}. Best is trial 13 with value: 0.12202033400535583.
[I 2025-04-14 18:31:01,070] Trial 18 finished with value: 0.1219538152217865 and parameters: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2342521323299082, 'dense_units_0': 49, 'dense_dropout_0': 0.2647961356437788, 'dense_units_1': 27, 'dense_dropout_1': 0.22986179545072508, 'learning_rate': 0.004340766228604256}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:05,092] Trial 19 finished with value: 0.12519453465938568 and parameters: {'n_lstm_layers': 1, 'lstm_units': 90, 'n_dense_layers': 2, 'lstm_dropout_0': 0.23191074911715323, 'dense_units_0': 51, 'dense_dropout_0': 0.2524799881171843, 'dense_units_1': 34, 'dense_dropout_1': 0.24619467839051848, 'learning_rate': 0.004655891451922713}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:09,033] Trial 20 finished with value: 0.12496194243431091 and parameters: {'n_lstm_layers': 1, 'lstm_units': 106, 'n_dense_layers': 1, 'lstm_dropout_0': 0.11530903074510396, 'dense_units_0': 49, 'dense_dropout_0': 0.3120921460812828, 'learning_rate': 0.004508332343411105}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:13,605] Trial 21 finished with value: 0.1326376497745514 and parameters: {'n_lstm_layers': 1, 'lstm_units': 63, 'n_dense_layers': 2, 'lstm_dropout_0': 0.18239526750404844, 'dense_units_0': 34, 'dense_dropout_0': 0.4227816411506312, 'dense_units_1': 26, 'dense_dropout_1': 0.19172515670392276, 'learning_rate': 0.001548891025550882}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:17,742] Trial 22 finished with value: 0.1289469450712204 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 2, 'lstm_dropout_0': 0.23964594746161197, 'dense_units_0': 38, 'dense_dropout_0': 0.2751324268369755, 'dense_units_1': 22, 'dense_dropout_1': 0.3071394892798214, 'learning_rate': 0.0030524140795197773}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:21,967] Trial 23 finished with value: 0.12425373494625092 and parameters: {'n_lstm_layers': 1, 'lstm_units': 45, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3426323197053846, 'dense_units_0': 53, 'dense_dropout_0': 0.2115904826561571, 'dense_units_1': 38, 'dense_dropout_1': 0.17693765799174954, 'learning_rate': 0.002225518811229913}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:26,876] Trial 24 finished with value: 0.1430932581424713 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 2, 'lstm_dropout_0': 0.459703042832988, 'dense_units_0': 31, 'dense_dropout_0': 0.13987316091084573, 'dense_units_1': 23, 'dense_dropout_1': 0.3111196969965086, 'learning_rate': 0.0011649689247619965}. Best is trial 18 with value: 0.1219538152217865.
[I 2025-04-14 18:31:27,756] A new study created in memory with name: tune-10-LightGBM_Baseline-24hr
[I 2025-04-14 18:31:32,409] Trial 0 finished with value: 0.15537048638173753 and parameters: {'n_estimators': 293, 'learning_rate': 0.014771245024382216, 'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 17, 'subsample': 0.5943569105428763, 'colsample_bytree': 0.6586171594276661, 'reg_alpha': 0.0007566292313088516, 'reg_lambda': 4.0124519418600313e-08}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:33,092] Trial 1 finished with value: 0.15756710728798617 and parameters: {'n_estimators': 270, 'learning_rate': 0.036585934855039, 'num_leaves': 33, 'max_depth': 9, 'min_child_samples': 31, 'subsample': 0.9106440976175714, 'colsample_bytree': 0.892229066548873, 'reg_alpha': 2.947626696411951e-07, 'reg_lambda': 2.2026708614337497e-06}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:34,503] Trial 2 finished with value: 0.16195946522015117 and parameters: {'n_estimators': 294, 'learning_rate': 0.001997926363223434, 'num_leaves': 55, 'max_depth': 8, 'min_child_samples': 12, 'subsample': 0.9078366153039037, 'colsample_bytree': 0.8488811414172548, 'reg_alpha': 4.0425572416730075e-07, 'reg_lambda': 0.0052390838814256905}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:34,846] Trial 3 finished with value: 0.1653120804630338 and parameters: {'n_estimators': 79, 'learning_rate': 0.006166372055562888, 'num_leaves': 58, 'max_depth': 11, 'min_child_samples': 33, 'subsample': 0.5564417014085248, 'colsample_bytree': 0.5216458441577317, 'reg_alpha': 7.760475310003471e-07, 'reg_lambda': 6.967620960689414e-07}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:35,227] Trial 4 finished with value: 0.16831108136739326 and parameters: {'n_estimators': 110, 'learning_rate': 0.0015590558133017213, 'num_leaves': 17, 'max_depth': 3, 'min_child_samples': 35, 'subsample': 0.5546190049459407, 'colsample_bytree': 0.9297166414009994, 'reg_alpha': 9.691863568368112e-08, 'reg_lambda': 1.8799927050792868e-06}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:35,734] Trial 5 finished with value: 0.15898408433496838 and parameters: {'n_estimators': 154, 'learning_rate': 0.03831003229927582, 'num_leaves': 57, 'max_depth': 5, 'min_child_samples': 37, 'subsample': 0.5209151923610461, 'colsample_bytree': 0.8790334572744223, 'reg_alpha': 3.638973780452259e-08, 'reg_lambda': 0.00015621437794172165}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:36,303] Trial 6 finished with value: 0.16608818046338847 and parameters: {'n_estimators': 86, 'learning_rate': 0.0022991656363992264, 'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 9, 'subsample': 0.6381591181839015, 'colsample_bytree': 0.7110465654536838, 'reg_alpha': 0.09454035479708273, 'reg_lambda': 0.0003289640813812864}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:36,619] Trial 7 finished with value: 0.15871056423747523 and parameters: {'n_estimators': 68, 'learning_rate': 0.14542686257050386, 'num_leaves': 53, 'max_depth': 8, 'min_child_samples': 27, 'subsample': 0.5934558319715436, 'colsample_bytree': 0.8037101184152753, 'reg_alpha': 2.1991818207633625e-07, 'reg_lambda': 3.64039357663895e-05}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:37,028] Trial 8 finished with value: 0.15689111922263818 and parameters: {'n_estimators': 75, 'learning_rate': 0.021283240826975157, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 13, 'subsample': 0.5571632637503803, 'colsample_bytree': 0.6187350639969961, 'reg_alpha': 0.06084364696733799, 'reg_lambda': 1.805093172034354e-05}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:37,486] Trial 9 finished with value: 0.16161267389645556 and parameters: {'n_estimators': 111, 'learning_rate': 0.009675164437537383, 'num_leaves': 50, 'max_depth': 11, 'min_child_samples': 22, 'subsample': 0.708306288675562, 'colsample_bytree': 0.817039473011977, 'reg_alpha': 0.01487521177680378, 'reg_lambda': 3.9239135753611355e-07}. Best is trial 0 with value: 0.15537048638173753.
[I 2025-04-14 18:31:37,736] Trial 10 finished with value: 0.1703326548544306 and parameters: {'n_estimators': 224, 'learning_rate': 0.23923438745930548, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 49, 'subsample': 0.8083951055157576, 'colsample_bytree': 0.6800531403127441, 'reg_alpha': 0.00028047816764656755, 'reg_lambda': 1.7961233070559604e-08}. Best is trial 0 with value: 0.15537048638173753.
Selected Model ID: 173, Version: v1.1_Final_Forecasting_20250414170641, Path Info: {"keras_model": "models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641.keras", "scalers_pkl": "models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641.keras', 'scalers_pkl': 'models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641_scalers.pkl'}
Detected separate Keras model (models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641.keras) and scalers (models/feeder_9/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170641_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.199817

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.167937

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.472531

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.230616

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.139444

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.199833

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.129459

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.170504

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.149396

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.124420

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.127085

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.119814

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.129613

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.119026

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.119943

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.125778

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.127294

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.120158

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.121433

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.118822

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.137716

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.134207

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.135023

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.144259

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.124684

--- Best Results for Feeder=9, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.118822
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 82
  n_dense_layers: 0
  lstm_dropout_0: 0.2354281028791115
  lstm_dropout_1: 0.33251150617828823
  learning_rate: 0.001141397815731878

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=9, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=9, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 174, Version: v1.1_Final_Forecasting_20250414170648, Path Info: {"keras_model": "models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648.keras", "scalers_pkl": "models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648.keras', 'scalers_pkl': 'models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648_scalers.pkl'}
Detected separate Keras model (models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648.keras) and scalers (models/feeder_9/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170648_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
[I 2025-04-14 18:31:38,480] Trial 11 finished with value: 0.1553589417946088 and parameters: {'n_estimators': 183, 'learning_rate': 0.026807397165187864, 'num_leaves': 45, 'max_depth': 6, 'min_child_samples': 17, 'subsample': 0.6766746125557253, 'colsample_bytree': 0.5973441765283993, 'reg_alpha': 0.0013286304888501987, 'reg_lambda': 0.5038862615469456}. Best is trial 11 with value: 0.1553589417946088.
[I 2025-04-14 18:31:39,312] Trial 12 finished with value: 0.1562266300783733 and parameters: {'n_estimators': 215, 'learning_rate': 0.06770244613924535, 'num_leaves': 45, 'max_depth': 6, 'min_child_samples': 19, 'subsample': 0.6761365344453663, 'colsample_bytree': 0.5792977150344056, 'reg_alpha': 0.0006166923139102957, 'reg_lambda': 0.951546096944246}. Best is trial 11 with value: 0.1553589417946088.
[I 2025-04-14 18:31:39,941] Trial 13 finished with value: 0.16015527148896194 and parameters: {'n_estimators': 169, 'learning_rate': 0.006727800127881768, 'num_leaves': 28, 'max_depth': 4, 'min_child_samples': 19, 'subsample': 0.7909979840396671, 'colsample_bytree': 0.6449948559710681, 'reg_alpha': 1.3481948876067116e-05, 'reg_lambda': 0.5335848293808312}. Best is trial 11 with value: 0.1553589417946088.
[I 2025-04-14 18:31:41,647] Trial 14 finished with value: 0.15324728826797324 and parameters: {'n_estimators': 229, 'learning_rate': 0.015367922521804266, 'num_leaves': 47, 'max_depth': 6, 'min_child_samples': 5, 'subsample': 0.7461358409822427, 'colsample_bytree': 0.7497854231982228, 'reg_alpha': 0.00225594560166635, 'reg_lambda': 0.03982146668079337}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:43,067] Trial 15 finished with value: 0.15601005865027093 and parameters: {'n_estimators': 208, 'learning_rate': 0.0795962885533083, 'num_leaves': 45, 'max_depth': 5, 'min_child_samples': 6, 'subsample': 0.751217285881939, 'colsample_bytree': 0.7617618904409665, 'reg_alpha': 0.004026481667904035, 'reg_lambda': 0.05605114815117824}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:44,948] Trial 16 finished with value: 0.15957995730797625 and parameters: {'n_estimators': 249, 'learning_rate': 0.003731002999316387, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 5, 'subsample': 0.835788949868841, 'colsample_bytree': 0.5776362431969024, 'reg_alpha': 1.889639501648415e-05, 'reg_lambda': 0.012234175739326279}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:45,810] Trial 17 finished with value: 0.15459063987618807 and parameters: {'n_estimators': 188, 'learning_rate': 0.020346989313114825, 'num_leaves': 45, 'max_depth': 3, 'min_child_samples': 13, 'subsample': 0.7252376318370084, 'colsample_bytree': 0.9916953858989652, 'reg_alpha': 0.8738084237402063, 'reg_lambda': 0.10595392955536777}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:46,546] Trial 18 finished with value: 0.15488174573907607 and parameters: {'n_estimators': 143, 'learning_rate': 0.01652684721836177, 'num_leaves': 10, 'max_depth': 3, 'min_child_samples': 11, 'subsample': 0.8593235961944115, 'colsample_bytree': 0.9983240411005025, 'reg_alpha': 0.6199622892645562, 'reg_lambda': 0.0014595977921508603}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:47,240] Trial 19 finished with value: 0.1599544437191158 and parameters: {'n_estimators': 243, 'learning_rate': 0.0672475164999649, 'num_leaves': 37, 'max_depth': 4, 'min_child_samples': 25, 'subsample': 0.7484004222554334, 'colsample_bytree': 0.988753937826555, 'reg_alpha': 0.6544657370842009, 'reg_lambda': 0.062538607190891}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:48,360] Trial 20 finished with value: 0.1661668597532264 and parameters: {'n_estimators': 194, 'learning_rate': 0.0010399638652751097, 'num_leaves': 32, 'max_depth': 4, 'min_child_samples': 8, 'subsample': 0.9464638586204873, 'colsample_bytree': 0.7427180307395087, 'reg_alpha': 4.4791082352647405e-05, 'reg_lambda': 0.05936408237526425}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:49,030] Trial 21 finished with value: 0.15548128267336184 and parameters: {'n_estimators': 142, 'learning_rate': 0.013834858018310522, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 12, 'subsample': 0.8554603396186072, 'colsample_bytree': 0.9886571038018993, 'reg_alpha': 0.4620724281280963, 'reg_lambda': 0.0019066708859456162}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:49,708] Trial 22 finished with value: 0.15891592088953335 and parameters: {'n_estimators': 141, 'learning_rate': 0.00795671440778534, 'num_leaves': 13, 'max_depth': 3, 'min_child_samples': 13, 'subsample': 0.749105462367174, 'colsample_bytree': 0.9397490776517485, 'reg_alpha': 0.0974711035707775, 'reg_lambda': 0.0010452029855394405}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:50,679] Trial 23 finished with value: 0.16044570561163404 and parameters: {'n_estimators': 170, 'learning_rate': 0.004261612480007112, 'num_leaves': 20, 'max_depth': 5, 'min_child_samples': 9, 'subsample': 0.8713377523626092, 'colsample_bytree': 0.9369508252098752, 'reg_alpha': 0.01233180259300773, 'reg_lambda': 0.012297117525754145}. Best is trial 14 with value: 0.15324728826797324.
[I 2025-04-14 18:31:51,528] Trial 24 finished with value: 0.15614941444633076 and parameters: {'n_estimators': 109, 'learning_rate': 0.015118035044838692, 'num_leaves': 49, 'max_depth': 4, 'min_child_samples': 5, 'subsample': 0.9978706566196269, 'colsample_bytree': 0.9919896862957703, 'reg_alpha': 0.9292745593718655, 'reg_lambda': 0.12728764536960216}. Best is trial 14 with value: 0.15324728826797324.
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.127676

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.125854

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.124540

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.128681

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.126492

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.226737

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.135688

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.135014

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.123245

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.136873

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.124280

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.125171

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.122813

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.122020

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.130364

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.122139

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.128333

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.122888

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.121954

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.125195

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.124962

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.132638

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.128947

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.124254

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.143093

--- Best Results for Feeder=9, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.121954
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 83
  n_dense_layers: 2
  lstm_dropout_0: 0.2342521323299082
  dense_units_0: 49
  dense_dropout_0: 0.2647961356437788
  dense_units_1: 27
  dense_dropout_1: 0.22986179545072508
  learning_rate: 0.004340766228604256

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=9, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 9, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=9, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=9, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 10 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 176, Version: v1.1_Final_Forecasting_20250414170700, Path Info: models/feeder_10/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170700.pkl
Loading artifact(s) based on path info: models/feeder_10/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170700.pkl
Detected single pickle artifact path: models/feeder_10/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170700.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170700.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170700.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.155370

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.157567

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.161959

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.165312

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.168311

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.158984

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.166088

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.158711

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.156891

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.161613

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.170333
[I 2025-04-14 18:31:54,169] A new study created in memory with name: tune-10-LSTM_Baseload-24hr
[I 2025-04-14 18:32:00,674] Trial 0 finished with value: 0.16525836288928986 and parameters: {'n_lstm_layers': 2, 'lstm_units': 64, 'n_dense_layers': 1, 'lstm_dropout_0': 0.42731942406276635, 'lstm_dropout_1': 0.22220410677271635, 'dense_units_0': 33, 'dense_dropout_0': 0.22127121683228737, 'learning_rate': 0.003654372526120939}. Best is trial 0 with value: 0.16525836288928986.
[I 2025-04-14 18:32:03,888] Trial 1 finished with value: 0.16926851868629456 and parameters: {'n_lstm_layers': 1, 'lstm_units': 54, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4512628524439949, 'learning_rate': 0.005828100631203847}. Best is trial 0 with value: 0.16525836288928986.
[I 2025-04-14 18:32:08,658] Trial 2 finished with value: 0.1650238037109375 and parameters: {'n_lstm_layers': 1, 'lstm_units': 86, 'n_dense_layers': 1, 'lstm_dropout_0': 0.25088548374393094, 'dense_units_0': 42, 'dense_dropout_0': 0.13095479389636508, 'learning_rate': 0.0010939626509221833}. Best is trial 2 with value: 0.1650238037109375.
[I 2025-04-14 18:32:13,054] Trial 3 finished with value: 0.16744086146354675 and parameters: {'n_lstm_layers': 1, 'lstm_units': 72, 'n_dense_layers': 2, 'lstm_dropout_0': 0.12710675599256427, 'dense_units_0': 19, 'dense_dropout_0': 0.14534847542778576, 'dense_units_1': 56, 'dense_dropout_1': 0.13016139372541702, 'learning_rate': 0.0009946801819000436}. Best is trial 2 with value: 0.1650238037109375.
[I 2025-04-14 18:32:16,619] Trial 4 finished with value: 0.16298890113830566 and parameters: {'n_lstm_layers': 1, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.25892848783, 'learning_rate': 0.0014009154843749498}. Best is trial 4 with value: 0.16298890113830566.
[I 2025-04-14 18:32:20,328] Trial 5 finished with value: 0.1684708148241043 and parameters: {'n_lstm_layers': 1, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3874387081277084, 'dense_units_0': 48, 'dense_dropout_0': 0.1426551938280523, 'learning_rate': 0.0069972647691509985}. Best is trial 4 with value: 0.16298890113830566.
[I 2025-04-14 18:32:27,562] Trial 6 finished with value: 0.17148935794830322 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2937494207385412, 'lstm_dropout_1': 0.1953999798239497, 'dense_units_0': 18, 'dense_dropout_0': 0.2938559374320572, 'dense_units_1': 33, 'dense_dropout_1': 0.2703634976970167, 'learning_rate': 0.0009595456551140176}. Best is trial 4 with value: 0.16298890113830566.
[I 2025-04-14 18:32:34,078] Trial 7 finished with value: 0.16153977811336517 and parameters: {'n_lstm_layers': 2, 'lstm_units': 109, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18177978754814667, 'lstm_dropout_1': 0.12694580777200143, 'learning_rate': 0.0026192952484302558}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:32:38,348] Trial 8 finished with value: 0.1669895350933075 and parameters: {'n_lstm_layers': 1, 'lstm_units': 53, 'n_dense_layers': 0, 'lstm_dropout_0': 0.43787209758067547, 'learning_rate': 0.0036151902469083387}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:32:43,218] Trial 9 finished with value: 0.2796420753002167 and parameters: {'n_lstm_layers': 1, 'lstm_units': 42, 'n_dense_layers': 2, 'lstm_dropout_0': 0.32038217545889963, 'dense_units_0': 22, 'dense_dropout_0': 0.1322276481800312, 'dense_units_1': 17, 'dense_dropout_1': 0.3847533703537832, 'learning_rate': 0.0006789854665674993}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:32:50,321] Trial 10 finished with value: 0.17493824660778046 and parameters: {'n_lstm_layers': 2, 'lstm_units': 121, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10215847433825986, 'lstm_dropout_1': 0.48732192076759107, 'learning_rate': 0.00012780244350862853}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:32:56,738] Trial 11 finished with value: 0.1619613617658615 and parameters: {'n_lstm_layers': 2, 'lstm_units': 121, 'n_dense_layers': 0, 'lstm_dropout_0': 0.19943488364178982, 'lstm_dropout_1': 0.1027779352802331, 'learning_rate': 0.0021637839896200546}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:02,878] Trial 12 finished with value: 0.16310641169548035 and parameters: {'n_lstm_layers': 2, 'lstm_units': 94, 'n_dense_layers': 0, 'lstm_dropout_0': 0.19002619422457712, 'lstm_dropout_1': 0.11033935377006387, 'learning_rate': 0.002345931595030054}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:10,019] Trial 13 finished with value: 0.16167646646499634 and parameters: {'n_lstm_layers': 2, 'lstm_units': 105, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1788284742982481, 'lstm_dropout_1': 0.1042562944457707, 'learning_rate': 0.00036471013945741255}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:17,029] Trial 14 finished with value: 0.20217421650886536 and parameters: {'n_lstm_layers': 2, 'lstm_units': 94, 'n_dense_layers': 1, 'lstm_dropout_0': 0.18001689064397747, 'lstm_dropout_1': 0.34500134358586604, 'dense_units_0': 61, 'dense_dropout_0': 0.4965390911624039, 'learning_rate': 0.00036176789002991737}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:23,797] Trial 15 finished with value: 0.16343474388122559 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 0, 'lstm_dropout_0': 0.15329656963407717, 'lstm_dropout_1': 0.1987971939556381, 'learning_rate': 0.0003177033575302313}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:30,872] Trial 16 finished with value: 0.36213457584381104 and parameters: {'n_lstm_layers': 2, 'lstm_units': 32, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2331027502952, 'lstm_dropout_1': 0.3077316684081701, 'dense_units_0': 27, 'dense_dropout_0': 0.49246372031661234, 'learning_rate': 0.0001662505655850022}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:37,999] Trial 17 finished with value: 0.16161257028579712 and parameters: {'n_lstm_layers': 2, 'lstm_units': 81, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3439349392009424, 'lstm_dropout_1': 0.14727973961127028, 'learning_rate': 0.0004413982677481269}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:44,902] Trial 18 finished with value: 0.17742769420146942 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3412980826312911, 'lstm_dropout_1': 0.1815516428424262, 'dense_units_0': 64, 'dense_dropout_0': 0.38901676753017134, 'learning_rate': 0.0005719523988588907}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:51,994] Trial 19 finished with value: 0.16856452822685242 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 0, 'lstm_dropout_0': 0.37655622460698884, 'lstm_dropout_1': 0.25647841446342884, 'learning_rate': 0.00017243936734200404}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:33:58,727] Trial 20 finished with value: 0.16298656165599823 and parameters: {'n_lstm_layers': 2, 'lstm_units': 110, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4857310938943502, 'lstm_dropout_1': 0.3870425830309052, 'learning_rate': 0.0016282524442509988}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:34:05,432] Trial 21 finished with value: 0.16487988829612732 and parameters: {'n_lstm_layers': 2, 'lstm_units': 109, 'n_dense_layers': 0, 'lstm_dropout_0': 0.28680303941790064, 'lstm_dropout_1': 0.142338277876738, 'learning_rate': 0.000317427485783801}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:34:11,790] Trial 22 finished with value: 0.16269394755363464 and parameters: {'n_lstm_layers': 2, 'lstm_units': 104, 'n_dense_layers': 0, 'lstm_dropout_0': 0.22287338064315598, 'lstm_dropout_1': 0.14868565547933085, 'learning_rate': 0.0005140042387602542}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:34:18,726] Trial 23 finished with value: 0.16329461336135864 and parameters: {'n_lstm_layers': 2, 'lstm_units': 89, 'n_dense_layers': 0, 'lstm_dropout_0': 0.15054329505877434, 'lstm_dropout_1': 0.1451335989089405, 'learning_rate': 0.00022545719725575007}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:34:25,829] Trial 24 finished with value: 0.1635054051876068 and parameters: {'n_lstm_layers': 2, 'lstm_units': 73, 'n_dense_layers': 0, 'lstm_dropout_0': 0.34207993903389955, 'lstm_dropout_1': 0.10517036305070927, 'learning_rate': 0.00048326678600711935}. Best is trial 7 with value: 0.16153977811336517.
[I 2025-04-14 18:34:27,474] A new study created in memory with name: tune-10-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:34:34,585] Trial 0 finished with value: 0.1732964962720871 and parameters: {'n_lstm_layers': 2, 'lstm_units': 111, 'n_dense_layers': 1, 'lstm_dropout_0': 0.1834557585732296, 'lstm_dropout_1': 0.43904660697689124, 'dense_units_0': 18, 'dense_dropout_0': 0.1350998876755318, 'learning_rate': 0.0008049569152114984}. Best is trial 0 with value: 0.1732964962720871.
[I 2025-04-14 18:34:41,496] Trial 1 finished with value: 0.22108805179595947 and parameters: {'n_lstm_layers': 2, 'lstm_units': 51, 'n_dense_layers': 0, 'lstm_dropout_0': 0.14190153973664393, 'lstm_dropout_1': 0.31576809735700007, 'learning_rate': 0.00011230540207778965}. Best is trial 0 with value: 0.1732964962720871.
[I 2025-04-14 18:34:48,706] Trial 2 finished with value: 0.1695568859577179 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 1, 'lstm_dropout_0': 0.44269656234767896, 'lstm_dropout_1': 0.3840590941358363, 'dense_units_0': 53, 'dense_dropout_0': 0.35977843274474475, 'learning_rate': 0.001181210110554509}. Best is trial 2 with value: 0.1695568859577179.
[I 2025-04-14 18:34:53,635] Trial 3 finished with value: 0.2234959602355957 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3998630601482833, 'dense_units_0': 51, 'dense_dropout_0': 0.13255824193165797, 'dense_units_1': 50, 'dense_dropout_1': 0.35801738321858734, 'learning_rate': 0.00023501256330921784}. Best is trial 2 with value: 0.1695568859577179.
[I 2025-04-14 18:34:57,693] Trial 4 finished with value: 0.1653793454170227 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 2, 'lstm_dropout_0': 0.19885533375865277, 'dense_units_0': 57, 'dense_dropout_0': 0.21967487115993567, 'dense_units_1': 48, 'dense_dropout_1': 0.41445856389186275, 'learning_rate': 0.007277655614582639}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:02,383] Trial 5 finished with value: 0.2254694402217865 and parameters: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3127314437302726, 'dense_units_0': 18, 'dense_dropout_0': 0.26150805826867796, 'learning_rate': 0.0005079305918157122}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:06,894] Trial 6 finished with value: 0.17002013325691223 and parameters: {'n_lstm_layers': 1, 'lstm_units': 90, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1067487983597125, 'learning_rate': 0.0010251101170079442}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:11,062] Trial 7 finished with value: 0.1684390902519226 and parameters: {'n_lstm_layers': 1, 'lstm_units': 45, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21752208554917468, 'learning_rate': 0.003426190514578847}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:15,281] Trial 8 finished with value: 0.16557824611663818 and parameters: {'n_lstm_layers': 1, 'lstm_units': 56, 'n_dense_layers': 2, 'lstm_dropout_0': 0.41886716271198476, 'dense_units_0': 26, 'dense_dropout_0': 0.22364876803268735, 'dense_units_1': 24, 'dense_dropout_1': 0.30342069150740014, 'learning_rate': 0.004300544920086494}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:22,283] Trial 9 finished with value: 0.16664382815361023 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 0, 'lstm_dropout_0': 0.14477737813733477, 'lstm_dropout_1': 0.4686684654813217, 'learning_rate': 0.0012281495866199592}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:26,171] Trial 10 finished with value: 0.16796645522117615 and parameters: {'n_lstm_layers': 1, 'lstm_units': 32, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2697254022254184, 'dense_units_0': 63, 'dense_dropout_0': 0.48231404173936493, 'dense_units_1': 64, 'dense_dropout_1': 0.4978628802952568, 'learning_rate': 0.008617437060703278}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:30,698] Trial 11 finished with value: 0.16568943858146667 and parameters: {'n_lstm_layers': 1, 'lstm_units': 46, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4941040433138383, 'dense_units_0': 31, 'dense_dropout_0': 0.2542146529415228, 'dense_units_1': 21, 'dense_dropout_1': 0.2585995400117173, 'learning_rate': 0.009486014716408734}. Best is trial 4 with value: 0.1653793454170227.

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.155359

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.156227

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.160155

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.153247

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.156010

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.159580

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.154591

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.154882

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.159954

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.166167

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.155481

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.158916

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.160446

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.156149

--- Best Results for Feeder=10, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.153247
Best Hyperparameters:
  n_estimators: 229
  learning_rate: 0.015367922521804266
  num_leaves: 47
  max_depth: 6
  min_child_samples: 5
  subsample: 0.7461358409822427
  colsample_bytree: 0.7497854231982228
  reg_alpha: 0.00225594560166635
  reg_lambda: 0.03982146668079337

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=10, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=10, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=10, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 177, Version: v1.1_Final_Forecasting_20250414170702, Path Info: {"keras_model": "models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702.keras", "scalers_pkl": "models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702.keras', 'scalers_pkl': 'models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702_scalers.pkl'}
Detected separate Keras model (models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702.keras) and scalers (models/feeder_10/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170702_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.[I 2025-04-14 18:35:34,880] Trial 12 finished with value: 0.16762897372245789 and parameters: {'n_lstm_layers': 1, 'lstm_units': 36, 'n_dense_layers': 2, 'lstm_dropout_0': 0.36149745051158033, 'dense_units_0': 28, 'dense_dropout_0': 0.21026443744113177, 'dense_units_1': 27, 'dense_dropout_1': 0.3785453519410331, 'learning_rate': 0.003591433811772461}. Best is trial 4 with value: 0.1653793454170227.
[I 2025-04-14 18:35:39,381] Trial 13 finished with value: 0.16509604454040527 and parameters: {'n_lstm_layers': 1, 'lstm_units': 57, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2553777297652144, 'dense_units_0': 40, 'dense_dropout_0': 0.34737598746294085, 'dense_units_1': 38, 'dense_dropout_1': 0.11094207453858271, 'learning_rate': 0.0032969859439712706}. Best is trial 13 with value: 0.16509604454040527.
[I 2025-04-14 18:35:43,573] Trial 14 finished with value: 0.16542714834213257 and parameters: {'n_lstm_layers': 1, 'lstm_units': 41, 'n_dense_layers': 2, 'lstm_dropout_0': 0.23704049216710893, 'dense_units_0': 44, 'dense_dropout_0': 0.36932073975844926, 'dense_units_1': 39, 'dense_dropout_1': 0.19062175064251224, 'learning_rate': 0.002272988986373054}. Best is trial 13 with value: 0.16509604454040527.
[I 2025-04-14 18:35:47,917] Trial 15 finished with value: 0.16474254429340363 and parameters: {'n_lstm_layers': 1, 'lstm_units': 63, 'n_dense_layers': 1, 'lstm_dropout_0': 0.31816764108355294, 'dense_units_0': 40, 'dense_dropout_0': 0.34266377150597205, 'learning_rate': 0.0051671961555181025}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:35:52,372] Trial 16 finished with value: 0.16884902119636536 and parameters: {'n_lstm_layers': 1, 'lstm_units': 68, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3302534801964504, 'dense_units_0': 38, 'dense_dropout_0': 0.36442314064560777, 'learning_rate': 0.0022639355791514316}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:35:59,287] Trial 17 finished with value: 0.16620782017707825 and parameters: {'n_lstm_layers': 2, 'lstm_units': 80, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2602073410918086, 'lstm_dropout_1': 0.12755115183117163, 'dense_units_0': 39, 'dense_dropout_0': 0.44475020688910233, 'learning_rate': 0.004842095966643602}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:03,546] Trial 18 finished with value: 0.16613154113292694 and parameters: {'n_lstm_layers': 1, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3501923262276066, 'dense_units_0': 36, 'dense_dropout_0': 0.3229308725084302, 'learning_rate': 0.0022249445067030215}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:07,887] Trial 19 finished with value: 0.16512887179851532 and parameters: {'n_lstm_layers': 1, 'lstm_units': 58, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2920886511578345, 'dense_units_0': 24, 'dense_dropout_0': 0.415057187050409, 'learning_rate': 0.006290484194752892}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:14,280] Trial 20 finished with value: 0.17091505229473114 and parameters: {'n_lstm_layers': 2, 'lstm_units': 75, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3682031303961445, 'lstm_dropout_1': 0.12703999606033897, 'dense_units_0': 45, 'dense_dropout_0': 0.3239207696616957, 'learning_rate': 0.0016644186530298693}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:17,919] Trial 21 finished with value: 0.1669897437095642 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2855184161545401, 'dense_units_0': 23, 'dense_dropout_0': 0.4187303352008908, 'learning_rate': 0.005645981083025048}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:21,932] Trial 22 finished with value: 0.16616323590278625 and parameters: {'n_lstm_layers': 1, 'lstm_units': 65, 'n_dense_layers': 1, 'lstm_dropout_0': 0.30709566069442334, 'dense_units_0': 22, 'dense_dropout_0': 0.40734738234747475, 'learning_rate': 0.006129653771241427}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:26,430] Trial 23 finished with value: 0.16694539785385132 and parameters: {'n_lstm_layers': 1, 'lstm_units': 51, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2479973642358769, 'dense_units_0': 32, 'dense_dropout_0': 0.4933882637934114, 'learning_rate': 0.003067057960984721}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:31,031] Trial 24 finished with value: 0.17569667100906372 and parameters: {'n_lstm_layers': 1, 'lstm_units': 84, 'n_dense_layers': 1, 'lstm_dropout_0': 0.29882668845582894, 'dense_units_0': 44, 'dense_dropout_0': 0.29677040971304436, 'learning_rate': 0.0005803149955769714}. Best is trial 15 with value: 0.16474254429340363.
[I 2025-04-14 18:36:32,093] A new study created in memory with name: tune-11-LightGBM_Baseline-24hr
[I 2025-04-14 18:36:32,753] Trial 0 finished with value: 0.19915525200957476 and parameters: {'n_estimators': 133, 'learning_rate': 0.0019524346277710453, 'num_leaves': 51, 'max_depth': 4, 'min_child_samples': 28, 'subsample': 0.522496401604813, 'colsample_bytree': 0.8481953600779986, 'reg_alpha': 1.4265861126758668e-07, 'reg_lambda': 4.770914566758715e-05}. Best is trial 0 with value: 0.19915525200957476.
[I 2025-04-14 18:36:33,516] Trial 1 finished with value: 0.19199805090935243 and parameters: {'n_estimators': 205, 'learning_rate': 0.0028004042877982395, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 46, 'subsample': 0.8203321092597242, 'colsample_bytree': 0.7749097069287036, 'reg_alpha': 0.0640432684691066, 'reg_lambda': 1.84798698581021e-07}. Best is trial 1 with value: 0.19199805090935243.
[I 2025-04-14 18:36:34,661] Trial 2 finished with value: 0.10087658941652478 and parameters: {'n_estimators': 196, 'learning_rate': 0.06949863492688538, 'num_leaves': 40, 'max_depth': 5, 'min_child_samples': 19, 'subsample': 0.8497916964611758, 'colsample_bytree': 0.5407547269553166, 'reg_alpha': 0.0046594059660883935, 'reg_lambda': 0.019664959621943395}. Best is trial 2 with value: 0.10087658941652478.
[I 2025-04-14 18:36:37,135] Trial 3 finished with value: 0.14475849418246808 and parameters: {'n_estimators': 258, 'learning_rate': 0.003602326692580551, 'num_leaves': 21, 'max_depth': 8, 'min_child_samples': 10, 'subsample': 0.5555773328984663, 'colsample_bytree': 0.9659539082274418, 'reg_alpha': 0.032649875331003164, 'reg_lambda': 0.003041485644205163}. Best is trial 2 with value: 0.10087658941652478.
[I 2025-04-14 18:36:38,271] Trial 4 finished with value: 0.12341423860757648 and parameters: {'n_estimators': 207, 'learning_rate': 0.17579451632243112, 'num_leaves': 52, 'max_depth': 7, 'min_child_samples': 22, 'subsample': 0.9594187191265167, 'colsample_bytree': 0.66641824909932, 'reg_alpha': 0.00981818776993742, 'reg_lambda': 2.3539890372481215e-06}. Best is trial 2 with value: 0.10087658941652478.
[I 2025-04-14 18:36:38,644] Trial 5 finished with value: 0.16224237126806143 and parameters: {'n_estimators': 61, 'learning_rate': 0.030174926092717238, 'num_leaves': 33, 'max_depth': 9, 'min_child_samples': 43, 'subsample': 0.5074986774505112, 'colsample_bytree': 0.7165307942494945, 'reg_alpha': 1.2398121348624994e-07, 'reg_lambda': 0.00038320975259104165}. Best is trial 2 with value: 0.10087658941652478.
[I 2025-04-14 18:36:39,307] Trial 6 finished with value: 0.0961180001574335 and parameters: {'n_estimators': 74, 'learning_rate': 0.08790556475647288, 'num_leaves': 29, 'max_depth': 5, 'min_child_samples': 18, 'subsample': 0.8555317383386971, 'colsample_bytree': 0.9466203051905835, 'reg_alpha': 2.492847362572821e-06, 'reg_lambda': 2.1661061231454955e-06}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:40,464] Trial 7 finished with value: 0.1387298490541816 and parameters: {'n_estimators': 287, 'learning_rate': 0.12188042831675427, 'num_leaves': 54, 'max_depth': 3, 'min_child_samples': 32, 'subsample': 0.9726791194961015, 'colsample_bytree': 0.7584091625934988, 'reg_alpha': 0.00021369504860827937, 'reg_lambda': 0.015996392976678965}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:41,233] Trial 8 finished with value: 0.20165429669085436 and parameters: {'n_estimators': 186, 'learning_rate': 0.001216396773517595, 'num_leaves': 58, 'max_depth': 6, 'min_child_samples': 31, 'subsample': 0.7801179440415538, 'colsample_bytree': 0.6437832972861712, 'reg_alpha': 7.924572592107413e-06, 'reg_lambda': 1.1800775222997249e-06}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:42,494] Trial 9 finished with value: 0.19798663181680587 and parameters: {'n_estimators': 235, 'learning_rate': 0.0010878114822191138, 'num_leaves': 57, 'max_depth': 9, 'min_child_samples': 21, 'subsample': 0.9070926001829958, 'colsample_bytree': 0.8131285934777419, 'reg_alpha': 0.0008999242918972547, 'reg_lambda': 5.005127714042501e-07}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:43,197] Trial 10 finished with value: 0.15836500723848282 and parameters: {'n_estimators': 56, 'learning_rate': 0.012400903445189298, 'num_leaves': 10, 'max_depth': 11, 'min_child_samples': 8, 'subsample': 0.6941787551197119, 'colsample_bytree': 0.9916685573918191, 'reg_alpha': 8.079250962603804e-06, 'reg_lambda': 0.7572703247723773}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:44,127] Trial 11 finished with value: 0.10477486542487051 and parameters: {'n_estimators': 130, 'learning_rate': 0.04309248438290123, 'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 16, 'subsample': 0.8524177771796946, 'colsample_bytree': 0.5084446786969701, 'reg_alpha': 4.387979414309793e-06, 'reg_lambda': 0.6466064044689604}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:44,978] Trial 12 finished with value: 0.10323910308871835 and parameters: {'n_estimators': 147, 'learning_rate': 0.0728993598362588, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 16, 'subsample': 0.6976624532682991, 'colsample_bytree': 0.5214086996362722, 'reg_alpha': 0.0019014281978045457, 'reg_lambda': 2.6368439236440956e-05}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:45,497] Trial 13 finished with value: 0.14064129250121207 and parameters: {'n_estimators': 95, 'learning_rate': 0.29792154040925056, 'num_leaves': 25, 'max_depth': 5, 'min_child_samples': 36, 'subsample': 0.8791762121966475, 'colsample_bytree': 0.896674756921774, 'reg_alpha': 0.5256341928686875, 'reg_lambda': 1.0590263354583108e-08}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:46,458] Trial 14 finished with value: 0.10711229736993659 and parameters: {'n_estimators': 163, 'learning_rate': 0.018540678326217624, 'num_leaves': 24, 'max_depth': 5, 'min_child_samples': 21, 'subsample': 0.7263688878338347, 'colsample_bytree': 0.5991520212945428, 'reg_alpha': 2.0597468525422676e-08, 'reg_lambda': 0.023149872484038207}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:47,922] Trial 15 finished with value: 0.1485791893458281 and parameters: {'n_estimators': 96, 'learning_rate': 0.008687134972658429, 'num_leaves': 45, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.633329015192473, 'colsample_bytree': 0.916864213642949, 'reg_alpha': 5.128758740756402e-05, 'reg_lambda': 0.0005684519534570611}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:48,882] Trial 16 finished with value: 0.10215358824431721 and parameters: {'n_estimators': 101, 'learning_rate': 0.06345774019340705, 'num_leaves': 29, 'max_depth': 7, 'min_child_samples': 13, 'subsample': 0.8024975377834894, 'colsample_bytree': 0.5787761086755664, 'reg_alpha': 1.2719865857291876e-06, 'reg_lambda': 8.104249740266152e-06}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:50,145] Trial 17 finished with value: 0.1384451574116511 and parameters: {'n_estimators': 236, 'learning_rate': 0.11931853243635107, 'num_leaves': 17, 'max_depth': 4, 'min_child_samples': 24, 'subsample': 0.9307219194964217, 'colsample_bytree': 0.6892170962491517, 'reg_alpha': 0.00019109581307824805, 'reg_lambda': 2.9113985582467656e-08}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:50,980] Trial 18 finished with value: 0.1499194561301885 and parameters: {'n_estimators': 180, 'learning_rate': 0.029449218041609382, 'num_leaves': 38, 'max_depth': 6, 'min_child_samples': 38, 'subsample': 0.8707100218476537, 'colsample_bytree': 0.8520522973537121, 'reg_alpha': 0.9269982145481698, 'reg_lambda': 0.10383980105301369}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:51,818] Trial 19 finished with value: 0.10803832936496016 and parameters: {'n_estimators': 113, 'learning_rate': 0.2806749734819282, 'num_leaves': 46, 'max_depth': 4, 'min_child_samples': 17, 'subsample': 0.7762750147716295, 'colsample_bytree': 0.5893901226902334, 'reg_alpha': 4.1033125155286517e-05, 'reg_lambda': 0.0012919422480804417}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:52,787] Trial 20 finished with value: 0.15579057546601313 and parameters: {'n_estimators': 295, 'learning_rate': 0.07171231206924687, 'num_leaves': 31, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.9917843502275128, 'colsample_bytree': 0.9293062147419004, 'reg_alpha': 0.0013969951192323612, 'reg_lambda': 0.00011432230722593029}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:53,671] Trial 21 finished with value: 0.10514222787282711 and parameters: {'n_estimators': 69, 'learning_rate': 0.05923797833322377, 'num_leaves': 28, 'max_depth': 7, 'min_child_samples': 12, 'subsample': 0.8277605465243136, 'colsample_bytree': 0.57782037107845, 'reg_alpha': 8.370752982492088e-07, 'reg_lambda': 7.1631172282747185e-06}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:54,814] Trial 22 finished with value: 0.10732507025195537 and parameters: {'n_estimators': 84, 'learning_rate': 0.11644050030035749, 'num_leaves': 36, 'max_depth': 6, 'min_child_samples': 13, 'subsample': 0.7933075476403048, 'colsample_bytree': 0.5412120880614787, 'reg_alpha': 1.2053722635039867e-06, 'reg_lambda': 7.058543801460353e-06}. Best is trial 6 with value: 0.0961180001574335.

Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.165258

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.169269

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.165024

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.167441

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.162989

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.168471

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.171489

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.161540

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.166990

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.279642

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.174938

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.161961

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.163106

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.161676

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.202174

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.163435

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.362135

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.161613

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.177428

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.168565

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.162987

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.164880

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.162694

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.163295

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.163505

--- Best Results for Feeder=10, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.161540
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 109
  n_dense_layers: 0
  lstm_dropout_0: 0.18177978754814667
  lstm_dropout_1: 0.12694580777200143
  learning_rate: 0.0026192952484302558

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=10, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=10, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 178, Version: v1.1_Final_Forecasting_20250414170709, Path Info: {"keras_model": "models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709.keras", "scalers_pkl": "models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709.keras', 'scalers_pkl': 'models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709_scalers.pkl'}
Detected separate Keras model (models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709.keras) and scalers (models/feeder_10/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170709_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (76, 177), y shape (76, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.173296

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.221088

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.169557

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.223496

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.165379

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.225469

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.170020

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.168439

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.165578

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.166644

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.167966

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.165689
[I 2025-04-14 18:36:55,734] Trial 23 finished with value: 0.10077351191645545 and parameters: {'n_estimators': 114, 'learning_rate': 0.03866868604412037, 'num_leaves': 18, 'max_depth': 9, 'min_child_samples': 18, 'subsample': 0.9099818609989857, 'colsample_bytree': 0.6193879261984734, 'reg_alpha': 4.387143977237275e-07, 'reg_lambda': 1.3107988224767723e-07}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:56,495] Trial 24 finished with value: 0.14806136185862248 and parameters: {'n_estimators': 124, 'learning_rate': 0.025585022654285566, 'num_leaves': 15, 'max_depth': 10, 'min_child_samples': 25, 'subsample': 0.9018839793562681, 'colsample_bytree': 0.6295250275407723, 'reg_alpha': 1.0893432770772942e-08, 'reg_lambda': 9.445226167071478e-08}. Best is trial 6 with value: 0.0961180001574335.
[I 2025-04-14 18:36:59,470] A new study created in memory with name: tune-11-LSTM_Baseload-24hr
[I 2025-04-14 18:37:07,111] Trial 0 finished with value: 0.18862101435661316 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4439218867738708, 'lstm_dropout_1': 0.3798880965443513, 'learning_rate': 0.00023449224259781336}. Best is trial 0 with value: 0.18862101435661316.
[I 2025-04-14 18:37:12,243] Trial 1 finished with value: 0.15265877544879913 and parameters: {'n_lstm_layers': 1, 'lstm_units': 35, 'n_dense_layers': 1, 'lstm_dropout_0': 0.35289361443554723, 'dense_units_0': 20, 'dense_dropout_0': 0.20111333876066442, 'learning_rate': 0.000785054363182483}. Best is trial 1 with value: 0.15265877544879913.
[I 2025-04-14 18:37:17,113] Trial 2 finished with value: 0.13178658485412598 and parameters: {'n_lstm_layers': 1, 'lstm_units': 41, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4344211844605931, 'learning_rate': 0.0011980542877013554}. Best is trial 2 with value: 0.13178658485412598.
[I 2025-04-14 18:37:24,042] Trial 3 finished with value: 0.14280669391155243 and parameters: {'n_lstm_layers': 2, 'lstm_units': 116, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3768159255067166, 'lstm_dropout_1': 0.16149206995980256, 'dense_units_0': 57, 'dense_dropout_0': 0.3843603241053307, 'dense_units_1': 53, 'dense_dropout_1': 0.4615052874044717, 'learning_rate': 0.0013703392676389491}. Best is trial 2 with value: 0.13178658485412598.
[I 2025-04-14 18:37:29,182] Trial 4 finished with value: 0.11999282240867615 and parameters: {'n_lstm_layers': 1, 'lstm_units': 59, 'n_dense_layers': 2, 'lstm_dropout_0': 0.10430954511745832, 'dense_units_0': 22, 'dense_dropout_0': 0.39390885177704504, 'dense_units_1': 54, 'dense_dropout_1': 0.3671550411524003, 'learning_rate': 0.0013590038562701341}. Best is trial 4 with value: 0.11999282240867615.
[I 2025-04-14 18:37:34,265] Trial 5 finished with value: 0.11223309487104416 and parameters: {'n_lstm_layers': 1, 'lstm_units': 53, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2259321677589232, 'dense_units_0': 18, 'dense_dropout_0': 0.15221938787764544, 'dense_units_1': 49, 'dense_dropout_1': 0.31222205921164603, 'learning_rate': 0.002167966276724681}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:37:42,088] Trial 6 finished with value: 0.13122043013572693 and parameters: {'n_lstm_layers': 2, 'lstm_units': 88, 'n_dense_layers': 2, 'lstm_dropout_0': 0.19593486617770176, 'lstm_dropout_1': 0.48134679789761303, 'dense_units_0': 30, 'dense_dropout_0': 0.49484998065822694, 'dense_units_1': 24, 'dense_dropout_1': 0.3326667062545392, 'learning_rate': 0.00234727703412098}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:37:49,316] Trial 7 finished with value: 0.11265594512224197 and parameters: {'n_lstm_layers': 2, 'lstm_units': 123, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3211866397624986, 'lstm_dropout_1': 0.4632838902824823, 'dense_units_0': 46, 'dense_dropout_0': 0.18679612664795955, 'learning_rate': 0.007262284342107441}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:37:56,911] Trial 8 finished with value: 0.15242251753807068 and parameters: {'n_lstm_layers': 2, 'lstm_units': 37, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4729937985374796, 'lstm_dropout_1': 0.46576656085913715, 'dense_units_0': 35, 'dense_dropout_0': 0.44568589198841035, 'dense_units_1': 20, 'dense_dropout_1': 0.4869473152086775, 'learning_rate': 0.0037083774144632104}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:38:01,426] Trial 9 finished with value: 0.13772697746753693 and parameters: {'n_lstm_layers': 1, 'lstm_units': 33, 'n_dense_layers': 2, 'lstm_dropout_0': 0.31483150401817994, 'dense_units_0': 39, 'dense_dropout_0': 0.36880331897505114, 'dense_units_1': 18, 'dense_dropout_1': 0.36873333686892196, 'learning_rate': 0.009589599876632523}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:38:06,478] Trial 10 finished with value: 0.3721170425415039 and parameters: {'n_lstm_layers': 1, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.22553758067420632, 'dense_units_0': 16, 'dense_dropout_0': 0.11101680782655718, 'learning_rate': 0.00012299998302025945}. Best is trial 5 with value: 0.11223309487104416.
[I 2025-04-14 18:38:13,961] Trial 11 finished with value: 0.09854495525360107 and parameters: {'n_lstm_layers': 2, 'lstm_units': 84, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2495586331656735, 'lstm_dropout_1': 0.23951942526028394, 'dense_units_0': 58, 'dense_dropout_0': 0.2098373588561905, 'learning_rate': 0.009778938872259967}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:18,485] Trial 12 finished with value: 0.11658094823360443 and parameters: {'n_lstm_layers': 1, 'lstm_units': 80, 'n_dense_layers': 1, 'lstm_dropout_0': 0.22153161954798864, 'dense_units_0': 60, 'dense_dropout_0': 0.2465147029789242, 'learning_rate': 0.004142789710571623}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:26,044] Trial 13 finished with value: 0.14570344984531403 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.16265947430383937, 'lstm_dropout_1': 0.20667887906375565, 'learning_rate': 0.0004913594669768247}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:33,018] Trial 14 finished with value: 0.11618171632289886 and parameters: {'n_lstm_layers': 2, 'lstm_units': 75, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2669368641848293, 'lstm_dropout_1': 0.29457149751487854, 'dense_units_0': 26, 'dense_dropout_0': 0.10572212111594563, 'learning_rate': 0.004504446973794782}. Best is trial 11 with value: 0.09854495525360107.

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.167629

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.165096

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.165427

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.164743

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.168849

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.166208

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.166132

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.165129

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.170915

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.166990

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.166163

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.166945

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.175697

--- Best Results for Feeder=10, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.164743
Best Hyperparameters:
  n_lstm_layers: 1
  lstm_units: 63
  n_dense_layers: 1
  lstm_dropout_0: 0.31816764108355294
  dense_units_0: 40
  dense_dropout_0: 0.34266377150597205
  learning_rate: 0.0051671961555181025

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=10, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 10, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=10, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=10, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 11 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 180, Version: v1.1_Final_Forecasting_20250414170721, Path Info: models/feeder_11/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170721.pkl
Loading artifact(s) based on path info: models/feeder_11/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170721.pkl
Detected single pickle artifact path: models/feeder_11/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170721.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170721.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170721.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.199155

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.191998

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.100877

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.144758

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.123414

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.162242

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.096118

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.138730

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.201654

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.197987

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.158365

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.104775

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.103239

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.140641

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.107112

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.148579

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.102154

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.138445

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.149919

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.108038

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.155791

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.105142

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.107325
[I 2025-04-14 18:38:38,113] Trial 15 finished with value: 0.11838804185390472 and parameters: {'n_lstm_layers': 1, 'lstm_units': 98, 'n_dense_layers': 1, 'lstm_dropout_0': 0.27503348603794536, 'dense_units_0': 17, 'dense_dropout_0': 0.28224622966403246, 'learning_rate': 0.0022449056835658772}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:43,349] Trial 16 finished with value: 0.1535944938659668 and parameters: {'n_lstm_layers': 1, 'lstm_units': 68, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1526543808850932, 'dense_units_0': 47, 'dense_dropout_0': 0.18022571456700054, 'dense_units_1': 38, 'dense_dropout_1': 0.13791482077192596, 'learning_rate': 0.00040076808426945754}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:50,856] Trial 17 finished with value: 0.10888080298900604 and parameters: {'n_lstm_layers': 2, 'lstm_units': 50, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2565725555621924, 'lstm_dropout_1': 0.1066132326289653, 'learning_rate': 0.006111771240997352}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:38:57,653] Trial 18 finished with value: 0.11678942292928696 and parameters: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3810311675114287, 'lstm_dropout_1': 0.10341559274879025, 'learning_rate': 0.006490740872247472}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:05,263] Trial 19 finished with value: 0.10649388283491135 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.263480900034621, 'lstm_dropout_1': 0.2612763269106575, 'learning_rate': 0.009217333053556716}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:12,756] Trial 20 finished with value: 0.10807396471500397 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1702698065138106, 'lstm_dropout_1': 0.27028158746927966, 'learning_rate': 0.008973073323082986}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:20,216] Trial 21 finished with value: 0.11087249219417572 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.16585338791229395, 'lstm_dropout_1': 0.27339936617463445, 'learning_rate': 0.008421850301975665}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:27,601] Trial 22 finished with value: 0.10847438126802444 and parameters: {'n_lstm_layers': 2, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.19138308674557958, 'lstm_dropout_1': 0.23984803573298413, 'learning_rate': 0.009775719597796762}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:35,027] Trial 23 finished with value: 0.11589420586824417 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10905057994052376, 'lstm_dropout_1': 0.35289158072115145, 'learning_rate': 0.0032508387173580313}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:42,574] Trial 24 finished with value: 0.11463657766580582 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 0, 'lstm_dropout_0': 0.295586214651274, 'lstm_dropout_1': 0.3446259614765015, 'learning_rate': 0.005329030395069484}. Best is trial 11 with value: 0.09854495525360107.
[I 2025-04-14 18:39:44,229] A new study created in memory with name: tune-11-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:39:49,266] Trial 0 finished with value: 0.11337772756814957 and parameters: {'n_lstm_layers': 1, 'lstm_units': 78, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4114386210154156, 'dense_units_0': 19, 'dense_dropout_0': 0.1437797327044446, 'learning_rate': 0.0019126387504533554}. Best is trial 0 with value: 0.11337772756814957.
[I 2025-04-14 18:39:54,066] Trial 1 finished with value: 0.2822013199329376 and parameters: {'n_lstm_layers': 1, 'lstm_units': 64, 'n_dense_layers': 1, 'lstm_dropout_0': 0.13018434881836877, 'dense_units_0': 25, 'dense_dropout_0': 0.48342323543558463, 'learning_rate': 0.00016127784694540084}. Best is trial 0 with value: 0.11337772756814957.
[I 2025-04-14 18:39:59,389] Trial 2 finished with value: 0.13580819964408875 and parameters: {'n_lstm_layers': 1, 'lstm_units': 62, 'n_dense_layers': 1, 'lstm_dropout_0': 0.13603284929549636, 'dense_units_0': 37, 'dense_dropout_0': 0.2811686942741124, 'learning_rate': 0.0005368808207053934}. Best is trial 0 with value: 0.11337772756814957.
[I 2025-04-14 18:40:06,964] Trial 3 finished with value: 0.10544324666261673 and parameters: {'n_lstm_layers': 2, 'lstm_units': 63, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3099631599943554, 'lstm_dropout_1': 0.27105181078990226, 'learning_rate': 0.003861108134085504}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:11,562] Trial 4 finished with value: 0.12190920859575272 and parameters: {'n_lstm_layers': 1, 'lstm_units': 40, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3259476137262956, 'dense_units_0': 17, 'dense_dropout_0': 0.19603075859192984, 'dense_units_1': 24, 'dense_dropout_1': 0.4201174802812536, 'learning_rate': 0.005301207231351567}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:19,310] Trial 5 finished with value: 0.16099442541599274 and parameters: {'n_lstm_layers': 2, 'lstm_units': 35, 'n_dense_layers': 2, 'lstm_dropout_0': 0.32478198474637887, 'lstm_dropout_1': 0.2778536498914242, 'dense_units_0': 16, 'dense_dropout_0': 0.23527242165703965, 'dense_units_1': 29, 'dense_dropout_1': 0.38527796765709554, 'learning_rate': 0.0005885453570618454}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:23,828] Trial 6 finished with value: 0.12217244505882263 and parameters: {'n_lstm_layers': 1, 'lstm_units': 37, 'n_dense_layers': 0, 'lstm_dropout_0': 0.48719583264111943, 'learning_rate': 0.0013469156198037398}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:31,519] Trial 7 finished with value: 0.16714665293693542 and parameters: {'n_lstm_layers': 2, 'lstm_units': 39, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18197658371810974, 'lstm_dropout_1': 0.487685411271948, 'learning_rate': 0.0003433951319797708}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:36,617] Trial 8 finished with value: 0.2725141942501068 and parameters: {'n_lstm_layers': 1, 'lstm_units': 78, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26181709259069647, 'dense_units_0': 19, 'dense_dropout_0': 0.18439121805729092, 'learning_rate': 0.00010657726290566381}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:41,473] Trial 9 finished with value: 0.13085688650608063 and parameters: {'n_lstm_layers': 1, 'lstm_units': 79, 'n_dense_layers': 2, 'lstm_dropout_0': 0.27231453246779225, 'dense_units_0': 31, 'dense_dropout_0': 0.320551396526613, 'dense_units_1': 48, 'dense_dropout_1': 0.30931062035823076, 'learning_rate': 0.0007616152708583874}. Best is trial 3 with value: 0.10544324666261673.
[I 2025-04-14 18:40:49,279] Trial 10 finished with value: 0.10053379088640213 and parameters: {'n_lstm_layers': 2, 'lstm_units': 127, 'n_dense_layers': 0, 'lstm_dropout_0': 0.41452901722284513, 'lstm_dropout_1': 0.13680331484116098, 'learning_rate': 0.009294264412399325}. Best is trial 10 with value: 0.10053379088640213.
[I 2025-04-14 18:40:56,851] Trial 11 finished with value: 0.09930500388145447 and parameters: {'n_lstm_layers': 2, 'lstm_units': 126, 'n_dense_layers': 0, 'lstm_dropout_0': 0.40915026485008116, 'lstm_dropout_1': 0.11149954434067108, 'learning_rate': 0.009498438059458804}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:04,650] Trial 12 finished with value: 0.0999104306101799 and parameters: {'n_lstm_layers': 2, 'lstm_units': 128, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4256625813415836, 'lstm_dropout_1': 0.10526604334781176, 'learning_rate': 0.009763072618136056}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:12,310] Trial 13 finished with value: 0.10374031215906143 and parameters: {'n_lstm_layers': 2, 'lstm_units': 124, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4157891223595561, 'lstm_dropout_1': 0.10248327098819726, 'learning_rate': 0.009304988190601104}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:20,001] Trial 14 finished with value: 0.10929213464260101 and parameters: {'n_lstm_layers': 2, 'lstm_units': 104, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4987355268995627, 'lstm_dropout_1': 0.17722300908875327, 'learning_rate': 0.0032106640915089994}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:26,877] Trial 15 finished with value: 0.11012596637010574 and parameters: {'n_lstm_layers': 2, 'lstm_units': 98, 'n_dense_layers': 0, 'lstm_dropout_0': 0.37355315635223973, 'lstm_dropout_1': 0.20522149912273083, 'learning_rate': 0.005679293233656955}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:34,756] Trial 16 finished with value: 0.11119671165943146 and parameters: {'n_lstm_layers': 2, 'lstm_units': 99, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4573062699799001, 'lstm_dropout_1': 0.40831000402205453, 'dense_units_0': 63, 'dense_dropout_0': 0.4928234335864818, 'learning_rate': 0.0024450150220000693}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:42,260] Trial 17 finished with value: 0.11288539320230484 and parameters: {'n_lstm_layers': 2, 'lstm_units': 49, 'n_dense_layers': 0, 'lstm_dropout_0': 0.38688585202391534, 'lstm_dropout_1': 0.22355604613502655, 'learning_rate': 0.0061293092686935296}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:49,775] Trial 18 finished with value: 0.10753799229860306 and parameters: {'n_lstm_layers': 2, 'lstm_units': 111, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4496375690156955, 'lstm_dropout_1': 0.10115564777576651, 'learning_rate': 0.0015775344144505566}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:41:56,879] Trial 19 finished with value: 0.10833306610584259 and parameters: {'n_lstm_layers': 2, 'lstm_units': 88, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3563440731167024, 'lstm_dropout_1': 0.3396306512566848, 'dense_units_0': 60, 'dense_dropout_0': 0.39702273175647584, 'learning_rate': 0.009939979180835425}. Best is trial 11 with value: 0.09930500388145447.
[I 2025-04-14 18:42:04,734] Trial 20 finished with value: 0.09916947782039642 and parameters: {'n_lstm_layers': 2, 'lstm_units': 115, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2285828274457054, 'lstm_dropout_1': 0.16919725134303384, 'dense_units_0': 41, 'dense_dropout_0': 0.10060917757860122, 'learning_rate': 0.0036422237367562294}. Best is trial 20 with value: 0.09916947782039642.
[I 2025-04-14 18:42:11,947] Trial 21 finished with value: 0.10418569296598434 and parameters: {'n_lstm_layers': 2, 'lstm_units': 115, 'n_dense_layers': 1, 'lstm_dropout_0': 0.19190308317065397, 'lstm_dropout_1': 0.1590892142023849, 'dense_units_0': 43, 'dense_dropout_0': 0.10215180032402243, 'learning_rate': 0.004074677330044054}. Best is trial 20 with value: 0.09916947782039642.
[I 2025-04-14 18:42:19,331] Trial 22 finished with value: 0.10352083295583725 and parameters: {'n_lstm_layers': 2, 'lstm_units': 128, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21887817677541999, 'lstm_dropout_1': 0.14396030709808164, 'learning_rate': 0.006392158644866677}. Best is trial 20 with value: 0.09916947782039642.
[I 2025-04-14 18:42:27,109] Trial 23 finished with value: 0.11926154047250748 and parameters: {'n_lstm_layers': 2, 'lstm_units': 96, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2517141086783306, 'lstm_dropout_1': 0.1052359474052496, 'dense_units_0': 48, 'dense_dropout_0': 0.31963469726978244, 'dense_units_1': 16, 'dense_dropout_1': 0.1453623583750692, 'learning_rate': 0.002682852083103333}. Best is trial 20 with value: 0.09916947782039642.
[I 2025-04-14 18:42:34,458] Trial 24 finished with value: 0.10198771208524704 and parameters: {'n_lstm_layers': 2, 'lstm_units': 112, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3453063001294605, 'lstm_dropout_1': 0.2170316433267327, 'learning_rate': 0.007061154012765495}. Best is trial 20 with value: 0.09916947782039642.

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.100774

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.148061

--- Best Results for Feeder=11, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.096118
Best Hyperparameters:
  n_estimators: 74
  learning_rate: 0.08790556475647288
  num_leaves: 29
  max_depth: 5
  min_child_samples: 18
  subsample: 0.8555317383386971
  colsample_bytree: 0.9466203051905835
  reg_alpha: 2.492847362572821e-06
  reg_lambda: 2.1661061231454955e-06

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=11, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=11, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Baseload, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=11, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 181, Version: v1.1_Final_Forecasting_20250414170724, Path Info: {"keras_model": "models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724.keras", "scalers_pkl": "models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724.keras', 'scalers_pkl': 'models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724_scalers.pkl'}
Detected separate Keras model (models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724.keras) and scalers (models/feeder_11/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170724_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.188621

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.152659

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.131787

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.142807

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.119993

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.112233

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.131220

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.112656

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.152423

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.137727

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.372117

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.098545

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.116581

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.145703

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.116182
[I 2025-04-14 18:42:35,532] A new study created in memory with name: tune-12-LightGBM_Baseline-24hr
[I 2025-04-14 18:42:39,849] Trial 0 finished with value: 0.030835979287348502 and parameters: {'n_estimators': 170, 'learning_rate': 0.23002725953728898, 'num_leaves': 12, 'max_depth': 7, 'min_child_samples': 19, 'subsample': 0.8204776166640376, 'colsample_bytree': 0.9116479332659164, 'reg_alpha': 1.4689202836571083e-05, 'reg_lambda': 4.9921107174654234e-05}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:41,257] Trial 1 finished with value: 0.047092776256397295 and parameters: {'n_estimators': 256, 'learning_rate': 0.002110387339238235, 'num_leaves': 57, 'max_depth': 3, 'min_child_samples': 11, 'subsample': 0.6649003871912964, 'colsample_bytree': 0.720262274971055, 'reg_alpha': 0.9537403179005968, 'reg_lambda': 0.001666136754528899}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:42,281] Trial 2 finished with value: 0.047792926599788656 and parameters: {'n_estimators': 87, 'learning_rate': 0.005667126398444577, 'num_leaves': 16, 'max_depth': 9, 'min_child_samples': 6, 'subsample': 0.7254105345613275, 'colsample_bytree': 0.7446819952201869, 'reg_alpha': 1.1701572157486195e-06, 'reg_lambda': 1.306053638820527e-06}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:42,983] Trial 3 finished with value: 0.06154215913340907 and parameters: {'n_estimators': 243, 'learning_rate': 0.0014058524460302101, 'num_leaves': 45, 'max_depth': 12, 'min_child_samples': 49, 'subsample': 0.872329612550262, 'colsample_bytree': 0.7530791170956077, 'reg_alpha': 3.0326949582140462e-05, 'reg_lambda': 0.02261707727056117}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:43,663] Trial 4 finished with value: 0.044019672019761806 and parameters: {'n_estimators': 176, 'learning_rate': 0.00429541279857603, 'num_leaves': 46, 'max_depth': 8, 'min_child_samples': 39, 'subsample': 0.837906502683092, 'colsample_bytree': 0.6744923605988767, 'reg_alpha': 0.0006461917456754791, 'reg_lambda': 1.5024967289936677e-06}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:44,407] Trial 5 finished with value: 0.060877902715237575 and parameters: {'n_estimators': 249, 'learning_rate': 0.001764751465786051, 'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 49, 'subsample': 0.6920805170859035, 'colsample_bytree': 0.8464941367272175, 'reg_alpha': 3.8160662360134876e-08, 'reg_lambda': 7.816687285087689e-05}. Best is trial 0 with value: 0.030835979287348502.
[I 2025-04-14 18:42:45,276] Trial 6 finished with value: 0.02881561516165267 and parameters: {'n_estimators': 202, 'learning_rate': 0.013937578211585042, 'num_leaves': 50, 'max_depth': 4, 'min_child_samples': 33, 'subsample': 0.7211882623701305, 'colsample_bytree': 0.810427378672705, 'reg_alpha': 0.024475306725282014, 'reg_lambda': 0.0001798629542077042}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:45,857] Trial 7 finished with value: 0.06159702438275946 and parameters: {'n_estimators': 172, 'learning_rate': 0.001953747800214753, 'num_leaves': 41, 'max_depth': 3, 'min_child_samples': 47, 'subsample': 0.9160105435114757, 'colsample_bytree': 0.8243046484920673, 'reg_alpha': 3.7537553729183046e-07, 'reg_lambda': 0.5553945663545513}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:47,386] Trial 8 finished with value: 0.03047390468140844 and parameters: {'n_estimators': 234, 'learning_rate': 0.06185210638890761, 'num_leaves': 54, 'max_depth': 5, 'min_child_samples': 17, 'subsample': 0.6707441031139971, 'colsample_bytree': 0.5474649595638827, 'reg_alpha': 6.229593684179092e-05, 'reg_lambda': 0.09485990136272657}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:48,885] Trial 9 finished with value: 0.029257362482852513 and parameters: {'n_estimators': 257, 'learning_rate': 0.031797528146145074, 'num_leaves': 54, 'max_depth': 4, 'min_child_samples': 21, 'subsample': 0.5236608782141288, 'colsample_bytree': 0.6633538159612427, 'reg_alpha': 5.6878282142943274e-08, 'reg_lambda': 0.002806901446815527}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:49,318] Trial 10 finished with value: 0.03880854429142747 and parameters: {'n_estimators': 61, 'learning_rate': 0.013217963506038011, 'num_leaves': 27, 'max_depth': 6, 'min_child_samples': 33, 'subsample': 0.5453744666832613, 'colsample_bytree': 0.9612059909300259, 'reg_alpha': 0.027253269041995782, 'reg_lambda': 4.9485927105929236e-08}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:50,331] Trial 11 finished with value: 0.028900391911303367 and parameters: {'n_estimators': 206, 'learning_rate': 0.037637063259880955, 'num_leaves': 30, 'max_depth': 5, 'min_child_samples': 27, 'subsample': 0.5221398326006284, 'colsample_bytree': 0.5967116658846013, 'reg_alpha': 0.006592729804581211, 'reg_lambda': 0.0007850210730723493}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:51,277] Trial 12 finished with value: 0.029616564037114806 and parameters: {'n_estimators': 193, 'learning_rate': 0.07411669181311817, 'num_leaves': 29, 'max_depth': 5, 'min_child_samples': 29, 'subsample': 0.5870232740775974, 'colsample_bytree': 0.530815936768151, 'reg_alpha': 0.004223955794060155, 'reg_lambda': 0.0005913544551503222}. Best is trial 6 with value: 0.02881561516165267.
[I 2025-04-14 18:42:52,396] Trial 13 finished with value: 0.028440528571149894 and parameters: {'n_estimators': 299, 'learning_rate': 0.015107597365832939, 'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 38, 'subsample': 0.6068132863816866, 'colsample_bytree': 0.6025554006929035, 'reg_alpha': 0.09655365044057063, 'reg_lambda': 8.571509033735547e-06}. Best is trial 13 with value: 0.028440528571149894.
[I 2025-04-14 18:42:53,577] Trial 14 finished with value: 0.02788431122093418 and parameters: {'n_estimators': 294, 'learning_rate': 0.014580565805057885, 'num_leaves': 39, 'max_depth': 7, 'min_child_samples': 40, 'subsample': 0.617928708949561, 'colsample_bytree': 0.8250732927523945, 'reg_alpha': 0.24131843645923107, 'reg_lambda': 2.909131533395455e-06}. Best is trial 14 with value: 0.02788431122093418.
[I 2025-04-14 18:42:54,632] Trial 15 finished with value: 0.03292367533618499 and parameters: {'n_estimators': 296, 'learning_rate': 0.00658616290124886, 'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 41, 'subsample': 0.9816255521251585, 'colsample_bytree': 0.6030088938143336, 'reg_alpha': 0.6377320324527617, 'reg_lambda': 4.31339916395792e-06}. Best is trial 14 with value: 0.02788431122093418.
[I 2025-04-14 18:42:55,697] Trial 16 finished with value: 0.027371289033547325 and parameters: {'n_estimators': 299, 'learning_rate': 0.021717148882897903, 'num_leaves': 22, 'max_depth': 7, 'min_child_samples': 41, 'subsample': 0.5989940441261528, 'colsample_bytree': 0.8884160934573438, 'reg_alpha': 0.07610914060294705, 'reg_lambda': 1.9418139277052897e-08}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:42:56,356] Trial 17 finished with value: 0.05410703270627065 and parameters: {'n_estimators': 123, 'learning_rate': 0.15658264818368592, 'num_leaves': 22, 'max_depth': 7, 'min_child_samples': 42, 'subsample': 0.6089713395166713, 'colsample_bytree': 0.8843479138190163, 'reg_alpha': 0.0007495930404480533, 'reg_lambda': 1.0177450664015698e-08}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:42:57,561] Trial 18 finished with value: 0.05356138525550897 and parameters: {'n_estimators': 279, 'learning_rate': 0.02841692487047113, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 44, 'subsample': 0.7758444039322862, 'colsample_bytree': 0.987444687645178, 'reg_alpha': 0.1460800072309126, 'reg_lambda': 1.7024876240400577e-07}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:42:58,804] Trial 19 finished with value: 0.029247474633459804 and parameters: {'n_estimators': 274, 'learning_rate': 0.008638757418802885, 'num_leaves': 38, 'max_depth': 8, 'min_child_samples': 35, 'subsample': 0.6280894821294826, 'colsample_bytree': 0.9360178827118198, 'reg_alpha': 0.000554703497082413, 'reg_lambda': 2.5190382182180673e-07}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:42:59,527] Trial 20 finished with value: 0.04743796952821679 and parameters: {'n_estimators': 136, 'learning_rate': 0.0034223363849771728, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 28, 'subsample': 0.5710046765704401, 'colsample_bytree': 0.8677677022359712, 'reg_alpha': 0.12173219252526435, 'reg_lambda': 2.4884574992526474e-08}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:43:00,654] Trial 21 finished with value: 0.02779982992321266 and parameters: {'n_estimators': 299, 'learning_rate': 0.0193315824347316, 'num_leaves': 28, 'max_depth': 6, 'min_child_samples': 37, 'subsample': 0.6354231353245589, 'colsample_bytree': 0.7968251632127175, 'reg_alpha': 0.14700382225703207, 'reg_lambda': 1.1411046167857216e-05}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:43:01,668] Trial 22 finished with value: 0.05347318659512332 and parameters: {'n_estimators': 276, 'learning_rate': 0.025594444851119766, 'num_leaves': 17, 'max_depth': 6, 'min_child_samples': 44, 'subsample': 0.6199121734343317, 'colsample_bytree': 0.7903480415517593, 'reg_alpha': 0.008879438040788997, 'reg_lambda': 9.33936071205977e-06}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:43:02,602] Trial 23 finished with value: 0.02775603581422036 and parameters: {'n_estimators': 224, 'learning_rate': 0.049062523362798045, 'num_leaves': 26, 'max_depth': 7, 'min_child_samples': 36, 'subsample': 0.6522380244765171, 'colsample_bytree': 0.7857233724286468, 'reg_alpha': 0.2726328150152904, 'reg_lambda': 3.1423899443195704e-07}. Best is trial 16 with value: 0.027371289033547325.
[I 2025-04-14 18:43:03,791] Trial 24 finished with value: 0.028943323184129444 and parameters: {'n_estimators': 222, 'learning_rate': 0.08450159705232622, 'num_leaves': 25, 'max_depth': 6, 'min_child_samples': 24, 'subsample': 0.6672762523482334, 'colsample_bytree': 0.7726782118292139, 'reg_alpha': 0.03155234887765084, 'reg_lambda': 2.2721097243283568e-07}. Best is trial 16 with value: 0.027371289033547325.

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.118388

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.153594

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.108881

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.116789

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.106494

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.108074

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.110872

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.108474

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.115894

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.114637

--- Best Results for Feeder=11, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.098545
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 84
  n_dense_layers: 1
  lstm_dropout_0: 0.2495586331656735
  lstm_dropout_1: 0.23951942526028394
  dense_units_0: 58
  dense_dropout_0: 0.2098373588561905
  learning_rate: 0.009778938872259967

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=11, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=11, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 182, Version: v1.1_Final_Forecasting_20250414170732, Path Info: {"keras_model": "models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732.keras", "scalers_pkl": "models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732.keras', 'scalers_pkl': 'models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732_scalers.pkl'}
Detected separate Keras model (models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732.keras) and scalers (models/feeder_11/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170732_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (152, 177), y shape (152, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (30, 177), y shape (30, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.113378

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.282201

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.135808

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.105443

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.121909

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.160994

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.122172

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.167147

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.272514

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.130857

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.100534

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.099305

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.099910

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.103740

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.109292

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.110126

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.111197

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.112885

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.107538

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.108333

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.099169

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.104186

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.103521

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.119262

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.101988

--- Best Results for Feeder=11, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.099169
Best Hyperparameters:
  n_lstm_layers: 2
[I 2025-04-14 18:43:07,326] A new study created in memory with name: tune-12-LSTM_Baseload-24hr
[I 2025-04-14 18:43:14,592] Trial 0 finished with value: 0.07816846668720245 and parameters: {'n_lstm_layers': 2, 'lstm_units': 32, 'n_dense_layers': 0, 'lstm_dropout_0': 0.29268524117146627, 'lstm_dropout_1': 0.33599190868440854, 'learning_rate': 0.0001248465407259068}. Best is trial 0 with value: 0.07816846668720245.
[I 2025-04-14 18:43:22,249] Trial 1 finished with value: 0.05692011117935181 and parameters: {'n_lstm_layers': 2, 'lstm_units': 57, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4387377048247204, 'lstm_dropout_1': 0.39252282009547035, 'dense_units_0': 28, 'dense_dropout_0': 0.3052457749393841, 'dense_units_1': 56, 'dense_dropout_1': 0.42541262682766556, 'learning_rate': 0.00042764054172493766}. Best is trial 1 with value: 0.05692011117935181.
[I 2025-04-14 18:43:29,346] Trial 2 finished with value: 0.03717690706253052 and parameters: {'n_lstm_layers': 2, 'lstm_units': 36, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10806669686320239, 'lstm_dropout_1': 0.2692377246137603, 'learning_rate': 0.001449442539919632}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:43:36,779] Trial 3 finished with value: 0.0971180871129036 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.42114472519678636, 'lstm_dropout_1': 0.32287045006905557, 'dense_units_0': 32, 'dense_dropout_0': 0.4887804015645224, 'learning_rate': 0.00021311185255567302}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:43:41,336] Trial 4 finished with value: 0.039258427917957306 and parameters: {'n_lstm_layers': 1, 'lstm_units': 95, 'n_dense_layers': 1, 'lstm_dropout_0': 0.18196383820740758, 'dense_units_0': 34, 'dense_dropout_0': 0.37808316061887803, 'learning_rate': 0.0030290988783736534}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:43:48,693] Trial 5 finished with value: 0.04611195623874664 and parameters: {'n_lstm_layers': 2, 'lstm_units': 123, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2750144284330581, 'lstm_dropout_1': 0.31230208874164245, 'learning_rate': 0.0002845991143492626}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:43:53,685] Trial 6 finished with value: 0.09912858158349991 and parameters: {'n_lstm_layers': 1, 'lstm_units': 75, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4353833234330532, 'dense_units_0': 17, 'dense_dropout_0': 0.45031519510912277, 'dense_units_1': 35, 'dense_dropout_1': 0.42885101778179935, 'learning_rate': 0.000336298925899952}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:44:01,011] Trial 7 finished with value: 0.03764914348721504 and parameters: {'n_lstm_layers': 2, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.18974501081495956, 'lstm_dropout_1': 0.2072822918649273, 'dense_units_0': 42, 'dense_dropout_0': 0.11475414656487369, 'dense_units_1': 64, 'dense_dropout_1': 0.16350446668376023, 'learning_rate': 0.0006781801630902101}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:44:05,753] Trial 8 finished with value: 0.04713866487145424 and parameters: {'n_lstm_layers': 1, 'lstm_units': 77, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3736782847429371, 'learning_rate': 0.0005730708571557628}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:44:10,153] Trial 9 finished with value: 0.039706408977508545 and parameters: {'n_lstm_layers': 1, 'lstm_units': 100, 'n_dense_layers': 1, 'lstm_dropout_0': 0.10698787730752164, 'dense_units_0': 47, 'dense_dropout_0': 0.14472532055400789, 'learning_rate': 0.0021222866471199515}. Best is trial 2 with value: 0.03717690706253052.
[I 2025-04-14 18:44:16,906] Trial 10 finished with value: 0.03452669084072113 and parameters: {'n_lstm_layers': 2, 'lstm_units': 43, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10250517474993634, 'lstm_dropout_1': 0.10600047244373834, 'learning_rate': 0.005686222274679695}. Best is trial 10 with value: 0.03452669084072113.
[I 2025-04-14 18:44:24,005] Trial 11 finished with value: 0.03515664488077164 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10444462407550476, 'lstm_dropout_1': 0.11214597331226284, 'learning_rate': 0.009962794303673738}. Best is trial 10 with value: 0.03452669084072113.
[I 2025-04-14 18:44:30,816] Trial 12 finished with value: 0.034338127821683884 and parameters: {'n_lstm_layers': 2, 'lstm_units': 45, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18768761901327152, 'lstm_dropout_1': 0.10329113922841233, 'learning_rate': 0.009611312819031968}. Best is trial 12 with value: 0.034338127821683884.
[I 2025-04-14 18:44:39,661] Trial 13 finished with value: 0.03294532746076584 and parameters: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.21530238431069615, 'lstm_dropout_1': 0.10445753810725922, 'learning_rate': 0.009140378008998012}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:44:46,371] Trial 14 finished with value: 0.03481829911470413 and parameters: {'n_lstm_layers': 2, 'lstm_units': 46, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2128241916650549, 'lstm_dropout_1': 0.488278665244996, 'dense_units_0': 63, 'dense_dropout_0': 0.21979340701858463, 'learning_rate': 0.009372090040934039}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:44:53,064] Trial 15 finished with value: 0.035062648355960846 and parameters: {'n_lstm_layers': 2, 'lstm_units': 51, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2254621992785191, 'lstm_dropout_1': 0.18367731523679123, 'learning_rate': 0.004091894545294993}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:00,145] Trial 16 finished with value: 0.0333402156829834 and parameters: {'n_lstm_layers': 2, 'lstm_units': 65, 'n_dense_layers': 1, 'lstm_dropout_0': 0.34499010766597105, 'lstm_dropout_1': 0.18006350215525974, 'dense_units_0': 16, 'dense_dropout_0': 0.2824908051123021, 'learning_rate': 0.005523418104740992}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:04,196] Trial 17 finished with value: 0.03860093653202057 and parameters: {'n_lstm_layers': 1, 'lstm_units': 67, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3488520452824962, 'dense_units_0': 19, 'dense_dropout_0': 0.29489250581235676, 'learning_rate': 0.0051248141536112965}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:11,861] Trial 18 finished with value: 0.038088150322437286 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3452881732710296, 'lstm_dropout_1': 0.17731644323303197, 'dense_units_0': 24, 'dense_dropout_0': 0.23866357606548794, 'dense_units_1': 16, 'dense_dropout_1': 0.10299991823950772, 'learning_rate': 0.0022279647480246915}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:19,271] Trial 19 finished with value: 0.04514206200838089 and parameters: {'n_lstm_layers': 2, 'lstm_units': 91, 'n_dense_layers': 1, 'lstm_dropout_0': 0.26819730035692585, 'lstm_dropout_1': 0.23018754373051747, 'dense_units_0': 21, 'dense_dropout_0': 0.37905000713088566, 'learning_rate': 0.0012849049486226742}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:24,203] Trial 20 finished with value: 0.03616352379322052 and parameters: {'n_lstm_layers': 1, 'lstm_units': 55, 'n_dense_layers': 1, 'lstm_dropout_0': 0.48578547044092496, 'dense_units_0': 16, 'dense_dropout_0': 0.19049118514763633, 'learning_rate': 0.0061537269631544425}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:30,428] Trial 21 finished with value: 0.03658958524465561 and parameters: {'n_lstm_layers': 2, 'lstm_units': 48, 'n_dense_layers': 0, 'lstm_dropout_0': 0.24638066240717765, 'lstm_dropout_1': 0.1396959806088305, 'learning_rate': 0.00828198933044641}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:37,595] Trial 22 finished with value: 0.03552240878343582 and parameters: {'n_lstm_layers': 2, 'lstm_units': 38, 'n_dense_layers': 0, 'lstm_dropout_0': 0.15816963303397527, 'lstm_dropout_1': 0.1532673850407096, 'learning_rate': 0.0036089207148548006}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:44,489] Trial 23 finished with value: 0.03564627096056938 and parameters: {'n_lstm_layers': 2, 'lstm_units': 41, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32264919074670295, 'lstm_dropout_1': 0.11753381532912827, 'learning_rate': 0.006795528315051727}. Best is trial 13 with value: 0.03294532746076584.
[I 2025-04-14 18:45:51,254] Trial 24 finished with value: 0.032705508172512054 and parameters: {'n_lstm_layers': 2, 'lstm_units': 61, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1480122154703271, 'lstm_dropout_1': 0.24594247033383898, 'learning_rate': 0.0024326125463904748}. Best is trial 24 with value: 0.032705508172512054.
  lstm_units: 115
  n_dense_layers: 1
  lstm_dropout_0: 0.2285828274457054
  lstm_dropout_1: 0.16919725134303384
  dense_units_0: 41
  dense_dropout_0: 0.10060917757860122
  learning_rate: 0.0036422237367562294

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=11, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 11, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=11, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=11, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Tuning for Feeder 12 =====

--- Tuning: Arch=LightGBM_Baseline, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LightGBM_Baseline, Scenario: 24hr, Version: None
Selected Model ID: 184, Version: v1.1_Final_Forecasting_20250414170745, Path Info: models/feeder_12/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170745.pkl
Loading artifact(s) based on path info: models/feeder_12/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170745.pkl
Detected single pickle artifact path: models/feeder_12/LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170745.pkl
Downloading single pickle artifact to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170745.pkl
Single pickle downloaded. Loading...
Single pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LightGBM_Baseline_24hr_v1.1_Final_Forecasting_20250414170745.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LightGBM_Baseline ---
Trial 0: Training model...
Trial 0: Evaluating model...
Trial 0: Validation Score (mae, scaled) = 0.030836

--- Optuna Trial 1 for LightGBM_Baseline ---
Trial 1: Training model...
Trial 1: Evaluating model...
Trial 1: Validation Score (mae, scaled) = 0.047093

--- Optuna Trial 2 for LightGBM_Baseline ---
Trial 2: Training model...
Trial 2: Evaluating model...
Trial 2: Validation Score (mae, scaled) = 0.047793

--- Optuna Trial 3 for LightGBM_Baseline ---
Trial 3: Training model...
Trial 3: Evaluating model...
Trial 3: Validation Score (mae, scaled) = 0.061542

--- Optuna Trial 4 for LightGBM_Baseline ---
Trial 4: Training model...
Trial 4: Evaluating model...
Trial 4: Validation Score (mae, scaled) = 0.044020

--- Optuna Trial 5 for LightGBM_Baseline ---
Trial 5: Training model...
Trial 5: Evaluating model...
Trial 5: Validation Score (mae, scaled) = 0.060878

--- Optuna Trial 6 for LightGBM_Baseline ---
Trial 6: Training model...
Trial 6: Evaluating model...
Trial 6: Validation Score (mae, scaled) = 0.028816

--- Optuna Trial 7 for LightGBM_Baseline ---
Trial 7: Training model...
Trial 7: Evaluating model...
Trial 7: Validation Score (mae, scaled) = 0.061597

--- Optuna Trial 8 for LightGBM_Baseline ---
Trial 8: Training model...
Trial 8: Evaluating model...
Trial 8: Validation Score (mae, scaled) = 0.030474

--- Optuna Trial 9 for LightGBM_Baseline ---
Trial 9: Training model...
Trial 9: Evaluating model...
Trial 9: Validation Score (mae, scaled) = 0.029257

--- Optuna Trial 10 for LightGBM_Baseline ---
Trial 10: Training model...
Trial 10: Evaluating model...
Trial 10: Validation Score (mae, scaled) = 0.038809

--- Optuna Trial 11 for LightGBM_Baseline ---
Trial 11: Training model...
Trial 11: Evaluating model...
Trial 11: Validation Score (mae, scaled) = 0.028900

--- Optuna Trial 12 for LightGBM_Baseline ---
Trial 12: Training model...
Trial 12: Evaluating model...
Trial 12: Validation Score (mae, scaled) = 0.029617

--- Optuna Trial 13 for LightGBM_Baseline ---
Trial 13: Training model...
Trial 13: Evaluating model...
Trial 13: Validation Score (mae, scaled) = 0.028441

--- Optuna Trial 14 for LightGBM_Baseline ---
Trial 14: Training model...
Trial 14: Evaluating model...
Trial 14: Validation Score (mae, scaled) = 0.027884

--- Optuna Trial 15 for LightGBM_Baseline ---
Trial 15: Training model...
Trial 15: Evaluating model...
Trial 15: Validation Score (mae, scaled) = 0.032924

--- Optuna Trial 16 for LightGBM_Baseline ---
Trial 16: Training model...
Trial 16: Evaluating model...
Trial 16: Validation Score (mae, scaled) = 0.027371

--- Optuna Trial 17 for LightGBM_Baseline ---
Trial 17: Training model...
Trial 17: Evaluating model...
Trial 17: Validation Score (mae, scaled) = 0.054107

--- Optuna Trial 18 for LightGBM_Baseline ---
Trial 18: Training model...
Trial 18: Evaluating model...
Trial 18: Validation Score (mae, scaled) = 0.053561

--- Optuna Trial 19 for LightGBM_Baseline ---
Trial 19: Training model...
Trial 19: Evaluating model...
Trial 19: Validation Score (mae, scaled) = 0.029247

--- Optuna Trial 20 for LightGBM_Baseline ---
Trial 20: Training model...
Trial 20: Evaluating model...
Trial 20: Validation Score (mae, scaled) = 0.047438

--- Optuna Trial 21 for LightGBM_Baseline ---
Trial 21: Training model...
Trial 21: Evaluating model...
Trial 21: Validation Score (mae, scaled) = 0.027800

--- Optuna Trial 22 for LightGBM_Baseline ---
Trial 22: Training model...
Trial 22: Evaluating model...
Trial 22: Validation Score (mae, scaled) = 0.053473

--- Optuna Trial 23 for LightGBM_Baseline ---
Trial 23: Training model...
Trial 23: Evaluating model...
Trial 23: Validation Score (mae, scaled) = 0.027756

--- Optuna Trial 24 for LightGBM_Baseline ---
Trial 24: Training model...
Trial 24: Evaluating model...
Trial 24: Validation Score (mae, scaled) = 0.028943

--- Best Results for Feeder=12, Arch=LightGBM_Baseline, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.027371
Best Hyperparameters:
  n_estimators: 299
  learning_rate: 0.021717148882897903
  num_leaves: 22
  max_depth: 7
  min_child_samples: 41
  subsample: 0.5989940441261528
  colsample_bytree: 0.8884160934573438
  reg_alpha: 0.07610914060294705
  reg_lambda: 1.9418139277052897e-08

--- Tuning: Arch=LightGBM_Baseline, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LightGBM_Baseline, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LightGBM_Baseline, Scenario=Day, Version=None
Warning: No existing model found for Feeder=12, Arch=LightGBM_Baseline, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LightGBM_Baseline, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LightGBM_Baseline, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LightGBM_Baseline, Scenario=Night, Version=None
Warning: No existing model found for Feeder=12, Arch=LightGBM_Baseline, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Baseload, Scenario: 24hr, Version: None
[I 2025-04-14 18:45:52,582] A new study created in memory with name: tune-12-LSTM_Change_in_Load-24hr
[I 2025-04-14 18:45:57,469] Trial 0 finished with value: 0.048726681619882584 and parameters: {'n_lstm_layers': 1, 'lstm_units': 48, 'n_dense_layers': 2, 'lstm_dropout_0': 0.38135222237105526, 'dense_units_0': 40, 'dense_dropout_0': 0.22476916088179022, 'dense_units_1': 56, 'dense_dropout_1': 0.3392308221896513, 'learning_rate': 0.0007596572819968436}. Best is trial 0 with value: 0.048726681619882584.
[I 2025-04-14 18:46:04,970] Trial 1 finished with value: 0.044811710715293884 and parameters: {'n_lstm_layers': 2, 'lstm_units': 96, 'n_dense_layers': 2, 'lstm_dropout_0': 0.1394035771829068, 'lstm_dropout_1': 0.178800504864585, 'dense_units_0': 22, 'dense_dropout_0': 0.2258560409927094, 'dense_units_1': 20, 'dense_dropout_1': 0.13993659418855905, 'learning_rate': 0.0021642638468656436}. Best is trial 1 with value: 0.044811710715293884.
[I 2025-04-14 18:46:12,372] Trial 2 finished with value: 0.04359309747815132 and parameters: {'n_lstm_layers': 2, 'lstm_units': 37, 'n_dense_layers': 0, 'lstm_dropout_0': 0.32443160813631045, 'lstm_dropout_1': 0.16139847176978056, 'learning_rate': 0.002177116139554525}. Best is trial 2 with value: 0.04359309747815132.
[I 2025-04-14 18:46:17,024] Trial 3 finished with value: 0.10556550323963165 and parameters: {'n_lstm_layers': 1, 'lstm_units': 109, 'n_dense_layers': 2, 'lstm_dropout_0': 0.40768483567228786, 'dense_units_0': 40, 'dense_dropout_0': 0.278983321161717, 'dense_units_1': 40, 'dense_dropout_1': 0.3020227368200959, 'learning_rate': 0.0002736545714694407}. Best is trial 2 with value: 0.04359309747815132.
[I 2025-04-14 18:46:21,793] Trial 4 finished with value: 0.04554923251271248 and parameters: {'n_lstm_layers': 1, 'lstm_units': 76, 'n_dense_layers': 0, 'lstm_dropout_0': 0.17068072435796827, 'learning_rate': 0.000830784194525543}. Best is trial 2 with value: 0.04359309747815132.
[I 2025-04-14 18:46:26,545] Trial 5 finished with value: 0.03780539706349373 and parameters: {'n_lstm_layers': 1, 'lstm_units': 73, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4659054922621725, 'dense_units_0': 34, 'dense_dropout_0': 0.20994300105650066, 'learning_rate': 0.0035553169106696952}. Best is trial 5 with value: 0.03780539706349373.
[I 2025-04-14 18:46:33,858] Trial 6 finished with value: 0.23360919952392578 and parameters: {'n_lstm_layers': 2, 'lstm_units': 76, 'n_dense_layers': 1, 'lstm_dropout_0': 0.10582280060431103, 'lstm_dropout_1': 0.24038821170346478, 'dense_units_0': 22, 'dense_dropout_0': 0.4952821993493479, 'learning_rate': 0.00013726586399588617}. Best is trial 5 with value: 0.03780539706349373.
[I 2025-04-14 18:46:38,643] Trial 7 finished with value: 0.06832101941108704 and parameters: {'n_lstm_layers': 1, 'lstm_units': 119, 'n_dense_layers': 0, 'lstm_dropout_0': 0.3307825783681875, 'learning_rate': 0.00016371903246861988}. Best is trial 5 with value: 0.03780539706349373.
[I 2025-04-14 18:46:45,946] Trial 8 finished with value: 0.03511636704206467 and parameters: {'n_lstm_layers': 2, 'lstm_units': 120, 'n_dense_layers': 1, 'lstm_dropout_0': 0.4646125728015842, 'lstm_dropout_1': 0.11179009797872319, 'dense_units_0': 38, 'dense_dropout_0': 0.15304886599084533, 'learning_rate': 0.004261186186680868}. Best is trial 8 with value: 0.03511636704206467.
[I 2025-04-14 18:46:51,013] Trial 9 finished with value: 0.035333793610334396 and parameters: {'n_lstm_layers': 1, 'lstm_units': 34, 'n_dense_layers': 2, 'lstm_dropout_0': 0.4777735438531251, 'dense_units_0': 22, 'dense_dropout_0': 0.20742076220831587, 'dense_units_1': 43, 'dense_dropout_1': 0.1168656230129527, 'learning_rate': 0.005009609490463576}. Best is trial 8 with value: 0.03511636704206467.
[I 2025-04-14 18:46:58,477] Trial 10 finished with value: 0.03163100406527519 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2251892786440224, 'lstm_dropout_1': 0.4697160729701241, 'dense_units_0': 64, 'dense_dropout_0': 0.10371474633760605, 'learning_rate': 0.008347199946264292}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:05,723] Trial 11 finished with value: 0.033335112035274506 and parameters: {'n_lstm_layers': 2, 'lstm_units': 53, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2247648357676823, 'lstm_dropout_1': 0.49841855944937813, 'dense_units_0': 64, 'dense_dropout_0': 0.10878124631368155, 'learning_rate': 0.009394879691159937}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:12,919] Trial 12 finished with value: 0.031964972615242004 and parameters: {'n_lstm_layers': 2, 'lstm_units': 52, 'n_dense_layers': 1, 'lstm_dropout_0': 0.22729960909662425, 'lstm_dropout_1': 0.4968015442314284, 'dense_units_0': 63, 'dense_dropout_0': 0.10477415649823091, 'learning_rate': 0.008086184489610827}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:20,463] Trial 13 finished with value: 0.03482411801815033 and parameters: {'n_lstm_layers': 2, 'lstm_units': 50, 'n_dense_layers': 1, 'lstm_dropout_0': 0.24507118314607956, 'lstm_dropout_1': 0.4910797466765211, 'dense_units_0': 64, 'dense_dropout_0': 0.39458542658396, 'learning_rate': 0.008098237757267182}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:28,111] Trial 14 finished with value: 0.03922833502292633 and parameters: {'n_lstm_layers': 2, 'lstm_units': 42, 'n_dense_layers': 1, 'lstm_dropout_0': 0.24366907789897319, 'lstm_dropout_1': 0.3590210935711706, 'dense_units_0': 52, 'dense_dropout_0': 0.11813192286619498, 'learning_rate': 0.0017430478745390039}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:35,417] Trial 15 finished with value: 0.03230378404259682 and parameters: {'n_lstm_layers': 2, 'lstm_units': 60, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20293658494881983, 'lstm_dropout_1': 0.3874261995330813, 'learning_rate': 0.00986780013129469}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:42,522] Trial 16 finished with value: 0.07347330451011658 and parameters: {'n_lstm_layers': 2, 'lstm_units': 60, 'n_dense_layers': 1, 'lstm_dropout_0': 0.28433371515137995, 'lstm_dropout_1': 0.42377568757034356, 'dense_units_0': 48, 'dense_dropout_0': 0.31303145572161994, 'learning_rate': 0.00047450806051993445}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:50,098] Trial 17 finished with value: 0.035008735954761505 and parameters: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2812865240749252, 'lstm_dropout_1': 0.31747663776720636, 'learning_rate': 0.0050242635112042675}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:47:57,742] Trial 18 finished with value: 0.037739578634500504 and parameters: {'n_lstm_layers': 2, 'lstm_units': 66, 'n_dense_layers': 1, 'lstm_dropout_0': 0.17661721738530928, 'lstm_dropout_1': 0.4413816516438418, 'dense_units_0': 50, 'dense_dropout_0': 0.1634612664080116, 'learning_rate': 0.0015294841032154286}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:48:05,474] Trial 19 finished with value: 0.047600165009498596 and parameters: {'n_lstm_layers': 2, 'lstm_units': 91, 'n_dense_layers': 2, 'lstm_dropout_0': 0.14301221894527374, 'lstm_dropout_1': 0.4443543153433661, 'dense_units_0': 17, 'dense_dropout_0': 0.10528910557024576, 'dense_units_1': 16, 'dense_dropout_1': 0.48925164780555075, 'learning_rate': 0.003291796446667085}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:48:13,045] Trial 20 finished with value: 0.03331143036484718 and parameters: {'n_lstm_layers': 2, 'lstm_units': 40, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3736037858370721, 'lstm_dropout_1': 0.28559386573095685, 'dense_units_0': 54, 'dense_dropout_0': 0.3189445869456239, 'learning_rate': 0.006518040945616527}. Best is trial 10 with value: 0.03163100406527519.
[I 2025-04-14 18:48:20,527] Trial 21 finished with value: 0.031615931540727615 and parameters: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20759715942685714, 'lstm_dropout_1': 0.381022890770056, 'learning_rate': 0.009742756373105673}. Best is trial 21 with value: 0.031615931540727615.
[I 2025-04-14 18:48:27,892] Trial 22 finished with value: 0.03587304800748825 and parameters: {'n_lstm_layers': 2, 'lstm_units': 54, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20380890415880532, 'lstm_dropout_1': 0.39060238596636127, 'learning_rate': 0.006690112138288274}. Best is trial 21 with value: 0.031615931540727615.
[I 2025-04-14 18:48:35,449] Trial 23 finished with value: 0.03534869849681854 and parameters: {'n_lstm_layers': 2, 'lstm_units': 64, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2661691239596081, 'lstm_dropout_1': 0.46942871531340663, 'learning_rate': 0.0030639034782283304}. Best is trial 21 with value: 0.031615931540727615.
[I 2025-04-14 18:48:42,967] Trial 24 finished with value: 0.03192569315433502 and parameters: {'n_lstm_layers': 2, 'lstm_units': 56, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2055181474574334, 'lstm_dropout_1': 0.3986470752490024, 'dense_units_0': 28, 'dense_dropout_0': 0.16416707562460034, 'learning_rate': 0.006179970147295016}. Best is trial 21 with value: 0.031615931540727615.
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Baseload, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Baseload, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Change_in_Load, Scenario: 24hr, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Change_in_Load, Scenario=24hr, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Change_in_Load, Scenario=24hr. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=ANN_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: ANN_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=ANN_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=12, Arch=ANN_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Baseload, Scenario: 24hr, Version: None
Selected Model ID: 185, Version: v1.1_Final_Forecasting_20250414170747, Path Info: {"keras_model": "models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747.keras", "scalers_pkl": "models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747.keras', 'scalers_pkl': 'models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747_scalers.pkl'}
Detected separate Keras model (models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747.keras) and scalers (models/feeder_12/LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Baseload_24hr_v1.1_Final_Forecasting_20250414170747_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Baseload ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.078168

--- Optuna Trial 1 for LSTM_Baseload ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.056920

--- Optuna Trial 2 for LSTM_Baseload ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.037177

--- Optuna Trial 3 for LSTM_Baseload ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.097118

--- Optuna Trial 4 for LSTM_Baseload ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.039258

--- Optuna Trial 5 for LSTM_Baseload ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.046112

--- Optuna Trial 6 for LSTM_Baseload ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.099129

--- Optuna Trial 7 for LSTM_Baseload ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.037649

--- Optuna Trial 8 for LSTM_Baseload ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.047139

--- Optuna Trial 9 for LSTM_Baseload ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.039706

--- Optuna Trial 10 for LSTM_Baseload ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.034527

--- Optuna Trial 11 for LSTM_Baseload ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.035157

--- Optuna Trial 12 for LSTM_Baseload ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.034338

--- Optuna Trial 13 for LSTM_Baseload ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.032945

--- Optuna Trial 14 for LSTM_Baseload ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.034818

--- Optuna Trial 15 for LSTM_Baseload ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.035063

--- Optuna Trial 16 for LSTM_Baseload ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.033340

--- Optuna Trial 17 for LSTM_Baseload ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.038601

--- Optuna Trial 18 for LSTM_Baseload ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.038088

--- Optuna Trial 19 for LSTM_Baseload ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.045142

--- Optuna Trial 20 for LSTM_Baseload ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.036164

--- Optuna Trial 21 for LSTM_Baseload ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.036590

--- Optuna Trial 22 for LSTM_Baseload ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.035522

--- Optuna Trial 23 for LSTM_Baseload ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.035646

--- Optuna Trial 24 for LSTM_Baseload ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.032706

--- Best Results for Feeder=12, Arch=LSTM_Baseload, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.032706
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 61
  n_dense_layers: 0
  lstm_dropout_0: 0.1480122154703271
  lstm_dropout_1: 0.24594247033383898
  learning_rate: 0.0024326125463904748

--- Tuning: Arch=LSTM_Baseload, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Baseload, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LSTM_Baseload, Scenario=Day, Version=None
Warning: No existing model found for Feeder=12, Arch=LSTM_Baseload, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Baseload, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Baseload, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LSTM_Baseload, Scenario=Night, Version=None
Warning: No existing model found for Feeder=12, Arch=LSTM_Baseload, Scenario=Night. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=24hr ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Change_in_Load, Scenario: 24hr, Version: None
Selected Model ID: 186, Version: v1.1_Final_Forecasting_20250414170755, Path Info: {"keras_model": "models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755.keras", "scalers_pkl": "models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755_scalers.pkl"}
Loading artifact(s) based on path info: {'keras_model': 'models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755.keras', 'scalers_pkl': 'models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755_scalers.pkl'}
Detected separate Keras model (models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755.keras) and scalers (models/feeder_12/LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755_scalers.pkl).
Downloading Keras model to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755.keras
Keras model downloaded. Loading...
Keras model loaded.
Downloading scalers pickle to: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755_scalers.pkl
Scalers pickle downloaded. Loading...
Scalers pickle loaded.
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755.keras
Cleaned up temporary file: H:\My Drive\Barbados_Forecasting_Tool_Final\tmp\LSTM_Change_in_Load_24hr_v1.1_Final_Forecasting_20250414170755_scalers.pkl
Preparing training and validation data using loaded scalers...
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (150, 177), y shape (150, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting feature engineering for scenario: 24hr...
Pivoting data into daily vectors...
Reshaped data: X shape (32, 177), y shape (32, 24)
Transforming data using provided scalers (X and y)...
Data transformed.
Starting Optuna optimization (25 trials)...

--- Optuna Trial 0 for LSTM_Change_in_Load ---
Trial 0: Training model...
Trial 0: Validation Score (mae, scaled) = 0.048727

--- Optuna Trial 1 for LSTM_Change_in_Load ---
Trial 1: Training model...
Trial 1: Validation Score (mae, scaled) = 0.044812

--- Optuna Trial 2 for LSTM_Change_in_Load ---
Trial 2: Training model...
Trial 2: Validation Score (mae, scaled) = 0.043593

--- Optuna Trial 3 for LSTM_Change_in_Load ---
Trial 3: Training model...
Trial 3: Validation Score (mae, scaled) = 0.105566

--- Optuna Trial 4 for LSTM_Change_in_Load ---
Trial 4: Training model...
Trial 4: Validation Score (mae, scaled) = 0.045549

--- Optuna Trial 5 for LSTM_Change_in_Load ---
Trial 5: Training model...
Trial 5: Validation Score (mae, scaled) = 0.037805

--- Optuna Trial 6 for LSTM_Change_in_Load ---
Trial 6: Training model...
Trial 6: Validation Score (mae, scaled) = 0.233609

--- Optuna Trial 7 for LSTM_Change_in_Load ---
Trial 7: Training model...
Trial 7: Validation Score (mae, scaled) = 0.068321

--- Optuna Trial 8 for LSTM_Change_in_Load ---
Trial 8: Training model...
Trial 8: Validation Score (mae, scaled) = 0.035116

--- Optuna Trial 9 for LSTM_Change_in_Load ---
Trial 9: Training model...
Trial 9: Validation Score (mae, scaled) = 0.035334

--- Optuna Trial 10 for LSTM_Change_in_Load ---
Trial 10: Training model...
Trial 10: Validation Score (mae, scaled) = 0.031631

--- Optuna Trial 11 for LSTM_Change_in_Load ---
Trial 11: Training model...
Trial 11: Validation Score (mae, scaled) = 0.033335

--- Optuna Trial 12 for LSTM_Change_in_Load ---
Trial 12: Training model...
Trial 12: Validation Score (mae, scaled) = 0.031965

--- Optuna Trial 13 for LSTM_Change_in_Load ---
Trial 13: Training model...
Trial 13: Validation Score (mae, scaled) = 0.034824

--- Optuna Trial 14 for LSTM_Change_in_Load ---
Trial 14: Training model...
Trial 14: Validation Score (mae, scaled) = 0.039228

--- Optuna Trial 15 for LSTM_Change_in_Load ---
Trial 15: Training model...
Trial 15: Validation Score (mae, scaled) = 0.032304

--- Optuna Trial 16 for LSTM_Change_in_Load ---
Trial 16: Training model...
Trial 16: Validation Score (mae, scaled) = 0.073473

--- Optuna Trial 17 for LSTM_Change_in_Load ---
Trial 17: Training model...
Trial 17: Validation Score (mae, scaled) = 0.035009

--- Optuna Trial 18 for LSTM_Change_in_Load ---
Trial 18: Training model...
Trial 18: Validation Score (mae, scaled) = 0.037740

--- Optuna Trial 19 for LSTM_Change_in_Load ---
Trial 19: Training model...
Trial 19: Validation Score (mae, scaled) = 0.047600

--- Optuna Trial 20 for LSTM_Change_in_Load ---
Trial 20: Training model...
Trial 20: Validation Score (mae, scaled) = 0.033311

--- Optuna Trial 21 for LSTM_Change_in_Load ---
Trial 21: Training model...
Trial 21: Validation Score (mae, scaled) = 0.031616

--- Optuna Trial 22 for LSTM_Change_in_Load ---
Trial 22: Training model...
Trial 22: Validation Score (mae, scaled) = 0.035873

--- Optuna Trial 23 for LSTM_Change_in_Load ---
Trial 23: Training model...
Trial 23: Validation Score (mae, scaled) = 0.035349

--- Optuna Trial 24 for LSTM_Change_in_Load ---
Trial 24: Training model...
Trial 24: Validation Score (mae, scaled) = 0.031926

--- Best Results for Feeder=12, Arch=LSTM_Change_in_Load, Scenario=24hr ---
Best Validation Score (mae, scaled): 0.031616
Best Hyperparameters:
  n_lstm_layers: 2
  lstm_units: 58
  n_dense_layers: 0
  lstm_dropout_0: 0.20759715942685714
  lstm_dropout_1: 0.381022890770056
  learning_rate: 0.009742756373105673

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Day ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Change_in_Load, Scenario: Day, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LSTM_Change_in_Load, Scenario=Day, Version=None
Warning: No existing model found for Feeder=12, Arch=LSTM_Change_in_Load, Scenario=Day. Cannot get scalers. Skipping.

--- Tuning: Arch=LSTM_Change_in_Load, Scenario=Night ---
Loading existing model artifact to get scalers/columns...
Selecting model for Feeder 12, Arch: LSTM_Change_in_Load, Scenario: Night, Version: None
Error: No matching model found for criteria: Feeder=12, Arch=LSTM_Change_in_Load, Scenario=Night, Version=None
Warning: No existing model found for Feeder=12, Arch=LSTM_Change_in_Load, Scenario=Night. Cannot get scalers. Skipping.

===== Hyperparameter Tuning Summary =====

Feeder: 1, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.082489
  Best Params: {'n_estimators': 97, 'learning_rate': 0.143780173340082, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 20, 'subsample': 0.8625111026367087, 'colsample_bytree': 0.9981403657772591, 'reg_alpha': 5.476285507534117e-06, 'reg_lambda': 0.0003991187467010624}

Feeder: 1, Architecture: ANN_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.089832
  Best Params: {'n_layers': 3, 'units_layer_0': 255, 'dropout_layer_0': 0.28062027452977767, 'units_layer_1': 71, 'dropout_layer_1': 0.2925653022404558, 'units_layer_2': 131, 'dropout_layer_2': 0.21331008677904822, 'learning_rate': 0.003775193066223191}

Feeder: 1, Architecture: ANN_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.061728
  Best Params: {'n_layers': 3, 'units_layer_0': 67, 'dropout_layer_0': 0.18743639333565498, 'units_layer_1': 146, 'dropout_layer_1': 0.21560215568540808, 'units_layer_2': 35, 'dropout_layer_2': 0.4145244715036238, 'learning_rate': 0.004839588117070405}

Feeder: 1, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.082314
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 44, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20505835763267546, 'lstm_dropout_1': 0.11259093026249084, 'learning_rate': 0.0022551761476824477}

Feeder: 1, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.059903
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 79, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10039998011565632, 'lstm_dropout_1': 0.3146228283196653, 'learning_rate': 0.005853592387776404}

Feeder: 2, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.091713
  Best Params: {'n_estimators': 73, 'learning_rate': 0.16494242595095507, 'num_leaves': 49, 'max_depth': 3, 'min_child_samples': 14, 'subsample': 0.5988240151343207, 'colsample_bytree': 0.8013284743960083, 'reg_alpha': 2.0251231679776354e-08, 'reg_lambda': 0.0009687043359664956}

Feeder: 2, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.100899
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 92, 'n_dense_layers': 1, 'lstm_dropout_0': 0.29777493411700545, 'lstm_dropout_1': 0.24045226694478883, 'dense_units_0': 20, 'dense_dropout_0': 0.2390892086324524, 'learning_rate': 0.005842769995302442}

Feeder: 2, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.084799
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 100, 'n_dense_layers': 1, 'lstm_dropout_0': 0.31919056548067415, 'lstm_dropout_1': 0.2566754956483025, 'dense_units_0': 64, 'dense_dropout_0': 0.10831157130924224, 'learning_rate': 0.0054834224985391014}

Feeder: 3, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.047145
  Best Params: {'n_estimators': 223, 'learning_rate': 0.06856482671559008, 'num_leaves': 21, 'max_depth': 5, 'min_child_samples': 13, 'subsample': 0.5829821236998173, 'colsample_bytree': 0.9072033258167731, 'reg_alpha': 1.4896384584284221e-06, 'reg_lambda': 0.024113614875541957}

Feeder: 3, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.053225
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 73, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3728473852130089, 'dense_units_0': 47, 'dense_dropout_0': 0.3847274684317129, 'learning_rate': 0.008504021355281777}

Feeder: 3, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.045081
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 47, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2674524414312311, 'lstm_dropout_1': 0.10002270904965499, 'learning_rate': 0.004524347631653716}

Feeder: 4, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.180571
  Best Params: {'n_estimators': 236, 'learning_rate': 0.2891874557120938, 'num_leaves': 43, 'max_depth': 6, 'min_child_samples': 23, 'subsample': 0.9266744852958987, 'colsample_bytree': 0.9014508188889362, 'reg_alpha': 0.9153281537337985, 'reg_lambda': 0.45567184251439646}

Feeder: 4, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.167818
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 82, 'n_dense_layers': 1, 'lstm_dropout_0': 0.3590813858165105, 'dense_units_0': 31, 'dense_dropout_0': 0.21284717344122217, 'learning_rate': 0.006903839646376025}

Feeder: 4, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.121488
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 83, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4912371753978999, 'lstm_dropout_1': 0.3439956026283413, 'learning_rate': 0.008642039575007658}

Feeder: 5, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.121520
  Best Params: {'n_estimators': 196, 'learning_rate': 0.028185632368471845, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 38, 'subsample': 0.9722910966716541, 'colsample_bytree': 0.8527236004809267, 'reg_alpha': 0.2919728256814584, 'reg_lambda': 0.0961960751689055}

Feeder: 5, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.125448
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 108, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1702998075739121, 'lstm_dropout_1': 0.2739042036232272, 'learning_rate': 0.0016927465122475217}

Feeder: 5, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.120304
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 107, 'n_dense_layers': 0, 'lstm_dropout_0': 0.4304650216554355, 'learning_rate': 0.004524594816263526}

Feeder: 6, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.133085
  Best Params: {'n_estimators': 253, 'learning_rate': 0.29471490959730323, 'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 5, 'subsample': 0.870653286534444, 'colsample_bytree': 0.9497587992545666, 'reg_alpha': 0.0001289760492381335, 'reg_lambda': 5.059092462761579e-05}

Feeder: 6, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.088777
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 118, 'n_dense_layers': 0, 'lstm_dropout_0': 0.23404914145337877, 'lstm_dropout_1': 0.19981906966616403, 'learning_rate': 0.006267757934529045}

Feeder: 6, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.100573
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 116, 'n_dense_layers': 0, 'lstm_dropout_0': 0.49562958928984724, 'lstm_dropout_1': 0.14974988853790872, 'learning_rate': 0.000537599716249571}

Feeder: 7, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.153065
  Best Params: {'n_estimators': 198, 'learning_rate': 0.0712077716299931, 'num_leaves': 60, 'max_depth': 4, 'min_child_samples': 5, 'subsample': 0.8535759889033576, 'colsample_bytree': 0.8376771882983307, 'reg_alpha': 0.00046509175327640517, 'reg_lambda': 1.1379492797485943e-05}

Feeder: 7, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.139208
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 97, 'n_dense_layers': 0, 'lstm_dropout_0': 0.13541453088745595, 'learning_rate': 0.0017748430448362071}

Feeder: 7, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.113783
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 87, 'n_dense_layers': 0, 'lstm_dropout_0': 0.28668509036197204, 'learning_rate': 0.005932343474320879}

Feeder: 8, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.114844
  Best Params: {'n_estimators': 53, 'learning_rate': 0.08274679703664146, 'num_leaves': 45, 'max_depth': 4, 'min_child_samples': 16, 'subsample': 0.7052973498144763, 'colsample_bytree': 0.7873966100360492, 'reg_alpha': 0.001829701432791697, 'reg_lambda': 0.0005404293524667066}

Feeder: 8, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.125700
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 78, 'n_dense_layers': 0, 'lstm_dropout_0': 0.10434836284218267, 'learning_rate': 0.00251665208851499}

Feeder: 8, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.098406
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 50, 'n_dense_layers': 2, 'lstm_dropout_0': 0.3658954649238185, 'lstm_dropout_1': 0.21554559347667882, 'dense_units_0': 59, 'dense_dropout_0': 0.10073885924604259, 'dense_units_1': 51, 'dense_dropout_1': 0.10667216924023493, 'learning_rate': 0.0046435408312779595}

Feeder: 9, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.114502
  Best Params: {'n_estimators': 77, 'learning_rate': 0.09788147429902692, 'num_leaves': 23, 'max_depth': 10, 'min_child_samples': 23, 'subsample': 0.974354356233927, 'colsample_bytree': 0.5030787717483867, 'reg_alpha': 2.732667434630833e-06, 'reg_lambda': 1.9857421215678946e-08}

Feeder: 9, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.118822
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 82, 'n_dense_layers': 0, 'lstm_dropout_0': 0.2354281028791115, 'lstm_dropout_1': 0.33251150617828823, 'learning_rate': 0.001141397815731878}

Feeder: 9, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.121954
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 83, 'n_dense_layers': 2, 'lstm_dropout_0': 0.2342521323299082, 'dense_units_0': 49, 'dense_dropout_0': 0.2647961356437788, 'dense_units_1': 27, 'dense_dropout_1': 0.22986179545072508, 'learning_rate': 0.004340766228604256}

Feeder: 10, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.153247
  Best Params: {'n_estimators': 229, 'learning_rate': 0.015367922521804266, 'num_leaves': 47, 'max_depth': 6, 'min_child_samples': 5, 'subsample': 0.7461358409822427, 'colsample_bytree': 0.7497854231982228, 'reg_alpha': 0.00225594560166635, 'reg_lambda': 0.03982146668079337}

Feeder: 10, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.161540
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 109, 'n_dense_layers': 0, 'lstm_dropout_0': 0.18177978754814667, 'lstm_dropout_1': 0.12694580777200143, 'learning_rate': 0.0026192952484302558}

Feeder: 10, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.164743
  Best Params: {'n_lstm_layers': 1, 'lstm_units': 63, 'n_dense_layers': 1, 'lstm_dropout_0': 0.31816764108355294, 'dense_units_0': 40, 'dense_dropout_0': 0.34266377150597205, 'learning_rate': 0.0051671961555181025}

Feeder: 11, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.096118
  Best Params: {'n_estimators': 74, 'learning_rate': 0.08790556475647288, 'num_leaves': 29, 'max_depth': 5, 'min_child_samples': 18, 'subsample': 0.8555317383386971, 'colsample_bytree': 0.9466203051905835, 'reg_alpha': 2.492847362572821e-06, 'reg_lambda': 2.1661061231454955e-06}

Feeder: 11, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.098545
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 84, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2495586331656735, 'lstm_dropout_1': 0.23951942526028394, 'dense_units_0': 58, 'dense_dropout_0': 0.2098373588561905, 'learning_rate': 0.009778938872259967}

Feeder: 11, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.099169
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 115, 'n_dense_layers': 1, 'lstm_dropout_0': 0.2285828274457054, 'lstm_dropout_1': 0.16919725134303384, 'dense_units_0': 41, 'dense_dropout_0': 0.10060917757860122, 'learning_rate': 0.0036422237367562294}

Feeder: 12, Architecture: LightGBM_Baseline, Scenario: 24hr
  Best Score (mae, scaled): 0.027371
  Best Params: {'n_estimators': 299, 'learning_rate': 0.021717148882897903, 'num_leaves': 22, 'max_depth': 7, 'min_child_samples': 41, 'subsample': 0.5989940441261528, 'colsample_bytree': 0.8884160934573438, 'reg_alpha': 0.07610914060294705, 'reg_lambda': 1.9418139277052897e-08}

Feeder: 12, Architecture: LSTM_Baseload, Scenario: 24hr
  Best Score (mae, scaled): 0.032706
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 61, 'n_dense_layers': 0, 'lstm_dropout_0': 0.1480122154703271, 'lstm_dropout_1': 0.24594247033383898, 'learning_rate': 0.0024326125463904748}

Feeder: 12, Architecture: LSTM_Change_in_Load, Scenario: 24hr
  Best Score (mae, scaled): 0.031616
  Best Params: {'n_lstm_layers': 2, 'lstm_units': 58, 'n_dense_layers': 0, 'lstm_dropout_0': 0.20759715942685714, 'lstm_dropout_1': 0.381022890770056, 'learning_rate': 0.009742756373105673}

--- Hyperparameter Tuning Script Finished ---
